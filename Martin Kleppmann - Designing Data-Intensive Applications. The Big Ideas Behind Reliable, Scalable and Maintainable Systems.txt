p45, imperative vs. declarative javascript:
the culprit here is "no abstraction" instead of being imperative

p74, "in order to find the value for a key, we first check the most recent segment’s hash map; if
the key is not present we check the second-most-recent segment, and so on."
... or store the epoch number as part of the index.

Branching factor of a B-tree is variable in a range, in Rust BTreeMap the range is [5, 11].

p87, multi-column indexes
One possible solution to multi-dimensional queries in relational databases is data cube, which is
standardized in ISO SQL 2018.

p95, Column-Oriented Storage
curiously akin to Entity Component System, in which components of objects rather than objects
themselves are stored together

p113, "if an attacker can get your application to decode an arbitrary byte sequence, they can
instantiate arbitrary classes, which in turn often allows them to do terrible things such as
remotely executing arbitrary code [6, 7]"
- [6]: CVE-2015-7501, Java, serializing / deserializing certain objects invokes methods through
    runtime reflection which can be exploited to run arbitrary code with forged payload
- [7]: CVE-2013-0156, Ruby, YAML.load occasionally evaluates serialized string which may include
    arbitrary code wrapped in `eval` function call
Both cases the vulnerability originated in lack of distinction between data and program in the
language and badly written serialization library, hence
> "For these reasons it’s generally a bad idea to use your language’s built-in encoding for
> anything other than very transient purposes"
doesn't necessarily apply to something like Bincode. In the Ruby case it's not even built-in
encoding, YAML is developed independently and had seen wide adoption since its early days.

[4] Frank McSherry, Michael Isard, and Derek G. Murray: “Scalability! But at What
COST?”
Hilarious paper presenting two main points:
1.  many workloads scales very well only because they are not optimized, after optimization the
    their performance no longer scales beyond ~10 cores
2.  many distributed algorithms despite scales very well is not more efficient than a simple
    single-threaded algorithm to begin with, not even with unbounded number of nodes
A reproduction conducted in 2019 (http://vaastavanand.com/blog/2019/Reproduction-Cost/) shows
that the single-threaded algorithm outperformed distributed algorithms even more due to improved
memory handling in Linux and better hardware

[23] Douglas B. Terry: “Replicated Data Consistency Explained Through Baseball”
Given 6 consistency model in partial order:
    Strong Consistency: See all previous writes.
    Bounded Staleness: See all “old” writes.
    Consistent Prefix: See initial sequence of writes.
    Monotonic Reads: See increasing subset of writes.
    Read My Writes: See all writes performed by reader.
    Eventual Consistency: See subset of previous writes.
where Strong Consistency is the absolute strongest,  Eventual Consistency is implied by all other
models, Bounded Staleness after a delay converges to Strong Consistency hence implies all others

The algorithm presented in the text is a variant of the dotted version vectors set (DVVSet)
operating on a single replica.
- https://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf
- https://github.com/ricardobcl/Dotted-Version-Vectors
The code (in Erlang) is barely documented, the company operating Riak went out of business in
2017, Amazon doesn't seem to be using version vectors any more since 2015

p208, Partitioning Secondary Indexes by Term
A discussion on this topic in Berkeley CS186 : https://www.youtube.com/watch?v=FNhJXpcc3I4,
partitioning indexes by terms can be a very bad idea since most human behaviors follow the Zipf
distribution: naturally 80% accesses will be on 20% terms

Common implementation of isolation levels
Read committed: 
    modification is performed on a different version of the store, only applied to the main store when commited
Snapshot isolation: 
    each transaction works on a snapshot version of the store identified by an always
    incrementing transaction id, modification is invisible to a transaction if
        1.  the modifying transaction is not committed yet when the current one started
        2.  modifying transaction has a later id
        3.  the modifying transaction aborted
    A background garbage collector periodically remove old values no longer visible to any
    ongoing and future transactions.
Serializable:
    1.  actual serial execution, one transaction at a time (became feasible recently)
    2.  locally shard the store then 1. may be executed concurrently
    3.  2PL: each object is protected by a read / write lock, in phase one the transaction tries to
        acquire all the locks of objects it may use, in phase two the transaction is executed and
        then locks released. To handle phantoms in addition to existing objects there must be lock
        on not yet existing objects (predicate locks) or ranges of them (index-range locks). 
    4.  Serializable snapshot isolation: the basic idea sketched by the text is superficially
        similar to that of software transactional memory (STM): on top of snapshot isolation,
        optimistically execute the transaction on a snapshot, commit only when the result is not
        invalidated by other current transactions; but STM is mentioned nowhere in the original
        paper [51], guess the description in the text must be over-simplified
    
[27] Michael Melanson: “Transactions: The Limits of Isolation”
As there's no commonly agreed interpretation to isolation levels provided by DBMS vendors, author
of this book wrote a tool to test them.

p242, "they also use B-trees (see “B-Trees” on page 79), they use an append-only/copy-on-write
variant that does not overwrite pages of the tree when they are updated, but instead creates a
new copy of each modified page"
One such persistent binary search tree is introduced in Introduction to algorithms, problems 13-1
