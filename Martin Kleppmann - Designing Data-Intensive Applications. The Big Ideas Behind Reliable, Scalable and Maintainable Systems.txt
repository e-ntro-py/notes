p45, imperative vs. declarative javascript:
the culprit here is "no abstraction" instead of being imperative

p74, "in order to find the value for a key, we first check the most recent segment’s hash map; if
the key is not present we check the second-most-recent segment, and so on."
... or store the epoch number as part of the index.

Branching factor of a B-tree is variable in a range, in Rust BTreeMap the range is [5, 11].

p87, multi-column indexes
One possible solution to multi-dimensional queries in relational databases is data cube, which is
standardized in ISO SQL 2018.

p95, Column-Oriented Storage
curiously akin to Entity Component System, in which components of objects rather than objects
themselves are stored together

p113, "if an attacker can get your application to decode an arbitrary byte sequence, they can
instantiate arbitrary classes, which in turn often allows them to do terrible things such as
remotely executing arbitrary code [6, 7]"
- [6]: CVE-2015-7501, Java, serializing / deserializing certain objects invokes methods through
    runtime reflection which can be exploited to run arbitrary code with forged payload
- [7]: CVE-2013-0156, Ruby, YAML.load occasionally evaluates serialized string which may include
    arbitrary code wrapped in `eval` function call
Both cases the vulnerability originated in lack of distinction between data and program in the
language and badly written serialization library, hence
> "For these reasons it’s generally a bad idea to use your language’s built-in encoding for
> anything other than very transient purposes"
doesn't necessarily apply to something like Bincode. In the Ruby case it's not even built-in
encoding, YAML is developed independently and had seen wide adoption since its early days.

[4] Frank McSherry, Michael Isard, and Derek G. Murray: “Scalability! But at What
COST?”
Hilarious paper presenting two main points:
1.  many workloads scales very well only because they are not optimized, after optimization the
    their performance no longer scales beyond ~10 cores
2.  many distributed algorithms despite scales very well is not more efficient than a simple
    single-threaded algorithm to begin with, not even with unbounded number of nodes
A reproduction conducted in 2019 (http://vaastavanand.com/blog/2019/Reproduction-Cost/) shows
that the single-threaded algorithm outperformed distributed algorithms even more due to improved
memory handling in Linux and better hardware

[23] Douglas B. Terry: “Replicated Data Consistency Explained Through Baseball”
Given 6 consistency model in partial order:
    Strong Consistency: See all previous writes.
    Bounded Staleness: See all “old” writes.
    Consistent Prefix: See initial sequence of writes.
    Monotonic Reads: See increasing subset of writes.
    Read My Writes: See all writes performed by reader.
    Eventual Consistency: See subset of previous writes.
where Strong Consistency is the absolute strongest,  Eventual Consistency is implied by all other
models, Bounded Staleness after a delay converges to Strong Consistency hence implies all others

The algorithm presented in the text is a variant of the dotted version vectors set (DVVSet)
operating on a single replica.
- https://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf
- https://github.com/ricardobcl/Dotted-Version-Vectors
The code (in Erlang) is barely documented, the company operating Riak went out of business in
2017, Amazon doesn't seem to be using version vectors any more since 2015

p208, Partitioning Secondary Indexes by Term
A discussion on this topic in Berkeley CS186 : https://www.youtube.com/watch?v=FNhJXpcc3I4,
partitioning indexes by terms can be a very bad idea since most human behaviors follow the Zipf
distribution: naturally 80% accesses will be on 20% terms

Common implementation of isolation levels
Read committed: 
    modification is performed on a different version of the store, only applied to the main store
    when commited
Snapshot isolation: 
    each transaction works on a snapshot version of the store identified by an always
    incrementing transaction id, modification is invisible to a transaction if
        1.  the modifying transaction is not committed yet when the current one started
        2.  modifying transaction has a later id
        3.  the modifying transaction aborted
    A background garbage collector periodically remove old values no longer visible to any
    ongoing and future transactions.
Serializable:
    1.  actual serial execution, one transaction at a time (became feasible recently)
    2.  locally shard the store then 1. may be executed concurrently
    3.  2PL: each object is protected by a read / write lock, in phase one the transaction tries to
        acquire all the locks of objects it may use, in phase two the transaction is executed and
        then locks released. To handle phantoms in addition to existing objects there must be lock
        on not yet existing objects (predicate locks) or ranges of them (index-range locks). 
    4.  Serializable snapshot isolation: the basic idea sketched by the text is superficially
        similar to that of software transactional memory (STM): on top of snapshot isolation,
        optimistically execute the transaction on a snapshot, commit only when the result is not
        invalidated by other current transactions; but STM is mentioned nowhere in the original
        paper [51], guess the description in the text must be over-simplified
    
[27] Michael Melanson: “Transactions: The Limits of Isolation”
As there's no commonly agreed interpretation to isolation levels provided by DBMS vendors, author
of this book wrote a tool to test them.

p242, "they also use B-trees (see “B-Trees” on page 79), they use an append-only/copy-on-write
variant that does not overwrite pages of the tree when they are updated, but instead creates a
new copy of each modified page"
One such persistent binary search tree is introduced in Introduction to algorithms, problems 13-1

[21] Salvatore Sanfilippo: “A Few Arguments About Redis Sentinel Properties and
Fail Scenarios”
A Redis leader, configured not to persist data on disk, crashed and restarted with an empty
store, yet managed to restart so fast that the watcher instance (Redis Sentinel) hadn't detected
the failure, as a result all replica synchronized with the leader and wiped their database. The
Redis developer (author of the blog) talked about how to prevent future accidents by a version
tag ("runid"), which is now implemented.

[90] Bowen Alpern and Fred B. Schneider: “Defining Liveness”
let 
    S be the set of program states
    S^ω be the set of infinite sequences of program states
    σ ∈ S^w be executions of program
    S^* be the set of finite sequences of program states
    σ_i ∈ S^*, the length i prefix of σ, be partial executions
    σ |= P when an execution σ of a program is in property P
safety property is defined as
    ∀σ∈S, ~(σ |= P) => ∃i>=0, ∀β∈S^ω, ~(σ_i β |= P)
that is, when an execution doesn't satisfy a safety property, there must be a point in the execution
that, after which the safety property is irredeemable: no further actions may make the execution
satisfy P ever again
liveness property is defined as
    ∀α∈S^*, ∃β∈S^ω, αβ |= P
that is, for any execution of the program, there's always a (maybe infinite) sequence of actions
that, after which the execution satisfies the liveness property P, or the liveness property
will "eventually happen"

[46] Nelson Minar: “Leap Second Crashes Half the Internet”
a bug in adjtimex(2) set some timer in the kernel one second ahead of others, as a consequence
clock_nanosleep shorter than 1 second will return immediately, turning certain loops into spin
locks which saturated CPU

[6] Maurice P. Herlihy and Jeannette M. Wing: “Linearizability: A Correctness Condition for
Concurrent Objects”
An operation invocation is a four tuple:
    (x, op, args, A), or by the notation of the paper,
    <x op(args*) A>
where
    x:      the object name
    op:     an operation name
    args:   a sequence of argument values
    A:      a process name
A response is a four tuple:
    <x term(res*) A>
where
    x:      the object name
    term:   a termination condition
    res:    a sequence of results
    A:      a process name
A response matches an invocation if their object names agree and their process names agree.
An event is either an invocation or a response
A history H is a sequence of events
complete(H) is the maximum subsequence of H that all invocations has matching responses
A history H is sequential if 
    1.  H starts with an invocation
    2.  except for the final invocation, each invocation is followed immediately by a matching
        response each response is followed immediately by a matching invocation
A process sub-history H|P is the subsequence of all events in H whose process names are P
An object sub-history H|x is similarly defined
A history is well-formed if for all P, H|P is sequential
Two histories H and H' are equivalent if
    ∀P, H|P = H'|P
A sequential specification for an object is a prefix-closed set of single-object sequential
histories for that object
A history H is legal if:
    1.  H is sequential
    2.  H|x for all x belongs to the sequential specification for x
An operation 
    [q inv/res A]
is a pair of matching invocation and the next matching response
An operation e0 lies within another operation e1 if inv(e1) precedes inv(e0) and res(e0) precedes
res(e1)
A history H induces an partial order <_H on operations:
    e0 <_H e1 if res(e0) precedes inv(e1) in H
if H is sequential, <_H is a total order
A history H is linearizable if it can be extended (by appending zero or more response events) to
some history H’ such that:
    1.  complete(H') is equivalent to some legal sequential history S
    2.  <_H ⊆ <_S
in other words, the completed operations in the history may be seen as sequentially executed while
preserving all the orderings and logical correctness.
Linearizability is local:
    H is linearizable iff H|x is linearizable for all object x
Linearizability is non-blocking:
    Let inv be an invocation of a total operation. If <x inv P> is a pending invocation in a
    linearizable history H, then there exists a response <x res P> such that H . <x res P> is
    linearizable.

[56] Leslie Lamport: “Time, Clocks, and the Ordering of Events in a Distributed System”
Define "happens before" relation -> as the transitive closure of:
    1.  a -> b if event a happens before b on the same process
    2.  a -> b if a sends a message and b is the receipt 
(in this paper events are instant, not a period of time)
naturally -> is a superset of causal dependencies
A clock C is a function that maps events to numbers, the correctness of a clock is defined as:
    a -> b implies C(a) < C(b)
An intuitive way to satisfy the correctness condition is, set a counter in each process that:
    1.  increment the counter between each two successive events in that process
    2.  tag each message with the current counter, upon receiving the message advance the counter to
        a number greater than the received number in the message
Assign an arbitrary total order to processes, define a total order => over tuples of events and
processes that:
    (C(a), Pi) => (C(b), Pj) iff C(a) < C(b) | (C(a) = C(b) & Pi < Pj
a simple proof of concept:
./distributed_system/lamport_timestamp
Without errors, any program that can be described as a (possibly infinite) state machine
    F: C x S -> S
where
    C: set of commands 
    S: set of states
    F: a function computes the next state from a command and the current state 
may be correctly implemented as a distributed system with Lamport timestamp and message
broadcasting: the order of comments is ensured by the total order =>.
Later half of the paper is dedicated on replacing the counter in Lamport timestamp by physical
times
