p45, imperative vs. declarative javascript:
the culprit here is "no abstraction" instead of being imperative

p74, "in order to find the value for a key, we first check the most recent segment’s hash map; if
the key is not present we check the second-most-recent segment, and so on."
... or store the epoch number as part of the index.

Branching factor of a B-tree is variable in a range, in Rust BTreeMap the range is [5, 11].

p87, multi-column indexes
One possible solution to multi-dimensional queries in relational databases is data cube, which is
standardized in ISO SQL 2018.

p95, Column-Oriented Storage
curiously akin to Entity Component System, in which components of objects rather than objects
themselves are stored together

p113, "if an attacker can get your application to decode an arbitrary byte sequence, they can
instantiate arbitrary classes, which in turn often allows them to do terrible things such as
remotely executing arbitrary code [6, 7]"
- [6]: CVE-2015-7501, Java, serializing / deserializing certain objects invokes methods through
    runtime reflection which can be exploited to run arbitrary code with forged payload
- [7]: CVE-2013-0156, Ruby, YAML.load occasionally evaluates serialized string which may include
    arbitrary code wrapped in `eval` function call
Both cases the vulnerability originated in lack of distinction between data and program in the
language and badly written serialization library, hence
> "For these reasons it’s generally a bad idea to use your language’s built-in encoding for
> anything other than very transient purposes"
doesn't necessarily apply to something like Bincode. In the Ruby case it's not even built-in
encoding, YAML is developed independently and had seen wide adoption since its early days.

[4] Frank McSherry, Michael Isard, and Derek G. Murray: “Scalability! But at What
COST?”
Hilarious paper presenting two main points:
1.  many workloads scales very well only because they are not optimized, after optimization the
    their performance no longer scales beyond ~10 cores
2.  many distributed algorithms despite scales very well is not more efficient than a simple
    single-threaded algorithm to begin with, not even with unbounded number of nodes
A reproduction conducted in 2019 (http://vaastavanand.com/blog/2019/Reproduction-Cost/) shows
that the single-threaded algorithm outperformed distributed algorithms even more due to improved
memory handling in Linux and better hardware

[23] Douglas B. Terry: “Replicated Data Consistency Explained Through Baseball”
Given 6 consistency model in partial order:
    Strong Consistency: See all previous writes.
    Bounded Staleness: See all “old” writes.
    Consistent Prefix: See initial sequence of writes.
    Monotonic Reads: See increasing subset of writes.
    Read My Writes: See all writes performed by reader.
    Eventual Consistency: See subset of previous writes.
where Strong Consistency is the absolute strongest,  Eventual Consistency is implied by all other
models, Bounded Staleness after a delay converges to Strong Consistency hence implies all others

The algorithm presented in the text is a variant of the dotted version vectors set (DVVSet)
operating on a single replica.
- https://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf
- https://github.com/ricardobcl/Dotted-Version-Vectors
The code (in Erlang) is barely documented, the company operating Riak went out of business in
2017, Amazon doesn't seem to be using version vectors any more since 2015

p208, Partitioning Secondary Indexes by Term
A discussion on this topic in Berkeley CS186 : https://www.youtube.com/watch?v=FNhJXpcc3I4,
partitioning indexes by terms can be a very bad idea since most human behaviors follow the Zipf
distribution: naturally 80% accesses will be on 20% terms