// solutions to practice exercises:
// http://os-book.com/OS9/practice-exer-dir/
// whenever possible C programming assignment will be done in Rust

1.1
as stated in the text,
    "In general, we have no completely adequate definition of an operating system."
more or less an operating system has to
    1.  provide an interface of hardwares to softwares (may not be the case for embedded systems)
    2.  run the user applications in a safe manner (again may not be the case for embedded systems)
    3.  manage hardware resources

1.2
1.  when strictly uniform performance is of importance
    e.g. the operating system has to perform exactly the same on different hardwares, maybe for real-time purpose
2.  for security reasons
    e.g. the recent Intel CPU exploits which operating systems sacrifices ~15% performance to patch
3.  to provide a backward-compatible user interface to softwares
    the operating system have to support legacy softwares and run in a mode designed for hardwares decades ago 
all these "waste" are necessary to fulfill their design requirements

1.3
the running time of all the instructions must be deterministic, which means:
    GC is almost impossible: the operating system cannot randomly pause for a milliseconds and collect garbages
    the language in use must have a very strict semantic model, mapping program to instructions in a well-defined manner
    some probabilistic algorithms and data structures cannot be utilized, e.g. hashtable

1.4
should:
    web browser is an absolutely necessary utility which should be provided by an operating system out-of-box
    compiling an entire web browser is both painful and difficult, web browsers are usually distributed in binary
shouldn't:
    it isn't really part of an operating system, web browser definitely doesn't run in kernel mode
    for linux distros most of their users should know how to fetch a web browser with wget or curl

1.5
user applications cannot run kernel mode privileged instructions directly which may potentially interfere the operating 
system and other user applications
they may only delegate access to these instructions to the operating system by means of well-defined syscalls
so these syscalls can be analyzed and verified by the operating system in the context of processes

1.6
a.  privileged, otherwise a user application can hold the CPU forever
b.  not privileged
c.  privileged, otherwise user applications can interfere with each other unchecked
d.  not privileged, by design
e.  privileged, otherwise a user application can deny syscalls from other applications and hold the CPU forever
f.  privileged, hardware is managed by the operating system, not directly by the user applications
g.  privileged, otherwise renders the whole dual-mode system useless
h.  privileged, IO devices are managed by the operating system, user applications should use syscalls

1.7
1.  the operating system, loaded into memory by the firmware on startup from secondary storage, cannot be modified by 
    the operating system itself, i.e. no update
2.  the protection is not complete: an operating system is not entirely static, it has to hold dynamic memories 
    for e.g. file system

1.8
ring -3: Intel ME, a separated chip beside Intel CPU which control and monitor the entire computer from beneath
ring -2: processor microcode, under machine code instructions, the real instructions running on the chip
ring -1: hypervisor of the virtual machine environment, manage multiple virtualized operating systems   
ring 0: kernel, operating system

1.9
starting from a time set by the user or synced from a remote server:
    the process asks the kernel to wake it a fixed time later by a syscall and go to sleep
    the operating system schedules the process to run after the fixed time
    the process upon wake up and increment the time by the fixed time

1.10
cache is useful due to the fact that:
    they are faster in term of access time compared to the storage on levels below
    by caching multiple small read / write can be performed in batch, possibly extending the lifetime of the storage 
    if it can only survive a finite time of read / write operations
cons: caching complicates access to the storage, also cache invalidation is one of the only two hard things in compsci
even if the cache is as big as the storage device, it may not be persistent, the content still have to be written to the 
storage device before power off

1.11
in client-server distributed systems hosts either generate or satisfy requests, in peer-to-peer distributed systems
every host do both of them

1.12
a.  1.  without proper isolation one user may have access to all the sensitive contents belongs to another user
    2.  critical failure of one user process may affect or even terminate other processes 
b.  virtualization may be able to provide the security, but in practice there's always another exploit yet to be found

1.13
a.  CPU, memory, storage devices
b.  CPU, memory, IO devices, network links
c.  (in addition to workstations) battery 

1.14
1.  when the user only use no more than a fraction of the hardware capacity, part of a time-sharing system can be 
    rented instead of an entire PC or workstation
2.  when the user works in a group and have to share read / write access to some files within the group, it's cheaper to 
    work on a time-sharing system then doing so via network links

1.15
symmetric: 
    all CPU cores are equal in functionality, with the same amount of SRAM cache, computing power and access to the 
    main memory, tasks are distributed in software level as well as communication between cores
    common design of desktop CPUs
asymmetric: 
    CPUs have different functionality: a main CPU controls how work is distributed among worker CPUs
    software software communicates solely to the main CPU
    common design of mobile CPUs
pros (compared to multiple single-processor PC):
    cheaper, no duplicated IO device and IO bus
    communication / memory sharing among processors are faster by magnitudes 
    easier to program: just spawn threads and the operating system can distribute them evenly among processors
cons:
    it is a single PC with a single set of IO device at the end, cannot be used by two people at the same time

1.16
instead of multiple processors managed by a single operating system, clustered systems "are composed of two or more 
individual systems—or nodes—joined together"
hardware: a network, wired or wireless
software: a distributed operating system, running on hosts and monitors each other

1.17
1.  duplicate each write to the two nodes, distribute reads evenly, higher availability, half efficiency
2.  distribute write evenly between two nodes, properly guide reads to the correct node (e.g. by DHT)
    full efficiency, a hardware failure permanently wipes data

1.18
a network computer (thin client) passes most of its tasks, which would be computed locally by a traditional PC, to a 
remote server assigned to it
by handing over its tasks, network computer consumes less energy thus has longer battery lifetime
if the data is stored in the server as well, users may access their data from different terminals seamlessly

1.19
to inform the CPU about a software / hardware event so it can handle it
traps are software generated interrupts, indicating either an software error (e.g. divide by zero) or a request of 
operating system service (syscalls)

1.20
a.  CPU sets up buffers, pointers and counters for the DMA controller, which copies a whole block of data into the
memory accordingly, meanwhile the CPU can do something else
b.  by a hardware interrupt
c.  thanks https://en.wikipedia.org/wiki/Direct_memory_access#Cache_coherency
    the memory transfer is invisible to the CPU before completion, DMA may cause cache incoherency between CPU cache and 
    the main memory 

1.21
the published instruction sets may be an abstraction over the real instructions running on the hardware (microcode), 
hence a dual-mode instruction set can be build on a mode-less hardware
such an architecure may be exploitable to adversaries with physical access to the computer

1.22
to better handle the typical computing tasks: in practice user applications works on both shared and isolated memories

1.23
depends on the memory ordering of read / write accesses, a write operation performed by one processors may or may not 
be visible to other processors immediately
refer https://doc.rust-lang.org/stable/std/sync/atomic/enum.Ordering.html

1.24
a.  DMA may perform memory write temporarily invisible to CPU and cache
b.  different cores may perform independent read / write thus have different cache before synchronization
c.  same to multiprocessor

1.25
dual-mode instructions
memory access is privileged instruction, user applications can only perform memory access through syscalls, operating 
system maintains memory region of each process, upon receiving a syscall examines if the process is accessing its own 
memory or not, if not return the the infamous segmentation fault error to the user application

1.26
a.  LAN, all devices are physically reachable by a network administrator
b.  WAN
c.  WAN, a neighborhood in general is not an organization

1.27
limited power supply
limited computing power
different IO devices (touch screen instead of keyboard & mouse)
higher requirement of stability (phones are rarely turned off)

1.28
higher availability: client-server architecure has a single point of failure which is the server
better scalability: peer-to-peer architecure in nature is more scalable compared to extending the capacity of a server 

1.29
file distribution (e.g. bittorrent)
video streaming 
network traffic tunneling (e.g. TOR)

1.30
pros:
    more participants, earlier bug detection, more agile response to needs (for developers)
    lower cost (for consumers)
    provides learning material to students
cons:
    bigger attack surface
    copies cannot be sold

2.1
provide an compatible and easy-to-use interface to user softwares and higher layer system components
hide the real implementation of system functionalities which is subject to change

2.2
// section 1.6
create and deletion
suspension and resumption
synchronization
communication
deadlock handling

2.3
// section 1.7
keeping track of which parts of memory are currently being used and who is using them
deciding which processes (or parts of processes) and data to move into and out of memory
allocating and deallocating memory space as needed


2.4
// section 1.8
free space management 
storage allocation
disk scheduling

2.5
to provide a programmable, concise and unambiguous user interface to run system and user applications
it's not implemented as a module of the kernel because it doesn't have to, a shell can be built on top of syscalls

2.6
fork() to create a process inheriting the stack of the current one

2.7
enhance modularity of the operating system, part of the operating system can be built upon the kernel instead of in it

2.8
modularity, the operating system can be implemented, reasoned and debugged one part of a time
but layered approach increases the overhead of syscalls

2.9
GUI
    human friendly access to user and system programs
    a user program in Linux land but a system program in Windows and OSX
    in a closed-source OS, the GUI usually is hard-coded into the system
program execution
    OS essential
    user program cannot access the layer under syscall
IO operation
    OS essential
    user program cannot access the layer under syscall
file system manipulation
    organize file in a human readable way
    it must be part of the OS, user program cannot define their own flavor of file system on the one provided by the OS
resource allocation
    OS essential
    kind of doable in user land if the OS exposes lower level syscalls to memory management functions
    earlier version of Rust used a custom memory allocator instead of the OS default

2.10
in that way the OS doesn't have to be loaded into the main memory
those hardwares simply have no enough memory to load the system

2.11
operating systems write their location on the disk to a special boot block on the disk during installation
on startup the boot loader reads these locations then let the user choose one from them

2.12
1.  UI and exposed API: load, IO, file system, communication, error detection
2.  internal system functions: resource allocation, resource accounting, memory protection
functions in the first category is visible to the user in form of exposed API and syscalls
functions in the second category is not visible but a promise the OS makes to the user

2.13
1.  put in a predefined sequence of registers, e.g. first few parameters in Linux ABI
2.  pushed to stack, e.g. after a few parameters in Linux ABI
3.  stored in a table in the memory

2.14
build the program with debug symbols, let the operating system interrupt the program frequently with a timer, record
where the execution is each time the program is interrupted
without time profiling optimization of a program of decent complexity is nearly impossible

2.15
// section 1.8.1
creating and deleting files
creating and deleting directories
file and directory manipulating primitives
mapping files onto secondary storage (mmap?)
backup to stable storage media

2.16
pros:
    these two concepts share a lot of resemblance
    a common API to both of them simplifies the system design and its interface
cons:
    not all file operations are possible to all devices
    e.g. seek a tty device results in an error
    certain devices are too danger to be manipulated as a file, pipe something to /dev/hda will wipe the boot block

2.17
possible if the default one is implemented in user land, i.e. all it does is call system programs

2.18
message passing: safer with bigger overhead and requires extra memory
shared memory: faster but must be done right carefully or will cause data race / deadlock

2.19
like any other program, the resulting operating system will be more configurable

2.20
device driver and memory management
memory management must be built upon drivers, but drivers may also need access to the memory

2.21
all but the bare minimum functions of the operating system is implemented as separate programs
user program requests services from the kernel
which in turn passes these requests to the corresponding module program
kernel components in microkernel architecure communicates by inter-process communication, much slower than function
calls in the same program

2.22
so these functions can be implemented and compiled separately and dynamically
installation of a new device can be done without recompiling or even restarting the system

2.23
they are both mobile operating system, serving roughly the same set of hardware and market 
iOS is closed-source, Android is partially open-source

2.24
https://web.archive.org/web/20080604070631/http://blogs.sun.com/jrose/entry/with_android_and_dalvik_at
main reason listed: GPL of openJDK, power consumption of JVM, efficiency of assembly v.s. Java bytecode

2.25
https://www.semanticscholar.org/paper/An-Overview-of-the-Synthesis-Operating-System-Pu-Massalin/c8f49d5d94e1f9adf608b7c99e1e731c2381d82a
Factoring Invariants method
    if a system service is called frequently with the same parameters, the execution path of the call is cached and
    carried out next time the same service is called
Collapsing Layers method
    lower layer of services can be invoked directly in execution
Executable Data Structures method 
    traversal order is stored alongside the data in data structures
faster syscalls in exchange of less flexible operating system architecure

2.26
./OS/posix-file-copy
sudo dtrace -n 'syscall:::entry /execname == "posix-file-copy"/ { @[probefunc] = count(); }'
dtrace: description 'syscall:::entry ' matched 535 probes
^C
  __mac_syscall                                                     1
  access                                                            1
  bsdthread_register                                                1
  exit                                                              1
  fcntl                                                             1
  getrlimit                                                         1
  issetugid                                                         1
  shared_region_check_np                                            1
  sysctlbyname                                                      1
  thread_selfid                                                     1
  close                                                             2
  csops_audittoken                                                  2
  fcntl_nocancel                                                    2
  fsgetpath                                                         2
  fstat64                                                           2
  getentropy                                                        2
  getpid                                                            2
  proc_info                                                         2
  read_nocancel                                                     2
  write                                                             2
  ioctl                                                             3
  read                                                              3
  csrctl                                                            4
  open                                                              4
  mprotect                                                         10
  stat64                                                           42

3.1
PARENT: value = 5
child process inherits a copy of stack of the parent process, modification in the child process will not reflect to the 
parent process

3.2
8

3.3
context switching 
short-term process scheduling  
accounting of process memory and inter-process communication

3.4
a special syscall switches the CPU to the other register set
some register set has to be swapped out to the memory to make room for the new context

3.5
only c. shared memory segments, others are copied

3.6
similar to the design of TCP
=>  request
<=  process call
    ACK (lost)
=>  request (resend)
<=  duplicate sequence number, ignored
    ACK
=>  ACK received

3.7
retransmission

3.8
short-term scheduling:
    controls which process in the ready queue could run and allocates CPU time to it
    executes once every ~100ms
medium-term scheduling:
    controls which process should be kept in memory 
    swaps a process out from memory is it's waiting on an IO event or others
    executes on every major IO event
long-term scheduling:
    controls in which order pooled processes could run
    executes every time a process terminated

3.9
saves the context of the current process to its PCB structure
loads the context of another process from its PCB structure

3.10
// from a fresh WSL debian
init(1) -> init(2)
init(2) -> bash
bash -> ps

3.11
when a process is terminated without waiting on its child processes, its child processes become orphans
the OS assigns init as the new parent of these orphan processes
init calls wait periodically so these orphan processes can be terminated on completion

3.12
16

3.13
in the child process if the call to fork succeeded

3.14
A: 0
B: 2603
C: 2603
D: 2600

3.15
ordinary pipe:
    message passing between parent and child processes
named pipe:
    abstract over the functionality of some program to provide an standard file interface to other programs
    e.g. a pipe that compresses the data passed to it and store them in a file
        // https://en.wikipedia.org/wiki/Named_pipe
        mkfifo my_pipe
        gzip -9 -c < my_pipe > out.gz &

3.16
at most once:
    an RPC service on an embedded system controlling a light bulb
    the bulb blinks instead of being switched on / off
exactly once:
    a distributed file system
    a write operation may be lost due to connection failure
any use case of UDP is also a use case of unreliable RPC

3.17
CHILD: 
    0, -1, -4, -9, -16
PARENT:
    0, 1, 2, 3, 4

3.18
a.  synchronous communication:
        if blocks on both ends the messages are passed from producer to consumer directly, no buffer required
        same as other blocking operations wastes cycles
    asynchronous communication:
        easier to use for programmers 
        the messages have to be buffered somewhere
b.  either the programmer or the kernel has to carry the burden of buffering
c.  extra memory copy & occupation v.s. danger of dangling pointers & data race
    OS must be able to mark memory as shared in the latter case
d.  fixed-sized messages: easier to implement but harder to use
    variable-sized messages: the opposite

3.19
./OS/process/zombie-child
% ps -l
  UID   PID  PPID        F CPU PRI NI       SZ    RSS WCHAN     S             ADDR TTY           TIME CMD
  501  2037  1916     4006   0  31  0  4297288   2136 -      Ss                  0 ttys001    0:00.03 /bin/zsh -l
  501  2279  2037     4006   0  31  5  4268544    740 -      SN                  0 ttys001    0:00.05 target/debug/zombie-child
  501  2289  2279     2006   0   0  5        0      0 -      ZN                  0 ttys001    0:00.00 (zombie-child)

3.20
// skipped, would be a simple wrapper around a hash set in this stage

3.21
./OS/process/collatz-child

3.22
./OS/process/collatz-child-shm
apparantly there's no way to list and remove shared memories in OSX which one forget to unlink

3.23 - 3.25
// skipped, entry level application layer programming

3.26
./OS/process/case-reverse-pipe

3.27
./OS/process/file-copy-pipe