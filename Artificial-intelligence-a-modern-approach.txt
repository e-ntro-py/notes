1.1
a.  ability to act rationally based on knowledge
b.  intelligence originates not in biomass but in artifacts
c.  actor
d.  make near optimal decisions under certain criteria
e.  inference correct conclusions given a set of facts

1.2
https://www.csee.umbc.edu/courses/471/papers/turing.pdf
The Theological Objection:
    have no familiarity in christianity
    by my buddhist grandma, even the most insignificant kind of bugs have souls equal to human's
    so why not intelligent machines
The "Heads in the Sand" Objection
    this idea is even stronger today fueled by 70 years of sci-fi movies and literatures since then
    threat of a possible "AI domination" scenario is unlikely to stop the creation of AI (if ever possible)
    similar to nuclear weapons, AI technology is too much an advantage to any major power
The Mathematical Objection
    machines cannot solve the halting problem for certain, yet there's no proof whether human can do it better
    modern compilers can sometimes detect infinite loops which are unobvious to human eyes
The Argument from Consciousness
    seems to be the most relevant objection today and Turing's refutations on this topic were quite weak
    the idea was later expanded by the Chinese room argument
    recent breakthrough in ML and AI research made machines more rational, but not necessarily more humanly
Arguments from Various Disabilities
    either solved by now or not falsifiable at first place
Lady Lovelace's Objection
    if creativity on music composing or literature writing can be specified in terms of scores
    ML algorithms can train a machine to do it
    this objection lands more on ambiguity in human feelings / languages than ability of machines
Argument from Continuity in the Nervous System 
    no idea 
The Argument from Informality of Behaviour 
    AI today is already more error-prone than human while e.g. driving a car
The Argument from Extrasensory Perception
    can't believe they took ESP into consideration seriously
    was that common back in 1950s?
it turns out unskilled interrogator is too easy to fool:
    "Artificial Stupidity", The Economist, 324 (7770): 14, 1 August 1992
at this rate no one knows what will possibly happen in 50 years 

1.3
it's rational in the sense that it's based on practical reasons instead of emotions
it's not intelligent as it's not a decision by reasoning

1.4
IQ test is designed for normal human beings, not machines on a special task
the microworld of IQ test is overly restrictive

1.5
10^4 / 10^-3 = 10^7
human power: 10^14

1.6
1.  people lies for various reasons
2.  people who lacks certain knowledges cannot express their thought and emotion correctly
3.  people with satisfactory knowledge of thought and emotion is a biased sample

1.7
a.  pattern recognition for non-natural patterns (artifical barcodes)
b.  pattern recognition (NLP) & decision making (order of entries by preference / collected browse histories)
c.  pattern recognition for natural patterns (human voice)
d.  decision making

1.8
these computational models immitates result of human evolution instead of human knowledge
people don't have to understand the ATP cycle to lift and get fit

1.9
self-preservation as a population
by natural selection, entities without the urge of self-preservation are more likely to be eliminated by the environment
and in most case self-preservation is considered rational

1.10
both the theory and the realization of the theory should be considered AI
recent boom in ML is mostly boosted by powerful video cards 

1.11
the latter is true in the same way to 
"human thoughts are just a bunch of electrical and chemical signals being tossed around inside the brain"
thus the first sentence cannot be derived from the latter

1.12
the latter is not true, human thought and behavior is not that deterministic by gene

1.13
same to 1.11

1.14
List of entries not possible yet:
    h:  NLP or the ability of catching fuzzy ideas as "funny" is still lagging behind other aspects
    k:  not heard, but AI can help surgeons perform better
        by https://publishing.rcseng.ac.uk/doi/pdf/10.1308/rcsbull.2017.87, better computer vision is the missing piece

1.15
//  skipped

2.1
consider a vaccum cleaner with limited battery, in an environment where dust is generated randomly over time
performance is again measured by how clean the floor is on average 
if T is short compared to the battery capacity
the cleaner may choose to search very actively, consume more energy than optimal in the first T time steps
and do no work at all afterwards 

2.2
a.  there are 4 cases for the initial environment, 2 cases of initial place of the vaccum cleaner
    4 * 2 = 8 inital cases in total, where half the cases are symmetric
    assume the cleanliness is asserted at the start of each time step 
    A: Clean, B: Clean, Start: A,
        performance measure is 2000 for any agents
    A: Dirt, B: Clean, Start: A,
        the agent cleans dirt in square A in time step 1, move back and forth afterwards
        performance measure is 1999
        1999 is the optimal performance as the dirty square cannot be cleaned before time step 1
    A: Dirt, B: Clean, Start: B,
        the agent moves to square A at the end of time step 1, clean square A in time step 2
        performance measure is 1998
        1998 is optimal as any agent needs at least 2 time steps to move and clean the dirt in square A
    A: Dirt, B: Dirt, Start: A,
        1: clean A, 2: move to B, 3: clean B
        performance measure is 1996
        1996 is optimal as any agent needs at least 3 time steps to clean the two squares
b.  same to figure 2.3 but stop moving when no square is dirty
    if the agent can observe the cleanliness of both squares, no internal state required
    otherwise the agent has to remember the cleanliness of another square
c.  it may be beneficial to learn the dirt distribution and the geography of the room
    dirts will be cleaned earlier if the agent returns to the square with a highest posibility to generate dirt

2.3
a.  false, the vaccum cleaner agent in figure 2.2 is perfectly rational despite sensing only partial information
b.  true, an environment in which a button should be pushed when two parts are defected in a row
c.  true, a vaccum cleaner world as figure 2.3 in which no dirt are ever generated
d.  false, agent function always takes sequence of percepts, while agent program may be pure reflex
e.  false, it may be phisically impossible due to limitation on storage or computation power
f.  true, where the performance measure is independent to the actions of agents
g.  true, the vaccum cleaner agent in 2.2.b is also rational in the world defined in figure 2.3
h.  false, an agent that never clean squares cannot be rational in the vaccum cleaner world, with sensor or not
i.  false, it's logically impossible: what will happen when two of such agents play against each other?

2.4
a.  playing soccer (as a single player):
        P:  (depends on position) goals, assists, pass success rate, ...
        E:  position, momentum, ... of other players, ball, judges, ...
        A:  all possible moves of a human being
        S:  visual, sound and physical contact
b.  subsurface ocean of Titan (as a rover / submarine):
        P:  completeness and accuracy of aquired data, project cost, (if manned) casualty
        E:  Titan (atmosphere, climate, marine condition, ...)
        A:  sampling devices, thrust, ...
        S:  visual inputs
// skipped

2.5
agent function:         formal definition of the performance logic of an agent
agent program:          implementation of an agent function
autonomy:               ability to complete tasks / make decisions under no supervision
reflex agent:           agent whose action is independent to history of percepts
model-based agent:      agent which simulates unobservable part of environment as interal states from percepts
                        and make decision based on those simulations
goal-based agent:       agent which asserts and changes its actions by a binary performance measure (goal / defeat)
utility-based agent:    agent which asserts and changes its actions by a performance measure function
learning agent: agent   agent which asserts and improves its actions from experiences

2.6
a.  let F be an reflex agent function, P be an agent program implementing F
    let P' be a program that on a percept:
        runs P twice, return the result of the second run
    by definition P' is also an implementation of F
b.  none, ignoring storage and computation limitations, the table-driven method is always possible
c.  yes or no according to a more precise definition of randomized agent function / program
d.  infinite, there are infinite possible implementations of a trivial agent which yields a single action forever 
e.  no, by structure of the program it will only emit an action on percept inputs
    speed up the machine only boost the reaction speed of the agent
    if the agent is a valid implementation of the agent function at the first space it have to wait more

2.7
a.  function GOAL-BASED-AGENT(percept) returns an action
        persistent: state, the agent's current simulation of the world
                    model, the simulation model used to update state
                    action, the most recent action taken
                    DESIRABLE, boolean function with built-in goal
        state <- UPDATE-STATE(state, action, percept, model)
        for action' in all feasible actions
            // estimate the impact of a chosen action
            state <- UPDATE-STATE(state, action', NULL, model)
            if DESIRABLE(state)
                return action'
b.  function UTILITY-BASED-AGENT(percept) returns an action
        persistent: state, the agent's current simulation of the world
                    model, the simulation model used to update state
                    action, the most recent action taken
                    UTILITY, function from state to a performance measure
        state <- UPDATE-STATE(state, action, percept, model)
        for action' in all feasible actions
            // estimate the impact of a chosen action
            state <- UPDATE-STATE(state, action', NULL, model)
            if UTILITY(state) is maximized
                return action'

2.8
./AI/vaccum_cleaner

2.9
./AI/vaccum_cleaner
World: TwoSquare { left: Clean, right: Clean }, agent: ReflexCleaner { pos: Left }, Score: 2000
World: TwoSquare { left: Clean, right: Clean }, agent: ReflexCleaner { pos: Right }, Score: 2000
World: TwoSquare { left: Clean, right: Dirt }, agent: ReflexCleaner { pos: Left }, Score: 1998
World: TwoSquare { left: Clean, right: Dirt }, agent: ReflexCleaner { pos: Right }, Score: 1999
World: TwoSquare { left: Dirt, right: Clean }, agent: ReflexCleaner { pos: Left }, Score: 1999
World: TwoSquare { left: Dirt, right: Clean }, agent: ReflexCleaner { pos: Right }, Score: 1998
World: TwoSquare { left: Dirt, right: Dirt }, agent: ReflexCleaner { pos: Left }, Score: 1996
World: TwoSquare { left: Dirt, right: Dirt }, agent: ReflexCleaner { pos: Right }, Score: 1996

2.10
a.  it cannot
    when there's initially no dirt in the environment, the simple reflex agent will move mindlessly
    an agent that does nothing at all will achieve score 2000 instead of 1000 by the simple reflex agent
b.  refer 2.2
c.  refer 2.2

2.11
./AI/vaccum_cleaner
a.  it cannot, a simple deterministic agent will only clean dirt on a fixed path
    if the initial dirt distribution generates no dirt along that path, no dirt will be cleaned by the reflex agent
    another agent may outperform it by cleaning even one square of dirt (by chance or better perception)
b.  it's possible as stated in part a
    results are concluded in part d
c.  a spiral environment
    map legend:
        #: obstacle
        %: dirty
         : clean
        @: start position of agent
    ##########
    #%%%%%%%%@
    #%########
    #%#%%%%%%#
    #%#%####%#
    #%#%#%%#%#
    #%#%%%%#%#
    #%######%#
    #%%%%%%%%#
    ##########
    after cleaning the square, the random cleaner will bump into walls frequently
    dispite there are only one correct direction to progress
d.  a stateful agent that records the visited part of the environment, decide the next moving direction by
        1. prioritize unvisited squares
        2. choose a random non-obstacle square if surrounded by visited squares
    all environments are 10 x 10 rectangles of clean and dirty squares or obstacles
    a square has
        1/8 chance to be an obstacle
        3/8 chance to be dirty
        4/8 chance to be clean
    score is measured by number of clean squares over a time period of 1000
    % ##%%# %%
    # # % % %#
    %%  %  %
    %   #  %
    %  #    %
    # %%#  %
    %###%#%###
    %% %% % #
    %#%#%  % #
    % #   #
    Bot position: (1, 0)
    RandomCleaner Score: 68262
    Stateful BumpCleaner Score: 73193
    #  %#% %
    % %# %
    %     %%
    # % %#% %%
    %% % #% %
    ## #%   %%
    % #% #%% %
    # % %%%
    % % %  %
    %#%% % # %
    Bot position: (4, 1)
    RandomCleaner Score: 70134
    Stateful BumpCleaner Score: 78198
    %  #  # %
    % # %  %
    ####  % %%
    %
    %%   %%%
    % #%#%% %
    #  %% %
    %%   % %
    %     %#%#
    ##%% % % %
    Bot position: (4, 8)
    RandomCleaner Score: 74664
    Stateful BumpCleaner Score: 80026
    %# %%  %#
    # #%%%#
    %  %#%%%#
    #   %  %
    %%# %
    %% #%%%%%%
    %%#%  %%#
    %%%%   %%%
    %%   %% %
    %% %% #%
    Bot position: (4, 3)
    RandomCleaner Score: 73039
    Stateful BumpCleaner Score: 82044
    #    %
    # %#% #%%#
    %%% % %%
    % % % % %
        # #  %
    %%% #%
    % % #  % #
    %%# %%
    %#%  %%%
    #  %   %
    Bot position: (6, 6)
    RandomCleaner Score: 74993
    Stateful BumpCleaner Score: 80545
    a cleaner cannot be perfectly rational without full percept of the environment

2.12
the agent in 2.11.d is already based on bump detection
if the bump detector fails, the cleaner should fall back to randomized reflex mode

2.13
a.  repeat the Clean action until the the dirt sensor gives "clean" twice in a row
b.  again a cleaner cannot be perfectly rational without full percept of the environment

3.1
without a goal, no action or state is rationally better than others, problem formulation is meaningless

3.2
let w be width of the maze, h be height of the maze
let i be the number of intersections
a.  4wh (4 orientations for each position)
b.  4i (4 orientations for each intersection)
c.  i, no need to keep track of orientations
d.  how the robot accelerate
    how the robot is controlled remotely
    position of the robot in the maze is in fact continuous 

3.3
a.  let G be a indirected graph
    each city is a node of G
    each road is an edge of G
    the state space is tuples of nodes (i, j) where i, j ∈ G.N
    starting state is (i0, j0) for some i0, j0 ∈ G.N
    for each state (i, j), an action is defined with 
        result: (i', j') where (i, i'), (j, j') ∈ G.E
        cost:   max(d(i, i'), d(j, j'))
b.  (i) is not admissible:
        let d(1, 2) = 1, d(2, 3) = 1, D(1, 3) = 2
        given start state (1, 3), the optimal solution has cost 1 < 2 = D(1, 3)
    (ii) >= (i), nor is (ii) admissible
    (iii):
        let start state be (i, j), let C*(i, j) be cost of the optimal solution
        if there's no solution to this instance, C*(i, j) is virtually infinite, greater than D(i, j) / 2 
        if there's an optimal solution to this instance
        basic: 
            i = j, C*(i, j) = D(i, j) / 2 = 0
        induction (on length of optimal solution):
            let the next state in the solution be (i', j')
            the cost of the next action is max(d(i, i'), d(j, j'))
            tail of the solution must be the optimal solution to the subproblem (i', j')
            (or a better solution can be constructed by replace the tail with a better solution to (i', j'))
            by induction on number of actions of optimal solution, C*(i', j') >= D(i', j') / 2
            C*(i, j)    = C*(i', j') + max(d(i, i'), d(j, j'))
                        >= D(i', j') / 2 + max(d(i, i'), d(j, j'))
                        >= (D(i', j') + d(i, i') + d(j, j')) / 2
                        >= D(i, j) / 2  // apply triangle inequality twice
c.  if they cannot stay in a city for a turn (i.e. there's no zero-cost self-cycle for each node)
        for each bi-partite graph with partitions {A, B}, if i0 ∈ A and j0 ∈ B
        if (i, j) is a successor of (i0, j0), by definition of bi-partite graph, i ∈ B and j ∈ A
        similarly, if (i', j') is a successor of (i, j), i ∈ A and j ∈ B
        since A and B are disjoint, there's no solution to the instance
    otherwise the shortest path i ~> j must contain infinite edges
d.  G.E = {(1, 1), (1, 2)}, start state = (1, 2)
    successors of (1, 2) are (1, 1) and (2, 1)
    (1, 1) is a goal state where 1 is visited twice by the first friend
    (2, 1) is symmetric to (1, 2), any state from (2, 1) will visit at least one city twice

3.4
//  only half of the proof
//  complete proof can be found in A Modern Treatment of the 15 Puzzle, AF Archer 1999
//  http://www.cs.cmu.edu/afs/cs/academic/class/15859-f01/www/notes/15-puzzle.pdf
represent the tiles as an array in row-major order
the goal state is a sorted array of numbers [1 - 8, E], where E is the empty tile
let I be the number of inversions in the state
I mod 2 is invariant by legal moves:
    a horizontal move will not change I
    when a tile A is moved downwards to the empty tile:
        there are two tiles B and C between A and the empty tile in row-major order
        if there are k inversions among (A, B), (A, C), after the move there will be 2 - k inversions
        I changeed by (2 - k) - k = 2 - 2k, which is even
the goal state [1, 2, 3, 4, 5, 6, 7, 8, E] has I mod 2 = 0
another state [1, 2, 3, 4, 5, 6, 8, 7, E] has I mod 2 = 1, both partitions are nonempty
by CLRS, number of inversions can be computed by modified merge sort in O(nlgn)
treat E as the tile number 9, then deduct the inversions caused by 9 from the result
search algorithms introduced in this chapter can only find an instance unsolvable after exhausting the state space
which is n! / 2 for an (n-1)-puzzle, the program might only terminate after years given enough space

3.5
a queen located left to a column may attack at most 3 squares in the column
hence there are at least n - 3i possible squares on ith column with n rows
S(n)    >= Π(n - 3i)
S^3(n)  >= Π(n - 3i)^3
        >= Π(n - 3i)(n - 3i - 1)(n - 3i - 2)
        = n!
S(n)    >= n^(1/3)
when n = 30, S(n) >= 10^10, any n greater may exhaust the memory of a personal computer

3.6
a.  let G be an indirected graph
    G.V = {i | i is a region on the map}
    G.E = {(i, j) | i and j are adjacent on the map}
    state of the problem is an array of length <= |V| of c ∈ Z4
    where 1 - 4 indicates different colors
    start state is the empty array []
    a state [c0 .. ck] is valid if:
        assign each ci to vertex i, no (i, j) ∈ G.E has ci = cj
    goal state is a valid state of length |V|
    for a state [c0, c1 .. ci], a possible action is defined as:
        result: [c0, c1 .. ci, ci+1] which is valid
        cost: 0
b.  state: position of monkey and crates (may be continuous)
    initial state: implied by the description of the problem
    goal state: monkey with banana
    actions: climb / leave the crates, move the crates around, grab the banana
    cost: unclear
c.  state: a set of records
    initial state: the file of records
    goal state: a singleton set of record
    actions: for a set of records R:
        result: R' ⊆ R, the program outputs "illegal input record" when fed R'
        cost: depends on how the result is computed
d.  state: amount of water in three jugs
    initial state: three empty jugs
    goal state: there's exactly one gallon of water in one of the jugs
    actions: given w0, w1, w2 as amount of water in jugs, c1, c2 and c3 be their capacities
        result: set wi = 0, or
                set wi = ci, or
                for some i != j, set wi = 0, wj = max(cj, wi + wj)
        cost: 1

3.7
a.  both uncountable
b.  when there are obstacles between two points on a plane, instead of the shortest (straight) path, the robot should 
    bypass the obstacle by turn away from the shortest path as little as possible, in which case the optimality of 
    polygon vertices over point on polygon sides and middle of nowhere can be roughly explained by triangle inequality
    the state space now contains all vertices of obstacles and the start and goal points
c.  let G be an indirected graph
    G.V = {i | i is a vertex of an obstacle, the start point or the goal point}
    G.E = {(i, j) | the straight line between point i and j is not blocked by any obstacle }
    state: any i ∈ G.V
    start state: the start point
    goal state: the goal point
    possible actions from a point i:
        result: j for all (i, j) ∈ G.E
        cost: straight line distance between i and j
d.  simply shortest path from single vertex after formulation, can be easily solved optimally with linear time and space

3.8
a.  consider only graph G that, for each states V, there is a path from start state to goal state passing V
    let start state be s, goal state be g
    let (v, u) be any transition in the graph, let G' be G without (v, u)
    let Cm be the maximum cost of any simple path in G'
    assume an algorithm which didn't examine (v, u) gave an optimal solution to G' with cost C*
    if the cost of (v, u) < -2Cm + C*, construct a path s ~> v -> u ~> g where s ~> v and u ~> g are simple paths
    by definition cost of such a path <= 2Cm + c(v, u) < C*
    hence ignoring any single transition in the graph may result in suboptimal solution
    an optimal algorithm must examine all transitions in the graph
b.  it won't help
    if the negative-cost edge forms a negative cost cycle in the graph
    then there's no optimal solution to the instance
c.  the optimal cost of the instance can be arbitrary low, i.e. no optimal solution
d.  the mental gain from repeatedly visiting the same scenery is diminishing (for sane people)
    formally the cost of an action is not independent to the history of actions
    enrich the state space with history of actions / states
    adjust action costs according to the history to reflect the diminishing gain in reality
e.  drug abuse
    the cost of taking drugs may not be significantly negative
    but the cost of not to take drugs will increase overtime and for each action of taking drugs
    to a point the drug abuser have no other choice
    
3.9
a.  state:  a five-tuple (M, C, M', C', B), where M, C, M' and C' are integers indicating missionaries and cannibals
            B are a binary value representing the position of the boat
    start state: (3, 3, 0, 0, 0)
    goal state: (0, 0, 3, 3, _)
    action: transfer at most two people from one side of the river to another while keeping M >= C and M' >= C'
            if B = 0, only transfer from M, C to M' and C' is valid and vice versa
            cost is uniform
b.  ./AI/searching
    this side: 3M + 3C, other side: 0M + 0C, boat on: This side
    this side: 2M + 2C, other side: 1M + 1C, boat on: Other side
    this side: 2M + 3C, other side: 1M + 0C, boat on: This side
    this side: 2M + 1C, other side: 1M + 2C, boat on: Other side
    this side: 2M + 2C, other side: 1M + 1C, boat on: This side
    this side: 1M + 1C, other side: 2M + 2C, boat on: Other side
    this side: 1M + 2C, other side: 2M + 1C, boat on: This side
    this side: 1M + 0C, other side: 2M + 3C, boat on: Other side
    this side: 1M + 1C, other side: 2M + 2C, boat on: This side
    this side: 0M + 0C, other side: 3M + 3C, boat on: Other side
    without checking repeated space, the searching will loop forever
c.  some move in an optimal solution is anti-intuitive

3.10
state: vertex, atomic description of the moving parts of the environment
state space: G.V, set of all possible states
search tree: tree derived from the state graph during searching
search node: a data structure keeping track of extra information tied to a state
goal: the destination in the state graph
action: transitions / edges in the state graph
transition model: adjacency list from a vertex in the state graph 
branching factor: out-degree of a vertex in the state graph

3.11
world state: the state in reality, without abstraction
state description: abstracted world state percepted and emulated by the agent
search node: data structure keeping track of state descriptions and else in search algorithm
none of any two of the above terms are equivalent:
several world state may correspond to the same state descriptions
there may be a lot search node for a single state description

3.12
for a problem with |V| states and branching factor b
making composite actions of n actions will increase total transitions from |V|b to |V|b^n
while only speed up the searching n times at best
the cost is not justified by the return

3.13
basic: 
    the frontier contains only the initial state s, path to any other state passes the initial state
induction:
    let u be the state expanded next, u is removed from the frontier after the iteration
    let s ~> v be the path from initial state to an unexplored state before expansion
    if u is not on s ~> v, as u is the only state removed from the frontier, s ~> v passes a state in the frontier
    if u is on s ~> v
        if v = u, v is nolonger unexplored
        if v != u, the path is s ~> u ~> v, where u ~> v must pass a successor of u
        by the algorithm, all successors of u are added to the frontier

3.14
a.  false, depth-first search may be quick to find suboptimal solutions
    if the initial state has an immediate goal state successor with high cost
    depth first search may accidentally explore it first and terminate
    A* search will only explore it after all node with lower-cost is explored
b.  true, h(n) = 0 is an admissible heuristic for any problem with non-negative costs
c.  false, not after proper abstraction
d.  true, breath-first search is ignorant to costs
e.  false, obvious

3.15
a.  digraph {
        0 [label="1"]
        1 [label="2"]
        2 [label="3"]
        3 [label="4"]
        4 [label="5"]
        5 [label="6"]
        6 [label="7"]
        7 [label="8"]
        8 [label="9"]
        9 [label="10"]
        10 [label="11"]
        11 [label="12"]
        12 [label="13"]
        13 [label="14"]
        14 [label="15"]
        0 -> 1
        0 -> 2
        1 -> 3
        1 -> 4
        2 -> 5
        2 -> 6
        3 -> 7
        3 -> 8
        4 -> 9
        4 -> 10
        5 -> 11
        5 -> 12
        6 -> 13
        6 -> 14
    }
b.  BFS:
        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11
    depth-limited (3):
        1, 2, 4, 8, 9, 5, 10, 11
    iterative deepening:
        1,
        1, 2, 3,
        1, 2, 4, 5, 3, 6, 7,
        1, 2, 4, 8, 9, 5, 10, 11
c.  reverse transition model has branching factor 1
    the search will be trivial in reverse order
d.  see part e
e.  ./AI/searching

3.16
a.  state: a railway and a set of unconnected pieces
    start state: an empty railway and 32 unconnected pieces
    goal state: a railway with no overlapping and loose ends with no unconnected pieces
    action: plug one of the unconnected piece to a hole on the railway
            for unsymmatric pieces there are two ways to plug it to a hole
    cost: insignificant
b.  as all goal states are in the same depth (depth 32)
    DFS will be most memory-efficient without incurring suboptimal time complexity
    also there's no significant cost, hence no reasonable heuristic to guide the searching
c.  for there being no loose ends, the number of plugs and holes must match
    removing any one of the fork pieces then the instance won't meet the prerequisite above
d.  the railway under construction has at most 3 holes
    there are 12 + (16 + 2 + 2) * 2 = 52 ways to plug a piece to a hole
    the maximum branching factor is 52 * 3 = 168, with maximum depth 32 the state space is at most 168^32

3.17
a.  given a finite program instance, let the set of action costs be C
    number of subsets of C is also finite
    hence the minimum positive difference between the sum of any two subsets is greater than a constant ε
    in graph search, the cost of a path is the sum of a subset of C
    therefore each iteration of iterative lengthening search will increase the cost limit by ε
    let the optimal cost be C*, when the cost limit is smaller than C*, there's no solution
    the algorithm will retry with a greater cost limit
    when the cost limit is greater or equal to C*, given non-negative costs
    uniform-cost search, as an optimal search algorithm, will find the optimal solution
    as C* / ε is finite, the algorithm will definitely terminate
b.  with unit step costs, ε >= 1
    d iterations at most
c.  it depends on the minimum positive difference ε defind above
d.  ./AI/searching/ils

3.18
a state space with branching factor f in which all state at depth d is a goal state
DFS will always terminate in O(d) time, while IDDFS algorithm have to analysis Ω(f^d) states at least

3.19
//  skipped
//  tracing every link on a page is extremely complicated nowadays with all the front end arcane magics
//  the state space is infinite (dynamic generated pages)
astar with heuristic based on common parts of the url
one (cheat) strategy may be heading a search engine from the first page then search the url of the second page
bidirectional search is infeasible as there's no proper way to generate complete of a predecessor
even with a search engine (single page applications, js user interfaces e.g. React, etc.)

3.20
a.  state space is tiny, any algorithm will suffice
    a possible admissible heuristic is f(n) = dirty squares * 2 - 1
    each square requires at least two actions (move to and suck) to clean
    except the square under the cleaner which can be cleaned by a single action
    non-negative cost actions only, graph search is preferable
b.  %%%
    ...
    ...
    Cleaner: (1, 1)
    %%%
    ...
    ...
    Cleaner: (1, 0)
    %.%
    ...
    ...
    Cleaner: (1, 0)
    %.%
    ...
    ...
    Cleaner: (0, 0)
    ..%
    ...
    ...
    Cleaner: (0, 0)
    ..%
    ...
    ...
    Cleaner: (1, 0)
    ..%
    ...
    ...
    Cleaner: (2, 0)
    ...
    ...
    ...
    Cleaner: (2, 0)
c.  search cost is negligible in such a tiny state space (a few milliseconds at most)
    avarage cost of 1000 samples is 4.493
d.  the astar search agent is optimal
e.  state space has size 2^(n^2) * n^2, the search cost will dominate move cost quickly
    reflex agent will outperform the search agent for any moderately large n

3.21
a.  when the transition model has uniform cost for all actions
    g(n) = depth of the node n, the shallowest node will be expanded next
    that's exactly the behavior of BFS
b.  assume the depth of a node is stored in the node itself
    let f(n) = -n.depth, the deepest node will always be expanded next
    which is exactly the behavior of DFS
c.  when h(n) = 0, f(n) = g(n) + f(n) = g(n), as well as uniform-cost search

3.22
//  this line of the pseudo-code
//      (result, best.f) ← RBFS(problem, best, min(f.limit, alternative))
//  contains a very sneaky assignment to best.f
//  without this assignment the implementation will blow the stack up
./AI/searching/src/rbfs.rs
much slower
partially due to naive unoptimized RBFS vs A* from an optimized extern crate
also RBFS is a tree search, exploring much more redundant states compared to A*

3.23
//  skipped

3.24
start state: 0
goal state: 3
costs:
    0 -> 1: 0
    1 -> 2: 0
    0 -> 2: 1
    2 -> 3: 2
heuristics:
    1: 2
    2: 0
    3: 0
frontier = [1, 2] after expanding start state
g(2) + h(2) = 1 < g(1) + h(1), 2 will be expanded next
the path 0 -> 1 -> 2 will never be expanded as 0 -> 2 adds 2 to explored set

3.25
when w = 0, f(n) = 2g(n), the algorithm is uniform cost search, not complete in tree search
when 0 < w < 2, f(n) = (2 - w)(g(n) + w * h(n) / (2 - w))
the algorithm is A* search with heuristic w * h(n) / (2 - w)
depending on h(n), this algorithm may or may not be complete
when w = 2, f(n) = 2h(n), the algorithm is greedy best first search, not complete in tree search
when h(n) is admissible, for 0 <= w / (2 - w) <= 1, w <= 1, (w / (2 - w))h(n) is also admissible

3.26
a.  4
b.  4k in graph search
    2(k + 1)(k + 2) in tree search
c.  Θ(4^(x + y))
d.  2(x + y + 1)(x + y + 2)
e.  true (manhattan distance)
f.  all nodes in the rectance((0, 0), (x, y)), (x + 1)(y + 1) nodes
g.  true, shortest path p0 ~> p1 may only increase when some link is removed
h.  no, if there is a link ((0, 0), (x, y)) when |x| + |y| > 1, the heuristic is no longer admissible

3.27
a.  A(n^2, n) = (n^2)! / n!
b.  <= 5^n
c.  manhattan distance
    it cannot move more than one grid without another vehicle
d.  (i) is not admissible:
        when n = 2, Σh = 4 but the optimal solution has cost 2
    (ii) is not admissible:
        given a state:
            . 2 3
            . . 1
            . . .
        the goal state is:
            3 2 1
            . . .
            . . .
        max{h} = 2, but the state can reach the goal state in a single action
    (iii) is admissible:
        let s be an arbitrary state, s' be one of its successor
        let h = (h1 .. hn) be heuristics in state s, h' = (h1' .. hn') be heuristics in s'
        let hi = min{h},
            if the ith vehicle stay put, hi' = hi, min{h'} >= min{h}
            if the ith vehicle moves normally, hi' >= hi - 1, min{h'} >= min{h} - 1
            if the ith vehicle hops over the jth car, hj' = hj >= min{h}, min{h'} >= min{h}
        thus an action can at most deduce min{h} by 1
        the goal state has min{h} = 0, if (s0 .. sk) is an optimal solution, h(s0) <= k

3.28
a totally random heuristic can easily lead A* to suboptimal solutions
./AI/searching
the optimal solution has f(n*) = g(n*) + h(n*) <= C* + c
any node explored before the optimal solution must have f(n) <= f(n*) = C* + c
assume h(n) is non-negative, f(n) = g(n) + h(n) >= g(n), g(n) <= C* + c

3.29
h(n) <= c(n, a, n') + h(n')
for an arbitrary state n0, let (n0 .. nk) be an optimal solution
optimal cost is sum of action costs Σc(ni, ai, ni+1) = C*
for each pair (ni, ni+1), h(ni) <= c(ni, ai, ni+1) + h(ni+1)
    Σh(ni) <= Σ(c(ni, ai, ni+1) + h(ni+1))
    // all but h(n0) and h(nk) cancels each other
    h(n0) <= Σ(c(ni, ai, ni+1)) + h(nk)
    h(n0) <= C* + 0 = C*
the heuristic in exercise 3.24

3.30
a.  a relaxed version of TSP where the tour does not have to be a hamiltonian cycle
b.  no description for straight line distance as a heuristic function provided
c.  cities: random points from [0, 1]^2
    start city: one of the cities
    a state keeps track of the current position of the salesman and the traveled city 
d.  refer CLRS

3.31
moving a square to the blank square can at most fix one misplaced square
for a solvable puzzle
    4 5 3
    1 2 6
    7 8 .
h1 = 4, h2 = 4, Gaschnig's heuristic = 5, optimal solution has cost 16
if a square i is misplaced, it occupies the tile of another square j, which occupies tile of square k, ..
these misplacements therefore forms cycles
each misplacement cycle of length k requires k actions to fix if the blank square is on the cycle
otherwise k + 1 actions

3.32
//  skipped

4.1
a.  simple hill-climbing search
b.  BFS if no information are shared between threads
c.  first-choice hill climbing
d.  random walk
e.  random walk (with mutations instead of successors from actions)

4.2
change from 3.16:
when connecting the next piece to the track, the piece can be rotated by an angle a in the range [-10, 10]
an angle a is accepted as the next state with probability e^(a/T), where T = schedule(t) is a function on time

4.3
a.  ./AI/searching
    average cost ratio over 1000 samples is 1.2425902960619555
b.  // oddly nowhere in the paper mentioned the fitness function they used
    // skipped

4.4
//  8-puzzle cannot be fomulated as a local search problem
//  the goal state is obvious for 8-puzzle, only the path matters
over 1000 samples of eight queens:
Steepest ascent cost: 31.666097ms
Steepest ascent success ratio: 0.16
First choice cost: 33.931055ms
First choice success ratio: 0.157
Simulated annealing cost: 172.206779ms
Simulated annealing success ratio: 0.14
Random restart cost: 220.052079ms

4.5
there must be a persistent map of type (state, SearchResult) as global variable or object field
the resulting plan may be a DAG instead of a tree
SearchResult is a tagged enum with three variants:
    Failed: there's no goal state reachable from this state
    Success(Plan): a goal state is reachable from this state
assume Plan type is already a shared pointer to the real plan structure
function OR-SEARCH(state, problem, path) returns a conditional plan, failure
    if Success(plan) = map[state] {
        return plan
    } else if Failed = map[state] {
        return failure
    } else if state is on path {
        map[state] <- Failed
    } else {
        // this is the first time state is explored
        plan <- new shared pointer to a plan structure
        for each action in problem.ACTIONS(state) do {
            plan <- AND-SEARCH(RESULTS(state, action), problem, map)
            if plan != failure {
                map[state] <- Success([action | plan])
                return [action | plan]
            }
        }
        map[state] <- Failed
        return failure
    }

4.6
//  incomplete
labeling:
    the search result is now Success(Plan), Loop(Plan) or Failure
    stored along each state on the path is the plan of that state
OR-SEARCH:
    if a loop is detected, return Loop(plan) with plan stored on the path
    in for each action loop, return Loop(plan) if there's no acyclic plan, return Failure if there's no plan at all
    the extended path [state | path] now must contain a placeholder plan LoopPlan, i.e. [(state, LoopPlan) | path]
    the value of the plan is replaced with the computed acyclic plan (if any) on return
AND-SEARCH:
    if resulting plan on all branches are cyclic, return Failure

4.7
max{h*(s) | s ∈ b}
let the original problem be P, the sensorless problem be P'
assume there is a solution (a0 .. ak) for believe state b, s ∈ b
applying (a0 .. ak) on s must bring s to a goal state of P, otherwise b is not a goal state of P'
therefore (a0 .. ak) is also a solution to s, c(a0 .. ak) >= h*(s)

4.8
a.  let b ⊆ b', RESULT(b, a) = {s' | s' = RESULTp(s, a) and s ∈ b}
                            ⊆ {s' | s' = RESULTp(s, a) and s ∈ b'}
                            = RESULT(b', a)
    let G be the set of goal states in the original problem
    for a sequence of actions a = (a0 .. ak), let APPLY(b, a) be the result of applying a to b in order
    clearly APPLY(b, a) ⊆ APPLY(b', a)
    if a is a solution to b', APPLY(b, a) ⊆ APPLY(b', a) ⊆ G, a is also a solution to b
    let c ⊆ b ∪ b', RESULT(c, a)
        = {s' | s' = RESULTp(s, a) and s ∈ c}
        ⊆ {s' | s' = RESULTp(s, a) and s ∈ b ∪ b'}
        = RESULT(b, a) ∪ RESULT(b', a)
    hence APPLY(c, a) ⊆ APPLY(b, a) ∪ APPLY(b', a) for any sequence a
    if a is a solution to both b and b', a is also a solution to c
b.  if b is in EXPLORED, for all b' ⊆ b, a solution to b is also a solution to b'
    therefore it's not necessary to add b to the frontier
c.  store solved states along with their plans
    on start of OR-SEARCH(b, ..), if a superset of b is solved, return the plan associated with it

4.9
let initial state be {s1, s2}, 
RESULT(s1, a) = RESULT(s1, b) = RESULT(s2, a) = RESULT(s2, b) = g
c(s1, a, g) = c(s2, b, g) = 3, c(s2, a, g) = c(s2, b, g) = 1
c({s1, s2}, a, {g}) = (1, 3), c({s1, s2}, b, {g}) = (3, 1), the two costs cannot be compared
the interval case and the set case cannot be solved by A*, as the heuristic is not well ordered
//  thanks solution manual
by principle of optimality:
    An optimal policy has the property that whatever the initial state and initial decision are, 
    the remaining decisions must constitute an optimal policy with regard to the state 
    resulting from the first decision.
 if the total cost of a path is defined as the minimal cost of any physical realization of the whole path
as stated in the solution manual, this definition violates principle of optimality
however if the cost of an action defined as the minimal (maximal) cost of any physical realization of an action
A* will return optimal solutions
when defined as interval or set, the cost is not well ordered

4.10
./AI/and_or_search
there's no path from initial state to any of the goal state
digraph {
    0 [label="[1, 2, 3, 4, 5, 6, 7, 8]"]
    1 [label="[1, 3, 5, 7]"]
    2 [label="[2, 4, 6, 8]"]
    0 -> 0 [label="Suck"]
    0 -> 1 [label="Left"]
    0 -> 2 [label="Right"]
    2 -> 2 [label="Suck"]
    2 -> 1 [label="Left"]
    2 -> 2 [label="Right"]
    1 -> 1 [label="Suck"]
    1 -> 1 [label="Left"]
    1 -> 2 [label="Right"]
}

4.11
//  skipped

4.12
a.  a physical state is consisted of a configuration of the maze and the position of the agent
    percepts and the position of the agent filters the set of possible configurations
    there are 12 possible internal walls, i.e. the inital believe state contains 2^12 configurations
    2^(2^12) * 3^2 believe states in total
b.  four: {Up, Right}, {Up}, {Right}, {}
c.  each percept of a preciously unknown wall shrinks the size of the believe state to 1/2
    each of the four possible percepts at the inital state shrinks the size of the believe state to 1/4
    any believe state with believe set of size 1 is a goal state
    if the maze is connected, 2 * MST = 18 is an upper bound of the length of a tour
    the size of the plan is roughly 4^18

4.13
//  skipped

4.14
by the line
    if s' is a new state (not in untried) then untried[s'] ← ACTIONS(s')
each step adds four actions to the untried list 
each step consumes only one action, the untried list is never empty
the algorithm will never backtrack
if ACTIONS(s') is pushed to untried[s'] with a fixed order, the same action will be repeated over and over
the agent can only reach (x, 0) or (0, y) for arbitrary x or y
a random walk agent will be complete: at each step the agent takes a random possible action or backtrack by chance
the path reaching (1, -1) can be any path possible

5.1
let p' be the single agent search problem derived from OM and the original two-player problem p
p'.RESULT(s, a) = OM(p.RESULT(s, a))
p'.GOAL-TEST(s) = state s which maximizes the utility function in p
then this problem can be solved by any search algorithm in chapter 3

5.2
a.  assume the two puzzles can be solved in arbitrary order (player can move pieces on either puzzle each move)
    a state is a tuple of two 8-puzzle states (s1, s2)
    the actions are sum of actions on the two puzzles 
    cost is uniform
b.  9!^2, or (9!/2)^2 counting only reachable states
c.  EXPECTMINIMAX from Figure 5.11
d.  it may not be the case
    let p(s) be the minimum number of moves required to solve a puzzle s
    terminal state is (s1, s2) where p(s1) = p(s2) = 0
    when p(s1) = 1 and p(s2) = 1
    if the player take an action which reduces p(s1) or p(s2), the other player will win with 50% chance next turn
    it seems better to move away from the terminal state by increasing p(s1) or p(s2)

5.3
a.  from left to right:
        dd(1): -4
        dd(2): -4
        cc: 2
b.  P is guranteed to win in at most 4 moves by the left half of the game tree
    each internal node in there has value >= its deepest descendants
    the right half is suboptimal moves for P and should not be taken
c.  from left to right:
        be, bf, be, bf, bc
d.  P can always drive E to node e or f and win the next turn as there's no way to escape
    the value of these nodes is bounded from below by
        - (the total time taken up to now + 2 * the length from P's position to node e or f)
    from left to right:
        be: 3 + 3 * 2 = 9
        bf: 3 + 3 * 2 = 9
        be: same to above
        bf: same to above
        bc: 3 + 3 * 2 = 9
e.  any node except the two paths from root to termination state dd(1) and dd(2)
f.  P always wins
    let the tree rooted from the node p occupied by P, let e be the node occupied by E
    if e = n, P wins immediately
    otherwise let c be the child of p which has e as its descendant, move E to c
    let S((p, e)) be the number of nodes in the subtree rooted at c, it's obvious that:
        each move of P reduces S((p, e))
        any move of E cannot increase S((p, e))
    when S((p, e)) = 1, P will win the next turn by moving to e, the only node in the subtree and a child of p
    so as long as S((p, e)) is finite at the beginning (i.e. the subtree is finite), P will always win

5.4
Monopoly (simplified)
State:
    position and assets of each player
Move: given state and player p,
    a chance node (2d6) decides the next stop of p
    mutate state according to the description of the stop (rants, taxes, may spawn more chance nodes by cards)
    if stopped at an unowned property, the player can choose whether to buy the property
Terminal test:
    all but one player is bankrupt
Utility function:
    the winning player has utility 1, others 0
Evaluation function:
    linear function of net asset and owned properties of players

5.5
Gomoku with time control
State:
    pieces on the board (next player can be computed from number of white / black pieces)
    remaining time of each player
Move:
    a piece of the player's color can be placed at any empty tile on the board
    a fixed time duration t + the remaining time of the player is allowed for the move
    if the time consumed exceeds t, the surplus is deducted from the remaining time of the player
Terminal test:
    5 or more pieces of the same color are placed on a row (vertial, horizontal or diagonal)
Utility function:
    the winning player has utility 1, other one 0
    or 1/2 and 1/2 if end in a draw
Evaluation function:
    a linear function of blocked / unblocked 3, 4, >= 5 pieces in a row for each color
    where the coefficient of >= 5 pieces in a row is big enough to dominate any other factors

5.6
even if the AI player can control exactly where to land its shots, in the absence of proper discretization
the branching factor is easily infinite, the AI does not stand a chance against a trained amateur
tennis players are constantly moving around regarding the position / velocity of the ball and the other player
it requires further discretization (to tiny time period?) to turn this constant move into turn-based nodes

5.7
induct on the height of the game tree from the shallowest MIN node
basis:
    all child nodes are terminal nodes from a MIN node
    if the decision of MIN at this node is not optimal, the value of the MIN node increases
    by definition of minimax algorithm, all MAX nodes above can only have value >= before
induction:
    the MIN nodes has children either terminal or is a MAX node
    by induction all the MAX children have value better or equal than before
    the optimal value of this MIN node is no better than that computed from minimax algorithm
    as the MIN player is suboptimal, the value of this MIN node is greater than minimax
    value of MAX nodes computed by minimax algorithm above it may never decrease
if MIN will always choose the same suboptimal move in a tree
RESULT(A, a1) = B
RESULT(A, a2) = C
RESULT(B, b1).UTILITY = 10
RESULT(B, b2).UTILITY = -10
RESULT(C, c).UTILITY = 5
if MIN is optimal, MAX should choose a2 in node A
if MIN is suboptimal and will always choose b1 at node B, MAX should chooce a1 at node A

5.8
a.  digraph G {
        node [shape=circle]
        1 [label="(1, 4) +1"]
        2 [label="(2, 4) +1"]
        3 [label="(2, 3) +1"]
        4 [label="(4, 3) +1", shape=box]
        5 [label="(1, 3) -1"]
        6 [label="(1, 4) ?", shape=box, peripheries=2]
        7 [label="(1, 2) -1"]
        8 [label="(3, 2) -1"]
        9 [label="(3, 1) -1", shape=box]
        10 [label="(3, 4) ?"]
        11 [label="(2, 4) ?", shape=box, peripheries=2]
        1 -> 2 -> 3 -> 4
        3 -> 5 -> 6
        5 -> 7 -> 8 -> 9
        8 -> 10 -> 11
    }
b.  assume both players prefer acyclic states over cyclic ones
c.  MINIMAX algorithm in the text is a DFS without redundancy check, it may loop forever with cyclic state graph
    record the path of states and assign special value Loop to repeated states, in the same way as and or graph search
    the value space is not a total order any more with the special value
    the assumption in part b above may not always be true
    if a player has to choose between certain lose and loop, they may prefer loop
d.  by graph generation, when n = 3 player B always wins, when n = 4 player A always wins
    for n = 2k, the start state is (1, 2k), the next state is (2, 2k)
    if A never goes back to the location 1, this is equivalent to a game where
        1. n = 2k - 1 
        2. the roles of two players are swapped
    by induction, when n = 2k - 1, player B will always win, i.e. reach the other end eariler than player A
    hence when n = 2k, player A can always win
    for n = 2k, the start state is (1, 2k + 1), the third state is (2, 2k)
    if A never goes back to location 1, this is equivalent to a game
        1. n = 2k - 1
    so player B will always win
    otherwise whenever A goes back to location 1, B moves moves left
    A's move is negated by B's move, reduces the state to a valid state in a game n = 2k - 1

5.9
a.  <= 3^9
    each tile may either be empty, X or O
    the next player can be decided by the number of Xs / Os on the board
b.  digraph G {
        node [shape=record]
        0 [label="...\n...\n...|1"]
        1 [label="x..\n...\n...|-1"]
        2 [label=".x.\n...\n...|-2"]
        3 [label="...\n.x.\n...|1"]
        4 [label="xo.\n...\n...|1"]
        5 [label="x.o\n...\n...|0"]
        6 [label="x..\n.o.\n...|-1"]
        7 [label="x..\n..o\n...|1"]
        8 [label="x..\n...\n..o|0"]
        9 [label="ox.\n...\n...|-1"]
        10 [label=".x.\no..\n...|0"]
        11 [label=".x.\n.o.\n...|-2"]
        12 [label=".x.\n...\no..|-1"]
        13 [label=".x.\n...\n.o.|0"]
        14 [label="o..\n.x.\n...|1"]
        15 [label=".o.\n.x.\n...|2"]
        0 -> 1, 2, 3
        1 -> 4, 5, 6, 7, 8
        2 -> 9, 10, 11, 12, 13
        3 -> 14, 15
    } 
c.  xo./.../...: 1
    x.o/.../...: 0
    x../.o./...: -1
    x../..o/...: 1
    x../.../..o: 0
    ox./.../...: -1
    .x./o../...: 0
    .x./.o./...: -2
    .x./.../o..: -1
    .x./.../.o.: 0
    o../.x./...: 1
    .o./.x./...: 2
d.  .../.../...: 1
    x../.../...: -1 
    .x./.../...: -2
    .../.x./...: 1
    best start move: .../.x./...
e.  if .../.x./... is explored first, all nodes but 
        o../.x./...
        .o./.x./...
        a random child of x../.../...
        a random child of .x./.../...
    will not be evaluated

5.10
a.  branching factor of a node at depth d is N - d
    depth of the game tree is at most N, number of nodes <= N!
b.  N! as stated above
c.  generalize the evaluation function defined in 5.9
    let Xi be the number of winning positions w ∈ W which is occupied by (|w| - i) X and no O
    the evaluation function is a linear combination of Xi and Oi, where
        if i < j, coefficient of Xi is greater than Xj, coefficient of Oi is smaller than Oj (both negative)
d.  with optimal exploration order, alpha-beta pruning only evaluates (N!)^(1/2) nodes
    100N * (N!)^(1/2) / (2 * 10^9) <= 1 => N <= 15
    100N * (N!)^(1/2) / (2 * 10^9) <= 60 => N <= 17
    100N * (N!)^(1/2) / (2 * 10^9) <= 3600 => N <= 20

5.11
a.  ./AI/minimax/src/othello.rs
b.  ./AI/minimax
c.  // skipped
b.  // skipped, papers paywalled

5.12
minimax works exactly as multiplayer game in section 5.2.2
each player maximizes their own utility and ignores the other's
the utility of one player will not affect the decision of the other
hence no node will be pruned by alpha-beta pruning
when the optimal terminal state for MAX is also the optimal terminal state for MIN
the game is just an optimal search problem which can be solved by any local search algorithm in chapter 4
otherwise it's still competitive

5.13
a.  n2 is a MAX node
    n2 = max{n | n is a child of n2}
    n1 = nj iff 
        n2 = min{n | n is a child of n1}
        n3 = max{n | n is a child of n2}
        ..
        nj = min{n | n is a child of nj-1}
    otherwise n1 is independent of nj
b.  n1  = min(l2, n2, r2)
        = min(l2, max(l3, n3, r3), r3)
        = ..
        = min(l2, max(l3, min(l4 .. min(lj, nj, rj) .. r4), r3), r2)
c.  if nj is greater than min(l2, r2, l5, r5, .., lj, rj), it will not affect n1
c.  if nj is smaller than max(l3, r3, l5, r5, .., lj, rj), it will not affect n1

5.14
assume 
    for a MIN node, the first child gives the minimum v
    for a MAX node, the first child gives the maximum v
if a MAX node is explored with (α, β) = (+∞, -∞)
    the first child (MIN) will be explored with (+∞, -∞), give the maximal v*
    α is updated to v*
    all the other children is explored with (v*, -∞)
if a MIN node is explored with (+∞, -∞)
    the first child (MAX) will be explored with (+∞, -∞), give the minimal v*
    β is updated to v*
    all the other children is explored with (+∞, v*)
if a MAX node is explored with (+∞, v*)
    if its parent is evaluated with (-∞, +∞)
        the first child (MIN) is explored with (+∞, v*), results in v >= v*
        otherwise the backed-up value of this node is greater than maximum
        no other child will be explored
    otherwise in the worst case it explores the same set of nodes as (-∞, +∞)
if a MIN node is explored with (v*, -∞)
    if its parent is evaluated with (-∞, +∞)
        the first child (MAX) is explored with (v*, -∞), results in v <= v*
        otherwise the backed-up value of this node is smaller than minimum
        no other child will be explored
    otherwise in the worst case it explores the same set of nodes as (-∞, +∞)
roughly half the levels are not expanded, O(b^(m/2)) nodes expanded in total

5.15
representation:
    there are 8 x 8 = 2^6 positions on the board, a position can be represented by 6 bits
    7 bits with the additional "not on board" position, or 1 byte with proper alignment
    there are 16 pieces for each side, 16 * 2 * 1 = 32 bytes
2^30 / 2^5 = 2^25 entries in 2GB table
10^7 * 3 * 60 = 1.8 * 10^9 > 2^25, the memory is not enough
without detail of the evaluation function / hash method / disk specification, no conclusion can be drawn

5.16
a.  digraph G {
        node [shape=none, label="", style=filled]
        1 [shape=triangle, label=1.5]
        2, 3 [shape=circle]
        2 [label=1.5]
        3 [label=-0.5]
        4, 5, 6, 7 [shape=invtriangle]
        4 [label=2]
        5 [label=1]
        6 [label=0]
        7 [label=-1]
        8, 9, 11, 13 [label="2"]
        10 [label="1"]
        12, 15 [label="0"]
        14 [label="-1"]
        1 -> 2, 3
        2 -> 4, 5 [label=0.5]
        3 -> 6, 7 [label=0.5]
        4 -> 8, 9
        5 -> 10, 11
        6 -> 12, 13
        7 -> 14, 15
    }
b.  let n3 be the right chance node
    if min{t7, t8} > 3, n3 > 1.5, the first action will be suboptimal
    if t7 = -1, n3 = -0.5, utility of t8 won't affect the optimal action
c.  0 <= n2 <= 2
d.  the last two terminal node

5.17
./AI/minimax

5.18
induct on the height of subtrees
basis (all children are terminal):
    MAX node:
        when a > 0, if x >= y, ax + b >= ay + b
        the optimal child will not change 
        backed-up value of this node is updated from x to ax + b
    MIN node:
        symmetric
    CHANCE node:
        Σ(aVi + b)Pi = ΣaViPi + ΣbPi = aΣViPi + b
        backed-up value of this node is updated from x to ax + b
induction:
    MAX node:
        all children have backed up value updated from x to ax + b
        the optimal child will not change
    MIN node:
        symmetric
    CHANCE node:
        similar to basis

5.19
it's a special case of Monte Carlo method which only expands chance nodes in random
the method describes a different game compared to the real scenario
(as players can forcast outcomes of all chance nodes)
in practice it may converge to expectminimax just like Monte Carlo to minimax

5.20
a.  no, adding a single terminal node may increase the optimal outcome
b.  no, adding a single terminal node may increase the value of its parent,
    either a MAX or CHANCE node, by an arbitrary value, which change may propagate all the way to the root
c.  no, as stated in b.
d.  no, as stated in b.
e.  yes, if any child evaluates to 1, other children can be pruned
f.  yes, alongside the situation of e., if
        a, left child of the root evaluates to 1
        b, right child of the root is a chance node with two children c, d with probability 0.5 each
        c = 0
    then b <= (0 + 1) / 2 = 0.5, d can be pruned
g.  highest probability first    
    more outcomes of children (probability-wise) are known about a node, more precise is the range of its own outcome 

5.21
a.  true
    as demonstrated by minimax algorithm, if both players are optimal, 
    the moves of one player is easily predictable by the other
b.  false, the assumption turns the game to a fully-observable game
c.  false, what will happen if two of such agents play against each other

5.22
a.  Monopoly, CHANCE nodes in other games have huge branching factor
b.  Scrabble, with fixed outcome of CHANCE nodes, poker and bridge are no longer partially observable,
    nature of the two games will change dramatically
c.  maintain believe states for all players assuming optimality
    likely to be extremely inpractical
    
6.1
./AI/csp
Solution with 2 colors: 0
Solution with 3 colors: 18
Solution with 4 colors: 768

6.2
a.  variables: positions of knights
b.  values: P ∈ Z8^2
c.  a single contraint between each pair of variables:
        for two knights at position (x0, y0) and (x1, y1), 
        (x1, y1) != (x0 + 2, y0 + 1) &&
        (x1, y1) != (x0 + 1, y0 + 2) &&
        (x1, y1) != (x0 - 2, y0 + 1) &&
        (x1, y1) != (x0 - 1, y0 + 2) &&
        (x1, y1) != (x0 + 2, y0 - 1) &&
        (x1, y1) != (x0 + 1, y0 - 2) &&
        (x1, y1) != (x0 - 2, y0 - 1) &&
        (x1, y1) != (x0 - 1, y0 - 2)
d.  ACTIONS: positions on the board not yet attacked by any knights existing
    RESULT: add a knight to the board with position given by ACTIONS
    objective function: number of knights on the board

6.3
a.  state: the board
    start state: no blank square is filled
    goal state: each blank square is filled
    actions: fill a word in the puzzle with a word in the dictionary, respecting crossword rules
    the path doesn't matter, local search is preferable
    if the blank squares are filled one character at a time, it will be harder to define legal actions
b.  variables: hole of words on the board
    values: words in the dictionary
    constraints: if one word spans another, the character on the intersection should be the same (2-constraints only)
    with characters as variables, constraints could involve more than 2 variables and would be harder to verify
    (each word on the board should be a word in the dictionary)

6.4
a.  variables: positions (coordinates of top left corner) of each rectangles
    values: coordinates in the larger rectangle
    constraints: no overlapping between any two rectangles (2-constraints only)
b.  variables: classes
    values: triple of time slot, classroom and professor
    1-constraints:
        professors are assigned to classes they can teach
    2-constraints:
        if two classes are allocated to the same time slot, 
        they should be assigned to different classroom and professor
c.  variables: cities
    values: order in the tour
    2-constraints:
        let (i, j) be the orders of two cities (a, b)
        if j = i + 1, there should be a road from a to b
    global constraints:
        ALLDIFF on orders

6.5
// thanks http://bach.istc.kobe-u.ac.jp/llp/crypt.html
938+938=1876
928+928=1856
867+867=1734
846+846=1692
836+836=1672
765+765=1530
734+734=1468

6.6
let domain of variable A be DA
consider any relation R ⊆ DA * DB * DC
define a new variable T with domain DA * DB
define 2-constraints:
    (A, T): T = (A, _)
    (B, T): T = (_, B)
    (C, T): T = (a, b), (a, b, c) ∈ R
for any R ⊆ Π(1 <= i <= n)Di
define T with domain Π(1 <= i <= n - 1)Di
the proof is similar to n = 3
if there are some unary constraints Ri ⊆ D for a variable V with domain D
let D' = ∩Ri
any value in D - ∩Ri will violate at least one unary constraint
all values in D - ∩Ri do not violate any of the unary constraints
change the domain to D - ∩Ri safely eliminates all the unary constraints on V

6.7
variables: five nationalities, five colors, five brands of candy, five drink and five pets, 25 in total
values: houses in domain {1, 2, 3, 4, 5}, ordered from left to right
most constraints will be unary or binary e.g.:
    The Norwegian lives in the first house on the left => Norwegian = 1
    The Englishman lives in the red house => Englishman = red
there are also 5 ALLDIFF constraints on five nationalities, colors, etc.

6.8
./AI/csp
[2, 0, 2, 0, 1, 2, 1, 0]

6.9
most constrained variable: smaller branching factor
least constrained variable: more likely to be consistent, closer to a goal state

6.10
./AI/csp
Sample size = 100
n = 10, k = 3, average time: 45.803µs
n = 10, k = 4, average time: 58.821µs
n = 20, k = 3, average time: 161.787µs
n = 20, k = 4, average time: 195.926µs
n = 30, k = 3, average time: 313.017µs
n = 30, k = 4, average time: 343.659µs
n = 40, k = 3, average time: 498.832µs
n = 40, k = 4, average time: 528.52µs
n = 50, k = 3, average time: 713.714µs
n = 50, k = 4, average time: 781.804µs
n = 60, k = 3, average time: 921.854µs
n = 60, k = 4, average time: 985.129µs
n = 70, k = 3, average time: 1.288054ms
n = 70, k = 4, average time: 1.376637ms
n = 80, k = 3, average time: 1.614063ms
n = 80, k = 4, average time: 1.688802ms
n = 90, k = 3, average time: 2.02847ms
n = 90, k = 4, average time: 2.081303ms
n = 100, k = 3, average time: 2.487953ms
n = 100, k = 4, average time: 2.664178ms
n = 110, k = 3, average time: 3.009056ms
n = 110, k = 4, average time: 3.096969ms
n = 120, k = 3, average time: 3.688433ms
n = 120, k = 4, average time: 3.92376ms
n = 130, k = 3, average time: 4.508409ms
n = 130, k = 4, average time: 4.536822ms
n = 140, k = 3, average time: 5.225739ms
n = 140, k = 4, average time: 5.445125ms
n = 150, k = 3, average time: 6.139016ms
n = 150, k = 4, average time: 6.203166ms
n = 160, k = 3, average time: 7.180469ms
n = 160, k = 4, average time: 7.404204ms
n = 170, k = 3, average time: 7.981097ms
n = 170, k = 4, average time: 8.107019ms
n = 180, k = 3, average time: 8.889312ms
n = 180, k = 4, average time: 9.092286ms
n = 190, k = 3, average time: 9.967555ms
n = 190, k = 4, average time: 10.107981ms
n = 200, k = 3, average time: 10.917996ms
n = 200, k = 4, average time: 11.265273ms
n = 210, k = 3, average time: 12.022255ms
n = 210, k = 4, average time: 12.487402ms
n = 220, k = 3, average time: 13.422819ms
n = 220, k = 4, average time: 13.653953ms
n = 230, k = 3, average time: 14.635311ms
n = 230, k = 4, average time: 14.935789ms
n = 240, k = 3, average time: 15.938145ms
n = 240, k = 4, average time: 16.251375ms
n = 250, k = 3, average time: 17.275465ms
n = 250, k = 4, average time: 17.656288ms
n = 260, k = 3, average time: 18.982531ms
n = 260, k = 4, average time: 19.508623ms
n = 270, k = 3, average time: 20.831927ms
n = 270, k = 4, average time: 21.118058ms
n = 280, k = 3, average time: 22.793173ms
n = 280, k = 4, average time: 23.28953ms
n = 290, k = 3, average time: 24.759013ms
n = 290, k = 4, average time: 24.864295ms
n = 300, k = 3, average time: 26.079515ms
n = 300, k = 4, average time: 26.54345ms
n = 310, k = 3, average time: 27.405902ms
n = 310, k = 4, average time: 28.365417ms
n = 320, k = 3, average time: 29.848001ms
n = 320, k = 4, average time: 30.388094ms
n = 330, k = 3, average time: 31.850545ms
n = 330, k = 4, average time: 32.298845ms
n = 340, k = 3, average time: 33.672704ms
n = 340, k = 4, average time: 34.208691ms
n = 350, k = 3, average time: 34.849628ms
n = 350, k = 4, average time: 35.996554ms
n = 360, k = 3, average time: 37.107424ms
n = 360, k = 4, average time: 37.22433ms
n = 370, k = 3, average time: 39.466757ms
n = 370, k = 4, average time: 40.312503ms
n = 380, k = 3, average time: 41.036165ms
n = 380, k = 4, average time: 41.037952ms
n = 390, k = 3, average time: 43.320708ms
n = 390, k = 4, average time: 43.584628ms
n = 400, k = 3, average time: 45.540979ms
n = 400, k = 4, average time: 45.755596ms
n = 410, k = 3, average time: 48.01493ms
n = 410, k = 4, average time: 48.26128ms
n = 420, k = 3, timeout after 5s
running time roughly quadratic in n

6.11
./AI/csp

6.12
n <- the number of variables, d <- the maximum size of domain
O(n) edges are checked, each takes O(d^2) time
O(nd^2) in total

6.13
only put an edge (Xq, Xk) back on the queue when:
    (Xk, Xi) is the current edge / constraint under examination
    (Xq, Xk) is an edge in the graph
    counter for some x ∈ Xk on (Xk, Xi) is reduced to 0
each edge has O(d) counters, which in turn takes value <= d
sum of all these counters at the beginning is O(cd^2)
counters are non-negative
// thanks solution manual
by algorithm AC-4 on the paper 
    Arc and path consistency revisited, Mohr and Henderson (1986) 
    http://cse.unl.edu/~choueiry/Documents/Mohr+Henderson-AIJ1986.pdf
the innermost loop decrements a counter, there are O(cd^2) = O(n^2d^2) such decrementations

6.14
the arc-consistent graph is later searched from the root
if arc-consistency is forced from parent to child, for (Xj, Xi = PARENT(Xj))
    for all xj ∈ Xj, there is xi ∈ Xi that (xi, xj) ∈ R
    if an arbitrary value xi in the domain is assigned to Xi
    {xj | xj ∈ Xj, (xi, xj) ∈ R} may be empty, backtracking may be necessary
if arc-consistency is forced from child to parent, for (Xi = PARENT(Xj), Xj)
    for all xi ∈ Xi, there is xj ∈ Xj that (xi, xj) ∈ R
    if an arbitrary value xi in the domain is assigned to Xi
    there is always an xj ∈ Xj that (xi, xj) ∈ R, no backtracking is required

6.15
for a given inital board:
START STATE: assign number in random order, only ensure each zone (3 x 3 square) is filled with number 1-9
GOAL STATE: by Sudoku rules 
ACTIONS: swap places of two numbers in a zone (3 x 3 square) that's not fixed by the inital board
size of the state space <= 9! * 9 <= 2^22, local search should be efficient in such a small state space

6.16
constraint:
    let (Di .. Dj) be a tuple of domains of variables, a constraint is a subset R ⊆ Di * .. * Dj
    or a structure C with an exposed method rel that C.rel(xi .. xj) = true iff (xi .. xj) ∈ R for some fixed R
backtracking search: 
    repeat the process:
    1.  assign a value to a variable with a domain of size >= 2
    2.  prune inconsistent values from other variables 
    3.  if any domain is reduced to empty, revert the changes made in 1. and 2. 
    4.  if any domain has size >= 2, go back to 1; otherwise return the assignment
arc consistency:
    csp has arc consistency <=> csp is consistent in respect to all the binary constraints
backjumping:
    in backtracking search, when the current assignment is proved to be inconsistent
    backtrack to the most recent variables that caused the inconsistency instead of the most recent variable
min-conflicts:
    upon choosing a new value for a variable
    choose a value that prunes as few as possible values from other variables
cycle cutset:
    let G be a CSP graph, S ⊆ G.V
    if by removing S and incdent edges from G, the resulting graph G' is a tree
    then S is a cycle cutset of G

6.17
enumerate all possible combination of k nodes in G, remove these nodes, check if the remaining graph is a tree
check can be performed in time O(V + E), O((V + E)n^k) in total
Approximation Algorithms for the Loop Cutset Problem, Becker, A. and Geige, D. (2013)
https://arxiv.org/ftp/arxiv/papers/1302/1302.6787.pdf
described an algorithm with time complexity O(E + VlgV)
for common CSP graphs, the optimal cycle cutset is already large
enumerating all the possible value assignments of S would be impractical

7.1
// ./AI/propositional
KB worlds:
  24: Pits: [(3, 1)], Wumpus: (1, 3)
a2 worlds:
  8: Pits: [(1, 3), (3, 1)], Wumpus: (1, 3)
  9: Pits: [(1, 3), (3, 1)], Wumpus: (2, 2)
  10: Pits: [(1, 3), (3, 1)], Wumpus: (3, 1)
  11: Pits: [(1, 3), (3, 1)], No wumpus
  12: Pits: [(1, 3)], Wumpus: (1, 3)
  13: Pits: [(1, 3)], Wumpus: (2, 2)
  14: Pits: [(1, 3)], Wumpus: (3, 1)
  15: Pits: [(1, 3)], No wumpus
  24: Pits: [(3, 1)], Wumpus: (1, 3)
  25: Pits: [(3, 1)], Wumpus: (2, 2)
  26: Pits: [(3, 1)], Wumpus: (3, 1)
  27: Pits: [(3, 1)], No wumpus
  28: Pits: [], Wumpus: (1, 3)
  29: Pits: [], Wumpus: (2, 2)
  30: Pits: [], Wumpus: (3, 1)
  31: Pits: [], No wumpus
a3 worlds:
  0: Pits: [(1, 3), (2, 2), (3, 1)], Wumpus: (1, 3)
  4: Pits: [(1, 3), (2, 2)], Wumpus: (1, 3)
  8: Pits: [(1, 3), (3, 1)], Wumpus: (1, 3)
  12: Pits: [(1, 3)], Wumpus: (1, 3)
  16: Pits: [(2, 2), (3, 1)], Wumpus: (1, 3)
  20: Pits: [(2, 2)], Wumpus: (1, 3)
  24: Pits: [(3, 1)], Wumpus: (1, 3)
  28: Pits: [], Wumpus: (1, 3).1

7.2
a.  mythical => immortal
b.  ~mythical => mortal ∧ mammal
c.  immortal ∨ mammal => horned
d.  horned => magical
from a and b:
    e.  immortal ∨ (mortal ∧ mammal)
from c and e:
    f.  horned
from d and f:
    g.  magical

7.3
a.  ./AI/propositional/src/lib.rs
b.  a => b with a = false
    a || b with a = true
    a && b with a = false
c.  TAOTOLOGY can be reduced to PL-TRUE? with empty model
    hence PL-TRUE? is NP-complete
d.  ./AI/propositional/src/lib.rs
    a => b with { a = true }
    a || b with { a = false }
    a && b with { a = true }
e.  if for a partial model P, PL-TRUE?(KB, P) is true or false
    all the full models M where P ⊆ M nolonger have to be checked

7.4
a.  true
b.  false (by definition of =>)
c.  true
d.  false {a = false, b = false}
e.  true 
f.  true
        !((A => C) ∨ (B => C))
    <=> (!A ∧ C) ∧ (!B ∧ C)
    <=> !(A ∨ B) ∧ C
    =>  !(A ∧ B) ∧ C
    =>  !(A ∧ B) ∨ C
    =>  !((A ∧ B) => C)
g.  true
        (C ∨ (!A ∧ !B))
    <=> (C ∨ !A) ∧ (C ∨ !B)
    <=> (A => C) ∧ (B => C)
h.  true (and-elimination)
i.  false {a = false, b = false, c = false, d = true, e = false}
j.  true {a = true, b = false}
k.  true {a = true, b = true}
l.  false (./AI/propositional)

7.5
let M(a) be the set of models in which a is true
a.      a is valid
    =>  a is true for every model
    =>  M(True) = M(a)
    =>  True |= a
        True |= a
    =>  M(True) ⊆ M(a), as M(True) is the universal set of models
    =>  a is valid
b.  M(False) = ∅ ⊆ M(a) for any a
c.      a |= b
    <=> M(a) ⊆ M(b)
    <=> for all model, if a is true, b must be true
    <=> !(a ∧ !b) is valid
    <=> (!a ∨ b) is valid
    <=> a <=> b is valid
d.  a |= b iff a => b is valid
    b |= a iff b => a is valid
    a ≡ b => (a => b && b => a), a <=> b is valid
    and vice versa
e.      a ∧ !b is unsatisfiable
    <=> !(a ∧ !b) is valid
    <=> !a ∨ b is valid
    <=> a => b is valid
    <=> a |= b

7.6
a.  a ∧ b => a is valid, so a ∧ b |= a and a ∧ b |= b
    if a |= γ, M(a ∧ b) ⊆ M(a) ⊆ M(γ), a ∧ b => γ
    if b |= γ, similar
b.      a |= (b ∧ γ)
    =>  a => b ∧ γ is valid
    =>  a => b ∧ a => γ is valid
    =>  a => b is valid and a => γ is valid
    =>  a |= b and a |= γ
c.  define
        a = True
        b = s
        γ = !s
    s ∨ !s is valid, True |= b ∨ γ
    but neither s nor !s is valid, both a |= b or a |= !s are false

7.7
a.  2^2
b.  2^4
c.  2^4

7.8
a.  XOR
b.  there are 2^4 = 16 functions in the domain N2 * N2 => N2
    each corresponds to a binary operation
c.  for some of them the result does not depend on all the operands

7.9
./AI/propositional

7.10
./AI/propositional
a.  valid
b.  neither
c.  neither
d.  valid
e.  valid
f.  valid
g.  valid

7.11
let S = {Si} be the set of symbols appeared in the sentence
let M = {Mi} be the set of models in which the sentence is not the case
let C(Mj) be a conjunction that:
    C(Mi) = L1 ∧ .. ∧ Ln where
    Lj  = Sj if Sj is true in Mi
        = !Sj if Sj is false in Mi
the sentence is equivalent to:
        !(∨{C(Mi) | Mi ∈ M})
    <=> ∧{!C(Mi) | Mi ∈ M}
    <=> ∧{!C'(Mi) | Mi ∈ M} where
    C'(Mi) = L'1 ∨ .. ∨ L'n
    L'j = !Sj if Sj is true in Mi
        = Sj if Sj is false in Mi
which is a CNF

7.12
~(~A & ~B) = A | B
A | B + ~B | A:
    A
~A | B | E + A:
    B | E
B | E + ~E | B:
    B
~B | F + B:
    F
~B | C + B:
    C
~C | ~F | ~B + B + F + C:
    {}
~A & ~B is proven

7.13
a.      (P1 & .. & Pm) => Q
    <=> ~(P1 & .. & Pm) | Q
    <=> (~P1 | .. | ~Pm) | Q
    <=> ~P1 | .. | ~Pm | Q
b.      ~P1 | .. | ~Pm | Q1 | .. | Qn
    <=> (~P1 | .. | ~Pm) | (Q1 | .. | Qn)
    <=> (P1 & .. & Pm) => (Q1 | .. | Qn)
c.  let two clauses be
        (P1 & .. & Pm) => (Q1 | .. | Qn) and
        (X1 & .. & Xs) => (Y1 | .. | Yt)
    where Pi = Yj, then
        (P1 & .. & Pi-1 & Pi+1 & Pm & X1 & .. & Xs) => (Q1 | .. | Qn | Y1 | .. | Yj-1 | Yj+1 | .. | Yt)

7.14
a.  (ii)
b.  (i):    ~R | ~E | C
    (ii):   (~R | ~E | C) & (~R | ~C | E)
    (iii):  ~R | ~C | E | ~E

7.15
a.  digraph G {
        X1 -> X2 -> X3 -> X4 -> X5 [label="Imp"]
    }
b.  ~A | B <=> A => B ("Imp")
    if Xi = true, all Xj with j > i must have Xj = true
    there are n solutions to this SAT problem
c.  with MAC:
    at first the solution X1 .. X5 = false is explored in O(n)
    assigning false to variables triggers no change to consistent domains, INFERENCE is O(1)
    then the algorithm backtracks to X1 .. Xi = false, starting from i = 4
    one run of MAC in time O(n - i) will reduce the domain of all variables Xi+1 .. Xn to a single value
    O(n^2) in total
d.  PL-FC-ENTAILS? only has running time linear in number of literals 
    if clauses can be indexed by literals in premise in constant time
    possible connection: for both problems edges (clauses in SAT, constraints in CSP) are only propagated once

7.16
let c = {l1 .. ln} be a clause
if l1 = A, assign true to A, c is satisfied
if l1 = ~A, assign false to A, c is satisfied
a 3-clause {A, B, C} is unsatisfied only when both A, B and C is false
when A, B and C mention distinct symbols, in 1 / 2^3 = 1/8 of all the models the clause is unsatisfiable
hence each clause rules out at most 1/8 of all the models, 5 / 8 < 1, 3-SAT of 5 clauses is always satisfiable
unsatisfiable 3-SAT problem contains at least 8 clauses

7.17
a.  ~C | G + ~G:
        ~C
    ~D | G + ~G:
        ~D
    ~B | D + ~D:
        ~B
    A | B + ~B:
        A
    ~A | C + A + ~C:
        {}
b.  there are C(n, 2) = n * (n - 1) / 2 pairs of distinct symbols, 4 semantically distinct clauses for each pair:
        {A, B}, {~A, B}, {A, ~B}, {~A, ~B}
    two semantically distinct clauses for each symbol alone:
        {A, A}, {~A, ~A}
    where {A, ~A} <=> True for any A
    4(n^2 - n)/2 + 2n + 1 = 2n^2 + 1 clauses in total
c.  resolving two 2-CNF clauses will result in another 2-CNF clause
    there are O(n^2) semantically distinct 2-CNF clauses
    constructing a new clause from the KB may take at most O(n^2) time by enumerating all pairs
    O(n^4) in total
d.  RC(3-CNF) is not closed, resolving two 3-CNF results in a 4-CNF clause

7.18
./AI/propositional
a.  satisfiable
b.  lhs: (~A | ~C | B)
    rhs: (~A | B) & (~C | B)
    all symbols appear in both CNF with the same sign
c.  original: (~A | ~B | B) & (~A | A | B) & (~A | B | C)
    negation: (~A | ~C | B) & (~B) & (A | C)
    none of them resolves to empty clause

7.19
a.  enumerate all the assignments in which the sentence is true
    construct a clause for each assignment that:
        li = si if s1 = true in the assignment
        li = ~si if s1 = false in the assignment
b.  first to NNF, then distribute each AND over ORs 
    ./AI/propositional/src/lib.rs#to_dnf_expr
c.  for each clause ci:
        for each literal li in ci:
            if symbol of li is already assigned with contradicting value, return UNSATISFIABLE
            otherwise assign li to make it satisfied
        assign all symbols not in ci true
        return assignment
d.  ((((~A & ~B) & ~C) | ((B & ~B) & ~C)) | (((~A & C) & ~C) | ((B & C) & ~C))) | ((((~A & ~B) & ~A) | ((B & ~B) & ~A)) | (((~A & C) & ~A) | ((B & C) & ~A)))
    A = B = C = false
e.  // thanks solutions manual
    the final step (distribute AND over ORs) frequently produces DNF of exponential size of the original sentence

7.20
// thanks http://formal.cs.utah.edu:8080/pbl/PBL.php
S1: (~A | B | E) & (~B | A) & (~E | A)
S2: ~E | D
S3: ~C | ~F | ~B
S4: ~E | B
S5: ~B | F
S6: ~B | C

7.21
more likely
a random 4-CNF clause is a random 3-CNF clause + a new literal, distinct or not 
which is more likely to be satisfiable

7.22
a.  assuming indices are one-based
    (X12 & X22 & ~X21) | (X12 & ~X22 & X21) | (~X12 & X22 & X21)
b.  for each of C(n, k) combinations of neighbors N
    construct a conjuction clause in which:
        li = Xi if Xi ∈ N
        li = ~Xi if Xi ∉ N
    return disjunction of these clauses
c.  KB contains assertions from all known numbers 
    resolve KB & Xi and KB & ~Xi
d.  there are N symbols in which exactly M of them must be true
    let DPLL take one more parameter: limit
    return false if the number of true symbols in model > limit
    return false if the model is complete but the number of true symbols < limit 
e.  no, if KB |= a, KB & b |= a
f.  when M = k, k-1 mines are already proved
    if there are two squares Xi and Xj that may contain a mine
    no matter how long the distance between Xi and Xj is, Xi <=> ~Xj

7.23
KB |= a is proved by unsatisfiability of KB & ~a
first all pure symbols will be assigned
a pure symbol can be extracted in time O(n) where n is the number of literals in the CNF
here a is not a pure symbol since both a and ~a ∈ (KB & ~a)
then all the unit clauses are assigned
again a unit clause can be find in time O(n) given a partial model 
once a is assigned, further recursive calls will immediately return false
let p be the number of pure symbols appear in the run, u be the number of unit clauses appear in the run
DPLL will take O(pn + un) time

7.24
// ./AI/propositional
(~A | ~B | L) & (~A | ~P | L) & (~B | ~L | M) & (~L | ~M | P) & (~P | Q) & (~Q) & (A) & (B)
{}
chosen Q = false by unique clause heuristic
{Q = false}
chosen P = false by unique clause heuristic
{P = false, Q = false}
chosen A = true by pure symbol heuristic
{A = true, P = false, Q = false}
chosen L = true by pure symbol heuristic
{A = true, L = true, P = false, Q = false}
chosen B = true by pure symbol heuristic
{A = true, B = true, L = true, P = false, Q = false}
chosen M = true by unique clause heuristic
{A = true, B = true, L = true, M = true, P = false, Q = false}
heuristics were unbelievably effective here

7.25
Locked(t+1) <=> (~Locked(t) & Lock(t)) | (Locked(t) & ~Unlock(t))

7.26
// only fluents mentioned in the text
FaceingEast(t+1) <=>    (FacingNorth(t) & TurnRight(t)) |
                        (FacingSouth(t) & TurnLeft(t)) |
                        (FacingEast(t) & ~TurnRight(t) & ~TurnLeft(t))
WumpusAlive(t+1) <=>    WumpusAlive(t) &
                        ~(FacingWumpus(t) & HaveArrow(t) & Shoot(t))
FacingWumpus is not a fluent, it only depends on background & fluents for the current time t

7.27
// thanks solutions manual
define symbol or(Pij, Pqr) for each pair of Pij and Pqr
then P31 | P22 will be included in the next believe state as or(P31, P22)
// code / performance test skipped

8.1
a.  road, city, coastline
b.  explicit: location of cities, start and end point of roads, scale of the map
    implicit: whether two cities are connected by roads, length of the roads, size of cities
c.  temporal states / fluents (e.g. traffic flow at the moment)
d.  exact shape of the coastline
    exact shape of a road
e.  statistical graphics
        pros: intuitive, expressive
        cons: lacks precision compared to raw data
    Venn diagram:
        pros: intuitive
        cons: causes certain kind of misunderstanding of set theories

8.2
true under closed-world assumption
in standard semantics there may be infinitely more unnamed objects x in the domain, for which ~P(x)

8.3
it is valid, without unique-name assumption x and y may be different names of the same object

8.4
∀x, y x = y

8.5
each constant symbol may point to one of D elements, c^D possible arrangements
a predicate of arity k is a subset of the powerset of domain D in which all sets are of size k
    there are C(D, k) different subsets of size k, 2^C(D, k) for each predicate
    2^C(D, k)pk for all predicates of arity k, Π(1 <= k <= A)2^C(D, k)pk = 2^Σ(1 <= k <= A)C(D, k)pk in total
size of the function domain D^k => D ∪ {empty} is (D + 1)^D^k
    ((D + 1)^D^k)^fk = (D + 1)^(D^k)fk for each k
    Π(1 <= k <= A)(D + 1)^(D^k)pk = (D + 1)^Σ(1 <= k <= A)(D^k)pk in total
c^D * 2^Σ(1 <= k <= A)C(D, k)pk * (D + 1)^Σ(1 <= k <= A)(D^k)pk

8.6
a.  valid
    ∃x x = x means the object domain is not empty
    hence for each object there is an object (itself) equals to it
b.  valid, only falsy in intuitionistic logic
c.  valid, x = x for all object by definition, x = x => Smart(x) | x = x 

8.7
1.  ∃x x = x
    true in any domain with at least one object, false in the empty domain
2.  ∃x P(x) | ~P(x)
    same to above
the empty domain leads to the strange consequence that ∀x α is no longer stronger than ∃x α
namely ∀x P(x) | ~P(x) is valid but not sentence 2. above

8.8
no, there's no axiom forcing monogamy in the system
∀x,y,z Spouse(y, x) & Spouse(z, x) => y = z
proof:
        Jim != George & Spouse(Jim, Laura)
    assume Spouse(Laura, George)
    =>  Jim = George & Jim != George // monogamy axiom
    contradiction
    =>  ~Spouse(Laura, George)
if Spouse if an unary function, monogamy is implicitly forced, but everything now in the domain must be married

8.9
a.  i.  invalid, Paris & Marseilles is not an object
    ii. correct
    iii.incorrect, disjunction instead of conjunction
b.  i.  correct
    ii. incorrect, true if any non-country object in the domain
    iii.invalid
    iv. invalid 
c.  i.  correct
    ii. correct, a & b => c <=> a => (b => c):
            a & b => c <=> ~(a & b) | c <=> ~a | ~b | c
            a => (b => c) <=> a => (~b | c) <=> ~a | ~b | c
    iii.incorrect, (a => b) => c <=> (~a | b) => c <=> ~(~a | b) | c <=> (a & ~b) | c
        additional restriction: for all object c, 
        if c is not in South America, c must not share border with Eucador & c must be a country
    iv. incorrect, all countries must be in South America & share border with Ecuador
d.  i.  correct
    ii. correct, a & b => ~c <=> ~(a & b) | ~c <=> ~a | ~b | ~c <=> ~(a & b & c)
    iii.incorrect: if there is a region in South America, there is a region in Europe sharing no border with it
    iv. invalid: ambiguous syntax
e.  i.  incorrect
    ii. correct
    iii.incorrect
    iv. invalid, x != y is not an object

8.10
a.  Occupation(Emily, Surgeon) | Occupation(Emily, Lawyer)
b.  Occupation(Joe, Actor) & ∃o Occupation(Joe, o) & o != Actor
c.  ∀p Occupation(p, Surgeon) => Occupation(p, Doctor)
d.  ~∃p Occupation(p, Lawyer) & Customer(Joe, p)
e.  ∃p Occupation(p, Lawyer) & Boss(p, Emily)
f.  ∃p1,p2 Occupation(p1, Lawyer) & (Customer(p2, p1) => Occupation(p2, Doctor))
g.  ∀p1∃p2 Occupation(p1, Doctor) => (Occupation(p2, Lawyer) & Customer(p1, p2))

8.11
a.  if two speaks the same language they may understand each other
b.  naturally Understands(x, y) is symmetric
c.  i.  ∀x,y Understands(x, y) => Friend(x, y)
    ii. ∀x,y,z Friend(x, y) & Friend(y, z) => Friend(x, z)

8.12
∀x NatNum(x) <=> x = 0 | ∃y x = S(y) & NatNum(y)

8.13
a.  ∀s Breezy(s) => ∃s' Adjacent(s, s') & Pit(s')
    ∀s ~Breezy(s) => ~∃s' Adjacent(s, s') & Pit(s')
        (a => b) & (~a => ~b)
    <=> (a => b) & (~~b | ~a)
    <=> (a => b) & (~a | b)
    <=> (a => b) & (a => b)
    <=> (a <=> b)
b.  ∀s,s' Pit(s) & Adjacent(s, s') => Breezy(s')
    this axiom won't factor out other causes of breeze
    no conclusions can be derived from Breezy(s)

8.14
∀p1,p2 GrandChild(p1, p2) <=> ∃p3 Parent(p3, p2) & Parent(p1, p3)
∀p1,p2 GrandParent(p1, p2) <=> GrandChild(p2, p1)
∀p1,p2 Grandgrandparent(p1, p2) <=> ∃p3 GrandParent(p3, p2) & Parent(p1, p3)
∀p1,p2 Ancestor(p1, p2, k) <=> Parent(p1, p2) & k = 1 | ∃p3 Ancestor(p3, p2, k-1) & Parent(p1, p3)
∀p1,p2 Sibling(p1, p2) <=> ∃p3 Parent(p3, p1) & Parent(p3, p2) & p1 != p2
∀p1,p2 Brother(p1, p2) <=> Sibling(p1, p2) & Male(p1)
∀p1,p2 Sister(p1, p2) <=> Sibling(p1, p2) & Female(p1)
∀p1,p2 Daughter(p1, p2) <=> Parent(p2, p1) & Female(p1)
∀p1,p2 Son(p1, p2) <=> Parent(p2, p1) & Male(p1)
∀p1,p2 FirstCousin(p1, p2) <=> ∃p3 GrandParent(p3, p1) & GrandParent(p3, p2) & ~Sibling(p1, p2) & p1 != p2
∀p1,p2 BrotherInLaw(p1, p2) <=> ∃p3 Spouse(p2, p3) & Brother(p1, p3)
∀p1,p2 SisterInLaw(p1, p2) <=> ∃p3 Spouse(p2, p3) & Sister(p1, p3)
∀p1,p2 Aunt(p1, p2) <=> ∃p3 Parent(p3, p2) & Sister(p1, p3)
∀p1,p2 Uncle(p1, p2) <=> ∃p3 Parent(p3, p2) & Brother(p1, p3)
https://en.wikipedia.org/wiki/Cousin
∀p1,p2,p3 MostRecentCommonAncestor(p3, p1, p2) <=>  ∃k1,k2 Ancestor(p3, p1, k1) & Ancestor(p3, p2, k2) &
                                                    ∀p4,k3,k4 Ancestor(p4, p1, k3) & Ancestor(p4, p2, k4) => (k1 <= k3 && k2 <= k4)
∀p1,p2,m,n Cousin(p1, p2, m, n) <=> ∃p3,k Ancestor(p3, p1, m + 1) & Ancestor(p3, p2, k) &
                                    MostRecentCommonAncestor(p3, p1, p2) & ~Sibling(p1, p2) & 
                                    k > 1 & |m + 1 - k| = n
engine used: pyDatalog https://sites.google.com/site/pydatalog/home
./AI/first_order/kinship.py
Elizabeth's grandchildren:
    Peter
    Harry
    Eugenie
    James
    William
    Beatrice
    Louise
    Zara
Diana's brothers-in-law:
    Andrew
    Edward
Zara's great-grandparents:
    Mum
    George
Eugenie's ancestors:
    George
    Elizabeth
    Philip
    Mum
    Andrew
    Sarah

8.15
there's no way to derive the absence of an element in a set

8.16
Nil = []
∀l List?(l) <=> l = [] | ∃h,t l = [h|t]
∀h,t First([h|t]) = h
First([]) = None
∀h,t Rest([h|t]) = t
Rest([]) = None
∀l Append([], l) = l
∀h,t,l Append([h|t], r) = [h|Append(t, r)]
∀x ~Find(x, [])
∀x,h,t Find(x, [h|t]) <=> h = x | Find(x, t)

8.17
the sentence may refer to squares out of bounds
the definition of adjacent is not symmetric
there's no way to prove non-adjacency

8.18
∀s,t At(Agent, s, t) & Stench(t) => Stenchy(s)
∀s Stenchy(s) <=> ∃s',t At(Wumpus, s', t) & Adjacent(s, s')
∀s,s' At(Wumpus, s, 0) & At(Wumpus, s', 0) => s = s'
∀s,t At(Wumpus, s, t) <=> At(Wumpus, s, 0)

8.19
∀p,p' Daughter(p, p') <=> Parent(p', p) & Female(p)
∀p1,p2,p3 ChildTogether(p1, p2, p3) <=> Parent(p2, p1) & Parent(p3, p1)
a.  ∃p Daughter(p, Joan)
b.  ∃1p Daughter(p, Joan)
c.  ∃1p Parent(Joan, p) & Female(p)
d.  ∃1p ChildTogether(p, Joan, Kevin)
e.  ∃p ChildTogether(p, Joan, Kevin) & ~(∃p,p' ChildTogether(p, Joan, p') & p' != Kevin)

8.20
a.  Even(0), ~Even(1)
    ∀x Even(x + 2) <=> Even(x)
b.  Prime(x) <=> x >= 2 & ∀y,z y * z = x => (y = 1 & z = x) | (y = x & z = 1)
c.  ∀x Even(x) => ∃y,z Prime(y) & Prime(z) & y + z = x

8.21
equality is transitive
if WA = red and any other region X also has X = red, WA = X entails

8.22
∀x,t∃t' Key(x) & Before(t', t) => Lost(x, t)
∀x,y,t∃t' Sock(x) & Sock(y) & Pair(x, y) & Before(t', t) => Lost(x, t) | Lost(y, t)

8.23
a.  x and y may be different names of the same object
    the sentence would be false whenever there is both a Person and a non-Person object
    ~∃x,y,n Person(x) & Person(y) & x != y & HasSS#(x, n) & HasSS#(y, n)
b.  correct
c.  sentence is stronger than in English: every Person has a SSN
    ∀x,n Person(x) & HasSS#(x, n) => Digits(n, 9) 
d.  ~∃x,y Person(x) & Person(y) => SS#(x) = SS#(y)
    SS#(John) = SS#(Mary)
    ∀x Person(x) => Digits(SS#(x), 9)

8.24
constants:  Franch, Greek, Spr2001
predicates: Take(s, l, t), Pass(s, l, t)
function:   Score(s, l, t)
a.  ∃s Take(s, Franch, Spr2001)
b.  ∀s,t Take(s, Franch, t) => Pass(s, Franch, t)
c.  ∃s Take(s, Greek, Spr2001) & (∀x,y Take(x, Greek, Spr2001) & Take(y, Greek, Spr2001) => x = y)
d.  ∀x,t1∃y,t2 Take(s, Franch, t1) => Score(y, Greek, t2) > Score(x, Franch, t1)
predicates: Smart(c), Expensive(p), Buy(c, p, a)
e.  ∀c (∃p,a Buy(c, p, a)) => Smart(c)
f.  ∀c,p Expensive(p) => ~Buy(c, p)
g.  ∃a∀c,p Buy(c, p, a) => ~Insured(c)
predicates: Shave(p1, p2), InTown(p)
h.  ∃p1∀p2 InTown(p2) & ~Shave(p2, p2) => Shave(p1, p2)
constants:  ByBirth, ByDescent
predicates: UKCitizen(p, c), UKResident(p), Parent(p1, p2)
functions:  BornPlace(p)
i.  ∀p1 BornPlace(p1) = UK & (∀p2 Parent(p2, p1) => (∃c UkCitizen(p2, c)) | UkResident(p2)) => UkCitizen(p1, ByBirth)
j.  ∀p1 BornPlace(p1) != UK & (∃p2 Parent(p2, p1) & UkCitizen(p2, ByBirth)) => UkCitizen(p1, ByDescent)
predicates: CanFool(p, f, t), People(f), Time(t)
k.  (∃p,f∀t Time(t) => CanFool(p, f, t)) & (∃p,t∀f People(f) => CanFool(p, f, t)) &
    ~(∃p∀f,t Time(t) & People(f) => CanFool(p, f, t))
predicates: Speak(x, l), Greek(x)
l.  ∀x,y Greek(x) & Greek(y) => ∃l Speak(x, l) & Speak(y, l)

8.25
constants:  Willington, Napoleon
predicates: Heard(p, o)
functions:  Death(p)
axiom:
    // if p1 heard about death of p2, p2 is dead upon p1's death, so p2 cannot hear about p1's death
    ∀p1,p2 Heard(p1, Death(p2)) => ~Heard(p2, Death(p1))
Heard(Willington, Death(Napoleon))
~Heard(Napoleon, Death(Willington))

8.26
define Ad(a, b, c) as a function N2 * N2 * N2 => N2^2:
    Ad1(a, b, c) = ((a + b + c) % 2, (a + b + c) / 2)
n-bit addition is a function N2^n * N2^n => (N2^n, N2) defined as:
    Adn([], []) = ([], 0)
    Adn([h1|t1], [h2|t2]) = 
        (s, c) <- Adn(t1, t2)
        (s', c') <- Ad1(h1, h2, c)
        ([s'|s], c')
define the function (syntax sugar over Signal) SignalAll:
    SignalAll(Out, c) = all output signals from a circult as a list
    SignalAll(In, c) = all input signals from a circult as a list
define a new circuit Add where
    ∀c Circuit(c) & Type(c) = Add => Arity(c, 3, 2)
    ∀c Circuit(c) & Type(c) = Add =>    
        (SignalAll(Out, c) = [0, 0] <=> SignalAll(In, c) = [0, 0, 0]) &
        (SignalAll(Out, c) = [1, 0] <=> SignalAll(In, c) = [1, 0, 0] | SignalAll(In, c) = [0, 1, 0] | SignalAll(In, c) = [0, 0, 1]) &
        (SignalAll(Out, c) = [0, 1] <=> SignalAll(In, c) = [1, 1, 0] | SignalAll(In, c) = [0, 1, 1] | SignalAll(In, c) = [1, 0, 1]) &
        (SignalAll(Out, c) = [1, 1] <=> SignalAll(In, c) = [1, 1, 1])
a 4-bit adder is defined as:
    Circuit(Ad4) & Arity(Ad4, 8, 5)
    Circult(Ad0) & Type(Ad1) = Add
    Circult(Ad1) & Type(Ad1) = Add
    Circult(Ad2) & Type(Ad1) = Add
    Circult(Ad3) & Type(Ad1) = Add
    Connected(Out(1, X0), In(1, Ad0))
    Connected(Out(1, Y0), In(2, Ad0))
    Connected(Out(1, X1), In(1, Ad1))
    Connected(Out(1, Y1), In(2, Ad1))
    Connected(Out(1, X2), In(1, Ad2))
    Connected(Out(1, Y2), In(2, Ad2))
    Connected(Out(1, X3), In(1, Ad3))
    Connected(Out(1, Y3), In(2, Ad3))
    Connected(Out(2, Ad0), In(3, Ad1))
    Connected(Out(2, Ad1), In(3, Ad2))
    Connected(Out(2, Ad2), In(3, Ad3))
    Connected(Out(1, Ad0), In(1, Z0))
    Connected(Out(1, Ad1), In(1, Z1))
    Connected(Out(1, Ad2), In(1, Z2))
    Connected(Out(1, Ad3), In(1, Z3))
    Connected(Out(2, Ad3), In(1, Z4))
for n = 4, there are (2^4)^2 = 256 different inputs, correctness of the function can be verified by enumeration

8.27
∀c CanApplyForPassport(c) <=> (∃p CanProveCitizenship(p, c)) & (∃p Photo(p) & Recognizable(p, c)) & CanPay(c, Fee)

8.28
a.  Wrote(Gershwin, TheManILove)
b.  ~Wrote(Gershwin, EleanorRigby)
c.  Wrote(Gershwin, TheManILove) | Wrote(McCartney, TheManILove)
d.  ∃s Wrote(Joe, s)
e.  ∃d Own(Joe, d) & CopyOf(d, Revolver)
f.  ∀s Sings(McCartney, s, Revolver) => Wrote(McCartney, s)
g.  ~∃s,p Sings(p, s, Revolver) & Wrote(Gershwin, s)
h.  ∀s Wrote(Gershwin, s) => ∃p,a Sings(p, s, a)
i.  ∃a∀s Wrote(Joe, s) => ∃p Sings(p, s, a)
j.  ∃d,a CopyOf(d, a) & Own(Joe, d) & Sings(BHoliday, TheManILove, a)
k.  ∀a∃d (∃s Sings(McCartney, s, a)) => Own(Joe, d) & CopyOf(d, a)
l.  ∃d,a Own(Joe, d) & CopyOf(d, a) & (∀s,p Sings(p, s, a) => p = BHoliday)

9.1
a.  assume ∀v a & ~SUBST({v/g}, a)
    as g is a term, ~SUBST({v/g}, a) <=> SUBST({v/g}, ~a) => ∃v ~a
    ~(∀v a & ~SUBST({v/g}, a)), therefore ∀v a |= SUBST({v/g}, a)
b.  let kb be the original knowledge base, let kb' be kb after existential instantiation
    =>: if kb & ~b is satisfiable, there is a model m in which ~b and kb are true
        for a existential subsentence ∃v a in kb which is true in m
        there must be at least one object C that SUBST({v/C}, a) is true
        for ∃v a is false in m, assume the domain is not empty, ~(∃v a) <=> ∀v ~a
        there must be an object C that SUBST({v/C}, ~a) <=> ~SUBST({v/C}, a) is true in m
        bind new constants in kb' to these objects, kb' would also be true in model m, kb' & ~b is true in m
    <=: if kb' & ~b is satisfiable, there is a model m in which ~b and kb' are true
        for a subsentence a in kb' is true in m
        if C is a constant in a, ∃v SUBST({C/v}, a) is true in m
        for a is false in m, ~a is true, ∃v SUBST({C/v}, ~a) <=> ~∃v SUBST({C/v}, a) is true in m
        existential quantifiers can be recovered without changing the satisfiability, kb & ~b => kb & ~b

9.2
a |= ∃v SUBST({k/v}, a) where k is a constant in a

9.3
a.  not legitimate, Everest is mentioned in the KB
b.  legitimate
c.  not legitimate but is entailed by KB, existential instantiation should only be applied once

9.4
./AI/first_order/inference
a.  Some({'y': B, 'x': A, 'z': B})
b.  None
c.  Some({'x': John, 'y': x})
d.  None

9.5
a.  Employs(x, y)
    Employs(Mother(a), y) | Employs(x, Father(b))
    Employs(Mother(John), y) | Employs(Mother(a), Father(b)) | Employs(x, Father(Richard))
    Employs(Mother(John), Father(b)) | Employs(Mother(a), father(Richard))
    Employs(Mother(John), Father(Richard))
b.  Employs(x, y)
    Employs(y, y)
    Employs(IBM, y)
c.  first find the sentences in KB which has the query in its subsumption lattice (by hashing)
    let the sentences be a set S
    FETCH(s) then returns unifiers from 2^S, the power set of S

9.6
a.  Horse(x) => Mammal(x)
    Cow(x) => Mammal(x)
    Pig(x) => Mammal(x)
b.  Offspring(x, y) & Horse(y) => Horse(x)
c.  True => Horse(Bluebeard)
d.  True => Parent(Bluebeard, Charlie)
e.  Offspring(x, y) <=> Parent(y, x)
f.  Mammal(x) => Parent(F(x), x)

9.7
a.  Parent, everyone have parents, no one is parent of themself
b.  ∀x∃y P(x, y) skolemizes to P(x, F(x))
    ~∃q P(q, q) <=> ∀q ~P(q, q) <=> ~P(q, q)
    without occur check, {q/x, x/F(x)} is a unifier, {} is entailed by KB
c.  ∀x∃y P(x, y) skolemizes to P(x, Sk)
    {x/Sk, q/Sk} is a unifier of P(x, Sk) and ~P(q, q), {} is entailed by KB
d.  if θ = {Sk1/A} is a unifier between P(Sk1) and ~P(A)
    SUBST(θ, P(Sk1)) and ~P(A) derives {}, P(Sk1) |= P(A) for arbitrary A

9.8
assume the first clause is (x1,1 | ~x1,2 | ~x1,3)
    (True(x1,1) | False(x1,2) | False(x1,3)) & .. => SAT
where x1,1 are variables to a domain of two objects: True and False
1.  True(True)
2.  False(False)
3.  True(x) XOR False(x)

9.9
// + here is a function i.e. can be unified with variables
a.  7 <= 3 + 9, unifies with only 8: 7 <= y & y <= 3 + 9
    sub y <= 3 + 9, unifies with 7: w + t <= 3 + 9
        y = w + t
        sub w <= 3, unifies with 1 
            w = 0
        sub t <= 9, unifies with 2
            t = 7
    sub 7 <= y
        7 <= 0 + 7, unifies with 8
        sub y <= 0 + 7, unifies with 6
            y = 7 + 0
        sub 7 <= y
            7 <= 7 + 0, true by 4
b.  from 1, 2 and 7:
    (1):    0 + 7 <= 3 + 9
    from 6:
    (2):    7 + 0 <= 0 + 7
    from (1), (2) and 8:
    (3):    7 + 0 <= 3 + 9
    from 4:
    (4):    7 <= 7 + 0
    from (4), (3) and 9:
            7 <= 3 + 9

9.10
sentences
    ~∃x Brother(x, I) | Sister(x, I)
    ∃x Son(x, Father(I)) & Father(Man) = x
after skolemization:
    1.  ∀x ~Brother(x, I) & ~Sister(x, I)
    2.  Son(C, Father(I))
    3.  Father(Man) = C
assume 
    4.  Father(Man) != I
from 3, 4 and transitivity of equation:
    (1):    C != I
from (1), 2 and family domain rules Father(x) = y => Parent(y, x):
    (2):    Parent(Father(I), C) & Parent(Father(I), I)
from (1), (2) and rule Sibling(x, y) <=> x != y & ∃p Parent(p, x) & Parent(p, y):
    (3):    Sibling(I, C)
from (3), 1 and the obvious Sibling(x, y) <=> Sister(x, y) | Brother(x, y):
    {}, contradiction
therefore Father(Man) = I, Son(Man, I)
the inference procedure have to understand transitivity of equations

9.11
S1: 
    Q1: O(1), assuming SSN is unique
    Q2: O(h), where h is the population of Houston
    Q3: O(p), where p is the total numbre of people in the database
    Q4: O(t) if ResidesIn(x, TinyTownUSA) is unified first, where t is the population of TinyTownUSA
S2:
    Q1: O(1)
    Q2: O(n)
    Q3: O(md) or O(n), where m is the number of mothers, d is the most children a mother may have in the database
        O(md) if queried by first argument of Mother, O(n) is queried by Mother predicate
    Q4: O(n)
S3:
    Q1: O(n)
    Q2: O(n) if everyone has an entry in ResidesIn table
    Q3: O(n) 
    Q4: O(n^2) if both table are unsorted
S4:
    same to S2 (how can the first argument be indexed without predicates?)
S5:
    Q1: O(1)
    Q2: O(h)
    Q3: O(n)
    Q4: O(t)

9.12
if a rule is applied multiple times during a proof and the variables are not standardized in place
the rule may fail to apply as the same variable cannot have two substitution at the same time 
e.g. in natural number domain
    Nat(n) => Nat(S(n))
to prove Nat(S(S(0))), the above rule must be applied twice
after the first application, n/S(0) ∈ θ
if sentences are standardized once and forall before inference, the second time will fail to unify

9.13
a.  ∃h Horse(h)
    and Offspring(h, y) // Offspring of a horse rule
        Parent(y, h) // Offspring definition
        or  Parent(Bluebeard, Charlie)
            y = Bluebeard, h = Charlie
        or  Mammal(h)
            Horse(h)
            // infinite loop from here
    and Horse(y) 
        // infinite loop from here
b.  the inference falls into an infinite loop from Horse(h) to Horse(h)
c.  Bluebeard and Charlie
d.  https://apps.dtic.mil/dtic/tr/fulltext/u2/a172502.pdf 4.1.4
    "In general, it is not decidable whether or not a given portion of a recursive
    search space is redundant. However, there are special cases where it is possible to
    prove redundancy without completely exploring the space. For repeating inference,
    a simple syntactic solution is possible. We can decide when to cut off inference by
    keeping track of the answers produced with each additional level of repetition. For
    divergent inference the problem is much harder. Here we must generate automatic
    proofs that no answers exist in a portion of the search space. These proofs are
    similar to proofs of program termination using well-founded sets."
    some kind of meta-analysis (auto-prove the redundency of part of the proof tree)

9.14
// skipped, refer figure 9.7

9.15
a.  P(A, [2, 1, 3])
    or  P(2, [2, 1, 3]), A = 2
    or  P((A, [1, 3]))
        or  P(1, [1, 3]), A = 1
        or  P(A, [3])
            or  P(3, [3]), A = 3
            or  P(A, []), stuck
    P(2, [1, A, 3])
    P(2, [A, 3])
    or  P(2, [2, 3]), A = 2
    or  P(2, [3])
        P(2, []), stuck
b.  Find / Member

9.16
// thanks https://swish.swi-prolog.org/
a.  sorted([]).
    sorted([_]).
    sorted([X, Y|Z]) :- sorted([Y|Z]), X =< Y.
b.  perm(X, Y) :- same_length(X, Y), contains(X, Y), contains(Y, X).
    contains([], _).
    contains([X|Z], Y) :- member(X, Y), contains(Z, Y).
c.  sort(L, M) :- perm(L, M), sorted(M).
d.  the algorithm filters all permutations of L by sorted, complexity is Ω(n! * n) 
e.  isort([], []).
    isort([X|Y], Z) :- isort(Y, I), insert(X, I, Z).
    insert(X, [], [X]).
    insert(X, [Y|Z], [X, Y|Z]) :- X =< Y.
    insert(X, [Y|Z], [Y|I]) :- X > Y, insert(X, Z, I).

9.17
a.  ∀X,Y simplify(X, Y) <=> (rewrite(X, Y) | ∃s rewrite(X, s) & simplify(s, Y)) & primitive(Y)
b.  x + y -> y + x
    x * 0 -> 0
    (x + y) + z -> x + (y + z)
    ..
c.  dx^n/dx -> nx^(n-1)
    dc/dx -> 0
    dy/dx -> 0
    d(-u)/dx -> -du/dx
    d(u + v)/dx -> du/dx + dv/dx
    duv/dx -> udv/dx + vdu/dx
    d(e^u)/dx -> e^u * du/dx
    ..
    // code skipped
    
9.18
solve(X, [X]) :- goal(X).
solve(X, [X|Y]) :- \+ goal(X), successor(X, Z), solve(Z, Y).
have no idea how to describe an efficient priority queue in prolog

9.19
a.  i.  {y/John} in 1st iteration
    ii. {y/John} in 2nd iteration
    iii.{} in 3rd iteration
    iv. never terminate
b.  no, the KB didn't state how to disprove Ancestor(x, y)
c.  no, exactly the same reason as above

9.20
a.  ∃p∀q S(p, q) <=> ~S(q, q)
b.  skolemization:
        ∃p S(p, q) <=> ~S(q, q)
        S(P, q) <=> ~S(q, q)
    1.  ~S(P, q) | ~S(q, q)
    2.  S(q, q) | S(P, q)
c.  SUBST({q/P}, 1):
    (1):    S(P, P)
    SUBST({q/P}, 2):
    (2):    ~S(P, P)
    from (1) and (2):
            {}

9.21
let True be the empty KB
True |= p <=> p is valid
if p is unsatisfiable, ~p is valid, True |= ~p

9.22
P(x), ~P(A) | ~P(B)
resolution gives ~P(A) or ~P(B)

9.23
a.  ∀x Horse(x) => Animal(x)
    ∀x,h HeadOf(h, x) & Horse(x) => Headof(h, x) & Animal(x)
b.  1.  ~Horse(x) | Animal(x) 
        ~(~(HeadOf(h, x) & Horse(x)) | (HeadOf(h, x) & Animal(x)))
        HeadOf(h, x) & Horse(x) & ~(HeadOf(h, x) & Animal(x))
        HeadOf(h, x) & Horse(x) & (~HeadOf(h, x) | ~Animal(x))
    2.  HeadOf(h, x)
    3.  Horse(x)
    4.  ~HeadOf(h, x) | ~Animal(h, x) 
    from 1 and 3:
    (1):    Animal(x)
    from (1) and 4:
    (2):    ~HeadOf(h, x)
    from (2) and 2:
            {}

9.24
a.  (A) for all natural numbers there is another natural number smaller than or equal to it
    (B) there is a natural number which is smaller than or equal to all natural numbers
b.  true, y = 0
c.  true, y = 0
d.  no, consider a domain with only ground facts n >= n for all natural number n
    A is true in this domain but B is not
e.  yes
f.  =>: ∃y∀x x >= y
        ~∀x∃y x >= y
            ∃x∀y ~(x >= y)
        skolemization:
        1.  x >= C0
        2.  ~(C1 >= y)
        θ = {x/C1, y/C0}, 1 and 2 derives {}
    <=: ∀x∃y x >= y
        ~∃y∀x x >= y
            ∀y∃x ~(x >= y)
        skolemization:
        1.  x >= F(x)
        2.  ~(x >= G(x))
        no unification
g.  how is that possible

9.25
when there are only definite clauses, both afterward and backward chaining return a (generator of) single unifier
in which no variable can be bind to two different ground terms

9.26
no, satisfication / validity of first order logic is undecidable
hence any algorithm deciding True |= s for some first order sentence s will either:
    be incorrect on some inputs, or
    not terminate on some inputs

10.1
the two concepts are equivalent
every planning problem can be described as a finite searching problem
each fninite searching problem can be described as a planning problem
(treat atomic states as constants, actions as schemas on constants)

10.2
Fly(P1, JFK, JFK)
Fly(P1, JFK, SFO)
Fly(P2, SFO, SFO)
Fly(P2, SFO, JFK)

10.3
a.  At(Monkey, A) & At(Bananas, B) & At(Box, C) & Height(Monkey, Low) & Height(Box, Low) & Height(Bananas, High) &
    Place(A) & Place(B) & Place(C) & Small(Bananas)
b.  Action(Go(from, to),
        PRECOND:    Place(from) & Place(to) & At(Monkey, from) & Height(Monkey, Low),
        EFFECT:     ~At(Monkey, from) & At(Monkey, to))
    Action(Push(o, from, to),
        PRECOND:    Place(from) & Place(to) & At(Monkey, from) & At(o, from) & Height(Monkey, Low) & Height(o, Low),
        EFFECT:     ~At(Monkey, from) & At(Monkey, to) & ~At(o, from) & At(o, to))
    Action(ClimbUp(p, o),
        PRECOND:    Place(p) & At(o, p) & At(Monkey, p) & Height(Monkey, Low) & Height(o, Low)
        EFFECT:     On(Monkey, o) & ~Height(Monkey, Low) & Height(Monkey, High))
    Action(ClimbDown(p, o),
        PRECOND:    On(Monkey, o),
        EFFECT:     ~On(Monkey, o) & ~Height(Monkey, High) & Height(Monkey, Low))
    Action(Grasp(o, p, h),
        PRECOND:    At(Monkey, p) & At(o, p) & Height(Monkey, h) & Height(o, h) & Small(o),
        /// an object hold by the monkey doesn't have At and Height properties
        EFFECT:     Holding(o) & ~At(o, p) & ~Height(o, h))
    Action(Ungrasp(o, p, h),
        PRECOND:    At(Monkey, p) & Height(Monkey, h) & Holding(o),
        /// ungrasping an object leaves it at where the monkey is
        EFFECT:     ~Holding(o) & At(o, p) & Height(o, h))
c.  Holding(Bananas, s) & ∃p At(Box, p, s0) & At(Box, p, s) & Following(s, s0)
    Following(s', s) <=> ∃a (Poss(a, s) & s' = Result(a, s)) | (∃s'' Poss(a, s'') & Following(s'', s) & s' = Result(a, s''))
d.  Action(Push(o, from, to),
        PRECOND:    Place(from) & Place(to) & At(Monkey, from) & At(o, from) & Height(Monkey, Low) & Height(o, Low) & ~Heavy(o)
        EFFECT:     ~At(Monkey, from) & At(Monkey, to) & ~At(o, from) & At(o, to))

10.4
a.  Action(Go(x, y, r),
        PRECOND:    In(x, r) & In(y, r) & At(Shakey, x),
        EFFECT:     ~At(Shakey, x) & At(Shakey, y))
    Action(Push(b, x, y, r),
        PRCOND:     Box(b) & In(x, r) & In(y, r) & In(b, r) & At(Shakey, x) & At(b, x),
        EFFECT:     ~At(b, x) & ~At(Shakey, x) & At(b, y) & At(Shakey, y))
    Action(ClimbUp(x, b),
        PRECOND:    Box(b) & At(b, x) & At(Shakey, x) & On(Shakey, Floor),
        EFFECT:     ~On(Shakey, Floor) & On(Shakey, b))
    Action(ClimbDown(b, x),
        PRECOND:    Box(b) & On(Shakey, b) & At(Shakey, x) & At(b, x),
        EFFECT:     ~On(Shakey, b) & On(Shakey, Floor))
    Action(TurnOn(x, s, b),
        PRECOND:    Box(b) & At(Shakey, x) & At(b, x) & At(s, x) & On(Shakey, b) & ~SwitchOn(s)
        EFFECT:     SwitchOn(s))
    Action(TurnOff(x, s, b),
        PRECOND:    Box(b) & At(Shakey, x) & At(b, x) & At(s, x) & On(Shakey, b) & SwitchOn(s)
        EFFECT:     ~SwitchOn(s))
    Init(
        In(S4, Room4) & In(Door4, Room4) & 
        In(S3, Room3) & In(Door3, Room3) & In(I0, Room3) &
        In(S2, Room2) & In(Door2, Room2) & 
        In(S1, Room1) & In(Door1, Room1) & In(B4, Room1) & In(B3, Room1) & In(B2, Room1) & In(B1, Room1) &
        In(Door4, Corridor) & In(Door3, Corridor) & In(Door2, Corridor) & In(Door1, Corridor) &
        At(Switch4, S4) & At(Switch3, S3) & At(Switch2, S2) & At(Switch1, S1) &
        At(Box4, B4) & At(Box3, B3) & At(Box2, B2) & At(Box1, B1) & At(Shakey, I0) &
        SwitchOn(Switch4) & ~SwitchOn(Switch3) & ~SwitchOn(Switch2) & SwitchOn(Switch1) &
        On(Shakey, Floor) & 
        In(R2, Room2)
    )
    [
        Go(I0, Door3, Room3),
        Go(Door3, Door1, Corridor),
        Go(Door1, B2, Room1),
        Push(Box2, B2, Door1, Room1),
        Push(Box2, Door1, Door2, Corridor),
    ]

10.5
State(s):
    current state of the 
Transition(s, v, s', v', d):
    Turing machine on state s and input value v transits to state s', write v' to the cell, move to direction d 
LeftOf(c, c'):
    cell c is at left of cell c'
ValueOf(c, v):
    cell c has value v
/// strictly speaking, each action should have 4 variants: with PRECOND v = v' or v != v', s = s' or s != s'
/// otherwise the EFFECT may contain contradictions
Action(Stay(c, s, v, s', v'),
    PRECOND:    Pos(c) & State(s) & ValueOf(c, v) & Transition(s, v, s', v', S),
    EFFECT:     ~State(s) & State(s') & ValueOf(c, v'))
Action(Left(c, s, v, c', s', v'),
    PRECOND:    Pos(c) & State(s) & ValueOf(c, v) & Transition(s, v, s', v', L) & LeftOf(c', c),
    EFFECT:     ~State(s) & State(s') & ~ Value(c, v) & ValueOf(c, v') & ~Pos(c) & Pos(c'))
Action(Right(c, s, v, c', s', v'),
    PRECOND:    Pos(c) & State(s) & ValueOf(c, v) & Transition(s, v, s', v', R) & LeftOf(c, c'),
    EFFECT:     ~State(s) & State(s') & ~ Value(c, v) & ValueOf(c, v') & ~Pos(c) & Pos(c'))
Init(
    /// All transitions
    /// All tape cell values
    /// All LeftOf relations between cells
    /// Initial state of the machine
)
Goal(State(Sgoal)) for some state Sgoal

10.6
PDDL uses database semantics, a negative literal ~A in the goal requires the absence of A in the state
let S' = RESULT(a, S) for some state S and action a
let a' be a without negative literals in effects
obviously the resulting state may only contain more literals, RESULT(a', S) ⊆ S'
this conclusion can be easily generalized to sequence of actions by induction
therefore any solution to the original problem is a solution to the relaxed problem
consider a problem where:
Init(A)
Action(Move(),
    PRECONDS:   A,
    EFFECTS:    ~A & B)
GOAL(A & B)
the original problem has no solution, while the relaxed problem has a solution [Move()]
by removing negative literals from effects, the relaxed problem has a proper superset of solutions

10.7
/// init state and actions described in Figure 10.3
Goal(On(B, C) & On(A, B))
/// solutions described in Figure 10.3
it's impossible for an noninterleaving planner if the planner only explores optimal solutions to subgoals
for subgoal On(B, C), the optimal solution is [Move(B, Table, C)]
but then the other subgoal cannot be achieved without undoing the first subgoal and vice versa

10.8
forward classic planning is complete:
    state space in classic planning is finite
    a forward planning algorithm will eventually try each possible action from each possible states 
    the state space is fully explored, a solution will be found if exists
backward classic planning is as powerful as forward planning:
    a state in backward planning is a believe state in forward planning
    if there's a solution to a problem in forward planning
    applying the actions in reverse order, along the path the believe state is never empty
    backward planning is able to find the same solution

10.9
/// skipped

10.10
a.  by definition of (parallel) planning graphs
    level k of planning graph contains all literals that can be derived in at most k actions from initial state
    basis, k = 0:
        S0 = initial state, all literals in initial state can be derived in 0 steps 
    induction:
        Sk contains all literals which can be derived in at most k actions from initial state
        by persistent actions, Sk ⊆ Sk+1 
        if L ∈ S for some state S, S is the result of k+1 actions
        S = RESULT(a, S') for some a and S', where S' is the result of k actions
        hence S' ⊆ Sk is mutex free, L ∈ S ⊆ Sk+1
    the let n be final level of planning graph, by definition Sn+i = Sn for all i >= 0
    if a literal L ∉ Sn, L cannot be derived from initial state by finite actions
b.  similar to a.
    if there's a solution with length k, those actions are mutex free 
    let goal state be Sg, Sg ⊆ Sk

10.11
it describes a relaxed problem where multiple non-mutually-exclusive actions can take place at the same time

10.12
a.  sounds promising, would be applicable if the branching factor in forward direction is small
b.  same as above
c.  maintain a DAG-like structure during the search, where nodes are states and edges are actions
    let S be a state in the current DAG, if S satisfies all preconditions of action a
    add the action and its result to the DAG, add constraint Before(a', a) for each action a' incoming S
    it's still a partial-ordered planning algorithm, searching in a DAG instead of a tree
    depends on implementation details, this algorithm may be able to update the middle of a sequence of actions
    while forward / backward searching may only update end of an action sequence 

10.13
forward / backward searching maintains a set of linear sequences of plan and update the end of them

10.14
a.  when HaveArrow(t) is False, HaveArrow(t+1) <=> HaveArrow(t) & ~Shoot(t) is always False
b.  yes, by part a, an illegal action will not affect the state
    the plan, axioms and initial state still entails the goal
c.  no, Poss(a, s) will not be satisfied

10.15
a.  Plane(p) & At(p, from, s) & Airport(from) & Airport(to) => Poss(Fly(p, from, to), s)
b.  Poss(a, s) => (At(p, y, Result(a, s)) <=> a = Fly(p, x, y) & Airport(x) & Airport(y) & Plane(p) & At(p, x, s))
c.  Plane(p) & At(p, from, s) & Airport(from) & Airport(to) & ~Warped(p, s) => Poss(Teleport(p, from, to), s)
    Poss(a, s) =>   (At(p, y, Result(a, s)) <=> (a = Fly(p, x, y) | a = Teleport(p, x, y))) & 
                    (Warped(p, Result(a, s)) <=>  Warped(p, s) | a = Teleport(p, x, y))
d.  for all clauses ci in precondition of an action a:
        c1' & .. & cn' => Poss(a, s)
    where for ci = P(x1, .., xn), ci' = P(x1, .., xn, s)
    Poss(a, s) => for all fluents X(..):
        X(.., RESULT(a, s)) <=>
            (X(.., s) & a = { actions which will leave X alone }) |
            (a = { actions which will introduce X into the state })
            
10.16
a.  if g(t) is satisfiable, g(0) | .. | g(Tmax) is satisfiable, so it will find a solution
b.  it may find a plan where g(t) | g(t') can be proven satisfiable but not g(t) or g(t') alone
c.  would be non-trivial as WALKSAT doesn't has the idea of length or cost built in

11.1
divide the planning problem to two subplans:
    achievement: a plan to the goal
    maintenance: a plan maintains both the goal state and the quantity of resources
the cost of the whole plan is some linear combination of cost of the two plans, determined by the nature of the problem 
the objective is to find a plan with accpectable cost
for the chandelier suspending problem, the planner may find a solution which:
    achievement: throw the chandelier in the air
    maintenance: catch the chandelier and throw it again
but the cost will be far higher than properly suspending the chandelier from the ceiling
as the maintenance plan keeps both the state and resources, it can be repeated indifinitely

11.2
Action(Navigate(t, from, to),
    PRECOND:    Truck(t) & Place(from) & Place(to) & At(t, from),
    EFFECT:     ~At(t, from) & At(t, to))
Action(Deliver(t, p, from, to),
    PRECOND:    Truck(t) & Package(p) & Place(from) & Place(to) & At(t, from) & At(p, from),
    EFFECT:     ~At(t, from) & ~At(p, from) & At(t, to) & At(p, to))
Navigate and Deliver refines to a sequence of Forward(t), TurnLeft(t), TurnRight(t), ..
Each truck may only deliver one package at a time

11.3
fn refine(actions: &[Action]) -> (State, State) {
    let mut preconds = State::new();
    let mut effects = State::new();
    for action in actions {
        let net_preconds = action.preconds() - effects;
        /// union operations here removes a literal when both A and ~A presents
        preconds = preconds ∪ net_preconds;
        effects = effects ∪ actions.effects();
    }
    (preconds, effects)
}

11.4
as stated in the text, no certain conclusion can be drawn from these two facts

11.5
/// assuming the sequence is legal, precondition check can be skipped
/// otherwise both optimistic and pessimistic descriptions are undefined 
fn angelic(descs: &[Description]) -> Description {
    let mut opt = Optimistic::new();
    let mut pes = Pessimistic::new();
    for desc in descs {
        for (flag, term) in desc.opt() {
            /// optimistic descriptions are updated by bit or
            /// each term is tagged by a bitflag describing whether the term may be added, removed or both
            /// possible definition of Flag:
            /// type Flag = u8;
            /// const ADD = 0b01;
            /// const REMOVE = 0b10;
            opt[term] = opt[term] | flag;
        }
        for (sign, term) in desc.pes() {
            /// pessimistic descriptions are updated by overwriting 
            pes[term] = sign;
        }
    }
    Description::new(opt, pes)
}

11.6
if the nondeterminism is managed by believe states or conditional effects, these fields must be embedded into effects
in certain scenarios e.g. risk of ruin these quantities can be treated as intervals instead of set of possible outcomes
in general, if the resources are only constrained by lower and upper bounds, they can be treated as intervals 
otherwise the precise value of them matters and the planner must keep track of set of possible outcomes

11.7
a.  Action(Assign(a, b, va, vb),
        PRECOND:    Variable(a) & Variable(b) & ValueOf(a, va), ValueOf(b, vb),
        EFFECT:     ~ValueOf(a, va) & ValueOf(a, vb))
b.  Action(Let(a, v),
        PRECOND:    Symbol(a) & ~Variable(a), Value(v),
        EFFECT:     Variable(a) & ValueOf(a, v))
    Init(Variable(A) & Variable(B) & Value(VA) & Value(VB) & ValueOf(A, VA) & ValueOf(B, VB) & Symbol(C))
    Goal(ValueOf(A, VB) & ValueOf(B, VA))
    [
        Let(C, VA),
        Assign(A, B),
        Assign(B, C),
    ]

11.8
Action(Flip(v),
    PRECOND:    Variable(v),
    EFFECT:     when True(v): ~True(v), when ~True(v): True(v))
if True(A) ∈ S, Result(Flip(A), S) = S - True(A)
if True(A) ∉ S, Result(Flip(A), S) = S ∪ {True(A)}
1-CNF is maintained

11.9
Action(Move(b, x, y),
    PRECOND:    On(b, x) & Clear(b) & Clear(y),
    EFFECT:     when y = Table: On(b, Table) & Clear(x) & ~On(b, x)
                when y != Table: On(b, y) & Clear(x) & ~On(b, x) & ~Clear(y))

11.10
Action(Move(p),
    PRECOND:    Place(p),
    EFFECT:     At(p))
Action(Suck(p),
    PRECOND:    At(p),
    EFFECT:     Clean(p))
Init(At(Left | Right), Place(Left), Place(Right), Clean(Left)?, Clean(Right)?)
Goal(Clean(Left), Clean(Right))

11.11
Suck a column, look for dirty spots on the column, suck these spots until they are clean, move to the next column
a contigent plan with action monitoring

11.12
what medication problem?

12.1
constants:
    Marks: X, O
    Players: Po, Px
    Squares: Q11 .. Q33
    Initial state: S0
functions:
    Opponent(Px) = Po
    Opponent(Po) = Px
    MarkOf(Px) = X
    MarkOf(Po) = O
    TurnOf(S0) = Px
    TurnOf(Result(a, s)) = Opponent(TurnOf(s))
predicates:
    Win(p, s) <=> ∃q1,q2,q3 MarkAt(MarkOf(p), q1, s) & MarkAt(MarkOf(p), q2, s) & MarkAt(MarkOf(p), q3, s) &
        (
            (q1 = Q11 & q2 = Q12 & q3 = Q13) |
            ... /// winning positions
        )
    Empty(q, s) <=> ∀m ~MarkAt(m, q, s)
    Reachable(r, s) <=> r = s | r = Result(a, t) & Poss(a, t) & Reachable(t, s)
    Endgame(e, s) <=> Reachable(e, s) & ~∃a Poss(a, e)
    ForcedWin(p, s) <=> ∀e Endgame(e, s) => Win(p, e)
actions:
    PlaceMark(p, q)
situation calculus:
    ∀m,q ~MarkAt(m, q, S0)
    Square(q) & Player(p) & Empty(q, s) & ∀p ~Win(p, s) => Poss(PlaceMark(p, q), s)
    Poss(a, s) => MarkAt(m, q, Result(a, s)) <=> 
        (a = PlaceMark(p, q) & TurnOf(s) = p & MarkOf(p) = m) |
        MarkAt(m, q, s)
    
12.2
/// skipped

12.3
predicates:
    Above(t, b, s)
    Active(w, s)
    Legal(t, l, b, r) <=> t < b & l < r
    Focused(w, a) <=> a = Focus(w) | a = Create(w, ..) | a = Move(w, ..)
functions:
    /// order of N ∪ { None }: None is the new minimum
    Top(w, S0) = None
    Top(w, Result(Move(w, t, l, b, r), s)) = t
    Top(w, Result(Destory(w), s)) = None
    Top(w, Result(Create(w, t, l, b, r), s)) = t
    Top(w, Result(a, s)) = Top(w, s)
    Left(w, s) = .. // similar to Top
    Bottom(w, s) = .. 
    Right(w, s) = .. 
    State(w, S0) = Nonexist
    State(w, Result(Create(w, t, l, b, r), s)) = Displayed
    State(w, Result(Minimize(w), s)) = Minimized
    State(w, Result(Display(w), s)) = Displayed
    State(w, Result(a, s)) = State(s)
axioms:
    ∀x,y,z Above(x, y, s) & Above(y, z, s) => Above(x, z, s)
actions:
    State(w, s) = Nonexist & Legal(t, l, b, r) => Poss(Create(w, t, l, b, r))
    Exist(w, s) => Poss(Destory(w))
    State(w, s) = Displayed & Legal(t, l, b, r) => Poss(Move(w, t, l, b, r))
    State(w, s) = Displayed => Poss(Minimize(w))
    State(w, s) = Minimized => Poss(Display(w))
    Exist(w, s) => Poss(Bring(w))
    Exist(w, s) => Focus(w)
situation calculus:
    Poss(a, s) =>
        (Above(w, m, Result(a, s)) <=>
            /// new window is on top
            (Focused(w, a) & m != w & Exist(m, Result(a, s))) |
            /// inherit from the last situation
            (w != m & ~Focused(w, a) & ~Focused(m, a) & Exist(w, Result(a, s)) & Exist(m, Result(a, s)) & Above(w, m, s)) |
            /// transitivity
            (∃p Above(w, p, Result(a, s)) & Above(p, m, Result(a, s)))) & 
        (Active(w, Result(a, s)) <=> 
            Focused(w, a) |
            ((∀w ~Focused(w, a)) & Active(w, s)))

12.4
a.  Above(W2, W1, S0) & Left(W1, S0) < Left(W2, S0) & Right(W1, S0) > Right(W2, S0)
b.  State(w, s) = Displayed => Top(w, s) < Bottom(w, s)
c.  State(w, Result(Create(w, ..), s)) = Displayed
d.  State(w, s) = Displayed => Poss(Minimize(w))

12.5 - 12.6
/// skipped, the result would be either overly complicated or overly far-fetched

12.7
a.  ∀w w ∈ Water => FreezingPoint(w, KPa(100)) = Celsius(0) & BoilingPoint(w, KPa(100)) = Celsius(100)
    Liquid(w, t, p) <=> FreezingPoint(w, p) < t < BoilingPoint(w, p)
b.  ∀w w ∈ Water => BoilingPoint(w, KPa(100)) = Celsius(100)
c.  ∀w w ∈ Water & In(w, JohnsWaterBottle) => Frozen(w)
d.  Perrier ⊆ Water
e.  ∃w w ∈ Perrier & In(w, JohnsWaterBottle)
f.  ∀w (∃t,p Liquid(w, t, p)) => FreezingPoint(w, p) != None
g.  ∀w,a w ∈ Water & a ∈ Alcohol & Volumn(w) = Liter(1) & Volumn(a) = Liter(1) => Weight(w) > Weight(a)

12.8
a.  ExhaustivePartDecomposition(s, c) <=> (∀i PartOf(i, c) <=> ∃p PartOf(i, p) & p ∈ s)
b.  PartPartition(s, c) <=> ExhaustivePartDecomposition(s, c) & PairwiseDisjoint(s)
c.  PairwiseDisjoint(s) <=> (∀c1,c2,p c1 != c2 => (PartOf(p, c1) => ~PartOf(p, c2)))

12.9
1.  it's not type safe
    all unit functions map to real numbers, so one can compare Pound(Weight(A)) and Kilogram(Weight(A))
    or even worse, Pound(Weight(A)) and Inch(Length(A))
2.  there's no way to easily name an abstract quantity with unit as $(50)
    only as $(v) = 50 for some value v
3.  conversion between units looks like:
        2.54 * Centimeter(l) = Inch(l)

12.10
/// plural and singular forms of a name describe the same category
∀n,c Name(n, c) => Name(Plural(n), c) & Name(Singular(n), c)
/// a name followed by its generalization forms a name of the same category
/// yet it's hard to specify the definition of proper generalization
/// "Laptop PC" is a proper name for Laptop, but "Laptop Thing" is not
∀n,g,c,p Name(n, c) & Name(g, p) & ProperGeneralization(c, p) => Name(n + g, c)
/// and rule, would be much more complicated as "Laptop and Laptop" is not a proper category name
/// in reality this rule cannot be chained to arbitrary length
/// a fifty-word string consisted of synonyms of laptop is not a proper name
∀n1,n2,c Name(n1, c) & Name(n2, c) => Name(n1 + " and " + n2, c)

12.11
/// thanks solutions manual
predicates:
    Inbound(p) // position p is in the bound
    InFrontOf(p, d, t) // t is in front of p by direction d
functions:
    Left(North) = West // and other four directions
    Right(North) = East // and other four directions
    Front(p, d) = .. // position in front of direction d from position p, may be out of bound
Initiates(e, HaveArrow(a), t) <=> e = Start
Terminates(e, HaveArrow(a), t) <=> e = Shoot(a)
Initiates(Start, Facing(a, North), 0)
/// the agent may only facing one direction at a time
T(Facing(a, d), t) => ∀d' T(Facing(a, d'), t) => d = d'
T(TurnLeft(a), i) <=> 
    ∃h,d Meets(h, i) & T(Facing(a, d), h) => Clipped(Facing(a, d), i) & Restored(Facing(a, Left(d)), i)
T(TurnRight(a), i) <=> 
    ∃h,d Meets(h, i) & T(Facing(a, d), h) => Clipped(Facing(a, d), i) & Restored(Facing(a, Right(d)), i)
T(Forward(a), i) <=>
    ∃h,p Meets(h, i) & T(At(a, p), h) & T(Facing(a, d), h) & Inbound(Front(p, d)) => 
    Clipped(At(a, p), i) & Restored(At(a, Front(p, d)), i)
T(Grab(a), i) <=>
    ∃h,p Meets(h, i) & T(At(a, p), h) & T(Gold(p), h) => 
    Clipped(Gold(p), i) & Restored(HaveGold(a), i)
T(Shoot(a), i) <=>
    ∃h,p,t Meets(h, i) & T(At(a, p), h) & T(HaveArrow(a), t) & InFrontOf(p, d, t) & Wumpus(t) =>
    Clipped(WumpusAlive, i) & Restored(WumpusDead, i)
T(Climb(a), i) <=>
    ∃h Meets(h, i) & T(At(a, S11), h) => Clipped(At(a, S11), i) & Restored(OutOfCave(a), i)

12.12
During(IK, LK)
During(PK, LK)
During(LK, LJ)
Meet(LK, PJ)
Overlap(LK, LO)
Before(IK, PK)
During(IK, LJ)
Before(IK, PJ)
Before(IK, LO)
During(PK, LJ)
Meet(PK, PJ)
Overlap(PK, LO)
During(PJ, LJ)
Overlap(LJ, LO)
During(PJ, LO)

12.13
Allen, J. and Ferguson, G. (1994): Actions and Events in Interval Temporal Logic
http://www.cs.rochester.edu/u/james/Papers/AllenFerguson-events-actions.pdf
Pelavin, R. (1992): Planning with simultaneous actions and external events, in Reasoning About Plans
/// available on libgen
an example of combinatoric axiom explosion:
    say a set of actions mutually interfere
    if encoded naively, precondition of each action in the set must mension all the other actions
    resulting in axioms of length Ω(n^2)
a solution is described in Pelavin (1992)

12.14
$(n, t), maps integer n and a time instance t to the domain of abstract value 

12.15
T(Fixed(Location(x)), (t1, t2)) <=> ∃p∀t t1 <= t <= t2 => Location(x) = p

12.16
T(Trade(a, b, p, q), i) <=> 
    ∃h Meet(h, i) & T(Own(a, p), h) & T(Own(b, q), h) =>
    Clipped(Own(a, p), i) & Clipped(Own(b, q), h) & Restore(Own(a, q), i) & Restore(Own(b, p), i)
Buy(a, b, p, m) = Trade(a, b, p, $(m))

12.17
/// skipped

12.18
functions:
    King(p): number of king in a pair p
    Ace(p): number of ace in a pair p
/// one may only have A-A, A-K or K-K pairs 
1.  ∀a Ka(Has(a, A-A) | Has(a, A-K) | Has(a, K-K))
/// 4 kings and 4 aces in total
2.  ∀a,p1,p2,p3 Ka(Has(A, p1) & Has(B, p2) & Has(C, p3) =>
    King(p1) + King(p2) + King(p3) = 4 & Ace(p1) + Ace(p2) + Ace(p3) = 4)
/// Alice knows the pair of Bob and Carlos
3.  ∀p1,p2 Has(B, p1) & Has(C, p2) => Ka(Has(B, p1) & Has(C, p2))
/// similarly Bob and Carlos knows the pairs of others
a.  A-K
b.  ~∃p Ka(Has(A, p)) & Has(B, K-K)
    if Has(C, K-K)
    =>  Ka(Has(C, K-K) & Has(B, K-K)) // rule 3
        Ka(Has(A, A-A)) // rule 2 
    hence ~Has(C, K-K)
    similarly, ~∃p Ka(Has(B, p)) => ~Has(C, A-A)
    therefore Has(C, A-K) // rule 1
c.  ~Has(C, K-K) // rule 2
    if Has(C, A-A)
        Kb(~∃p Ka(Has(a, p)) & Ka(Has(C, A-A)))
        Kb(~Has(B, A-A))
        Kb(~∃p Kc(Has(a, p)) & Ka(Has(A, K-K)))
        Kb(~Has(B, K-K))
        Kb(Has(B, A-K))
    therefore Has(C, A-K)
d.  if Has(C, A-A), this game is the same to Game 2, Alice should be able to answer at the beginning of the second round
    if Has(C, K-K), this game is symmetric to Game 2, Alice should be able to answer
    therefore Has(C, A-K)
e.  lemma: if a game has a winner in some order (a permutation of [A, B, C]), it has a winner in any order
        let the sequence of answers be a = [A, B, C, A, B, C, ..]
        it's always possible to insert answers to the sequence, making it into another order
        e.g. [C, B, A] can be achieved by insert C between (A, B), A between (B, C), ..
        the extended sequence should still have a winner since:
            1.  inserting answers only add knowledge to each player, never removes them
            2.  at the end of the sequence, the player in turn has enough knowledge to answer the question
    part b proved the existence of a winner of {A-A, A-A, K-K} and {A-A, K-K, A-K}
    part c proved the existence of a winner of {A-K, A-K, K-K}
    part c proved the existence of a winner of {A-K, A-K, A-K}
    along with symmetric worlds (swap roles of A and K) and lemma above, these are all the possible worlds

12.19
a.  quite reasonable whenever with limited number of states (e.g. 52 cards in bridge)
b.  just as the text described, if logical omniscience is reasonable,
    these moves (complicating the situation) would never be advantageous
c.  quite reasonable: knowledge base is limited by cost & moderate in size and complexity
d.  if an agent can derive discrete logarithm from axioms immediately
    DH key exchange protocol or RSA makes no sense

12.20
∀m 
    (∃s1,s2,s3 s1 != s2 & s1 != s3 & s2 != s3 & Son(s1, m) & Son(s2, m) & Son(s3, m)) &
    (∃d1,d2∀d3 Daughter(d3, m) => d3 = d1 | d3 = d2) &
    (∀s Sone(s, m) => Unemployed(s) & Married(s) & ∀p Spouse(s, p) => Doctor(p)) &
    (∀d Daughter(d, m) => Professor(d) & (Department(d, Physics) | Department(Math, d)))
it's rather inconvenient to express AtLeast in first order logic

12.21
a.  ∀x Brand(x, Dodge) & Year(x, 1973) & Model(x, Vans) => Worth(x, 575) 
    ∀x Brand(x, Ford) & Year(x, 2010) & Model(x, F150) => Worth(x, 16500)
    ∀x Brand(x, Honda) & Year(x, 2017) & Model(x, Civic) => Worth(x, 13999)
    in worst case all such rules will be unified before the result is emitted
b.  backward chaining will have linear complexity
    while complexity of inheritance depends on the depth of inheritance heirarchy and usually is O(1)
c.  if predicates are properly indexed by all combination of predicates and arguments
    given the three facts about the car (Brand, Year and Model), the price can be queried in nearly O(1)
d.  if price of the car depends on non-uniform aspects of the car
    (e.g. not only Brand, Year and Model but also tens of exceptional conditions)
    there may not be an efficient indexing scheme 
e.  assuming the 3-tuple Year, Brand and Model completely defines Worth
    a hash table keyed by all the three predicates can give Worth of a car in average O(1) time

12.22
Subset(A, B) does not mean ∀x,y x ∈ A & y ∈ B => Subset(x, y)
x and y may not even be sets

12.23 - 12.25
/// skipped


13.1
P(a | b && a)    = P(a && b && a) / P(b && a)
                = P(a && b) / P(a && b)
                = 1

13.2
given by equation 13.1
all possible values of a random variable forms the sample space of possible worlds

13.3
a.  P(a | b && c) = P(b | a && c)
    =>  P(a && b && c) / P(b && c) = P(a && b && c) / P(a && c)
    =>  P(b && c) = P(a && c)
    =>  P(b && c) / P(c) = P(a && c) / P(c)
    =>  P(b | c) = P(a | c)
b.  a = "It's rainy in Bucharest today"
    b = "Jack has toothache"
    c = "Jack has cavity"
c.  let the domain be t ∈ N * N
    a = "t = (x, y) && x + y is even"
    b = "t = (0, _)"
    c = "t = (_, 0)"
    P(a | b) = 1/2
    P(a | c) = 1/2
    P(a | b && c) = 1

13.4
P(a || b) = P(a) + P(b) - P(a && b)
0.5 = 0.7 - P(a && b), P(a && b) = 0.2
if P(a || b) = 0.7, P(a && b) = 0
how rational it is depends on the believe of the agent
both 0.5 and 0.7 may be justified by the knowledge base

13.5
a.  if s1 and s2 are two distinct atomic events 
    there exists at least one boolean variable xi that xi ∈ s1 and ~xi ∈ s2
    s1 || s2 by resolution derives {}, hence s1 || s2 is unsatisfiable
b.  for an arbitrary assignment, there is a corresponding proposition in the disjunction
    therefore the disjunction is true for any possible model / assignment
    the disjunction is true in all models => true |= disjunction
    as p |= true for all proposition p, true <=> disjunction
c.  same to b but in a subset of all possible worlds in which the proposition is true

13.6
P(a && b) + P(a && ~b) + P(~a && b) + P(~a && ~b) = 1 // 13.1
P(a || b)   = 1 - P(~(a || b)) // 13.2
            = 1 - P(~a && ~b)
            = P(a && b) + P(a && ~b) + P(~a && b)

13.7
a.  C(52, 5) = 2_598_960
b.  1 / 2_598_960
c.  royal stright flush: 
        4 atomic events
        4 / C(52, 5)
    four of a kind:
        13 * (52 - 4) = 624 atomic events
        624 / C(52, 5)

13.8
a.  0.108 + 0.012 + 0.016 + 0.064 = 0.2
b.  0.108 + 0.012 + 0.072 + 0.008 = 0.2
c.  0.108 + 0.012 = 0.12
d.  0.108 + 0.012 + 0.072 = 0.192

13.9
winning chance of player E:
    E ~ NB(7 - 2, 0.5), E >= 3
    P(E >= 3) = 1 - Σ(k ∈ {0,1,2})P(E = k) = 0.7734375
winning chance of player O:
    1 - P(E <= 7) = 0.2265625
the pot of money should be divided by their winning chance

13.10
a.  0.25^3 * (20 + 15 + 5 + 3) + // three in a row
    0.25^2 * (1 - 0.25) * 2 + // two cherries
    0.25 * ((1 - 0.25)^2 + (1 - 0.25) * 0.25)  // one cherry
    = 0.953125
b.  3 * 0.25^3 + 0.25^2 * (1 - 0.25)
    = 0.109375
c.  ./AI/uncertainty
    median <= 21
    mean = 216

13.11
