// rereading, lost all the notes / codes of the previous reading

Chapter 2
2.1-1
[ 31, 41, 59, 59, 41, 58 ]
[ 31, 41, 41, 59, 41, 58 ]
[ 31, 31, 41, 59, 41, 58 ]
[ 26, 31, 41, 59, 59, 58 ]
[ 26, 31, 41, 41, 59, 59 ]
[ 26, 31, 41, 41, 58, 59 ]

2.1-2
change line 5 to
    while i > 0 and A[i] < key

2.1-3
./CLRS/start/index.ts#linearSearch
loop invariant: 
    none of the first i items in the array equals to v
initialization:
    i == 0, loop invariant holds trivially
maintenance:
    every iteration, A[i] == v is checked
    the loop continues only when A[i] == v is false
termination:
    if the loop terminated early, then A[i] == v and the first i elements in the array are not equal to v
    therefore arr[i] is the first element equals to v
    if the loop terminated on loop condition, i = arr.length, the first i elements are the whole array
    none of the items in the array equals to v, so function returns NIL
    
2.1-4
Input: Two n-element sequence of 0 and 1s, representing two numbers a and b in binary form
Output: a (n+1)-element sequence of 0 and 1s, representing a number c == a + b in binary form
assumes little-endian
./CLRS/start/index.ts#addBinary

2.2-1
Θ(n^3)

2.2-2
invariant: 
    each of the the first i elements of the array are the ith smallest elements
the last element is greater or equal to all the previous items, thereby must be the greatest element
best-case and worst-case both Θ(n^2)

2.2-3
Σip(i) = (Σi) / n = (1 + n) * n / 2n = (1 + n) / 2 on average, Θ(n)
n on worst case, Θ(n)
assuming comparsion of integers takes constant time

2.2-4
hard-code the solution of a specific input in the program 
if input equals to the specific input, returns that solution immediately
base-case running time reduced to time required to check the input

2.3-1
[ 3, 41, 52, 26, 38, 57, 9, 49 ]
[ 3, 41, 26, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 9, 38, 49, 57 ]
[ 3, 9, 26, 38, 41, 49, 52, 57 ]
[ 3, 9, 26, 38, 41, 49, 52, 57 ]

2.3-2
./CLRS/start/mergesort.ts#mergeNoSentinel

2.3-3
when n = 2,
    T(n) = 2 = 2lg2
assume for n = 2^k, T(n) = nlgn = 2^klg(2^k) = k * 2^k
    T(2n)   = T(2^(k+1))
            = 2T(2^k) + 2^(k+1)
            = 2 * 2^k * k + 2^(k+1)
            = k * 2^(k+1) + 2^(k+1)
            = (k+1) * 2^(k+1)
            = (2n)lg(2n)
therefore for n = 2^k, k > 1,
    T(n) = nlgn

2.3-4
T(n)    = Θ(1)          when n = 1
        = T(n-1) + Θ(n) when n > 1

2.3-5
./CLRS/start/index.ts#binarySearch
T(n)    = Θ(1)          when n = 1
        = Θ(n/2) + Θ(1) when n > 1
by master theorem T(n) = Θ(lgn)

2.3-6
cannot improve
each iteration in insertion sort has to shift Θ(n) elements one place to the right
even if the right position to insert the element can be find in time Θ(lgn), shifting still takes Θ(n)
overall time still Θ(n^2)

2.3-7
first sort the array by mergesort
then for every element g in the sorted array, binary search x - g
(if the index of x - g equals the index of g, x = 2g, and such a pair doesn't exist)
./CLRS/index.ts#pairSum
mergesort: Θ(nlgn)
binary search: n * Θ(lgn) = Θ(nlgn)
overall: Θ(nlgn) + Θ(nlgn) = Θ(nlgn)

2-1
a.  insertion sort on an array of length k takes time Θ(k^2)
    there are n/k such arrays, overall running time Θ(k^2) * n / k = Θ(nk)
b.  the same with figure 2.5
    the height of the tree is reduced to lg(n/k)
    base level performs n/2k merges with arrays of length k, n/2k * Θ(k) = Θ(n) in total
    overall running time Θ(nlg(n/k))
c.  T(n) = Θ(nk + nlg(n/k))
    if k = ω(lgn), Θ(nk) = ω(nlgn), the running time of the modified algorithm then is asymptotically greater
d.  k = O(lgn), the precise value of k depends on cache size, hidden constant factors in algorithms, etc.

2-2
a.  it terminates in finite time on all inputs
b.  invariant:
        at the end of each iteration, the smallest element in slice A[j-1 .. A.length] is in A[j-1]
    initialization:
        j = A.length, the first iteration compares A[A.length] to A[A.length - 1], put the smaller in A[A.length - 1]
        which is the smallest in A[A.length - 1 .. A.length]
    maintenance:
        the smallest number is compared with A[j-1], the smaller of the two is swapped to A[j-1]
        inductively A[j-1] now holds the smallest number in A[j-1 .. A.length]
    termination:
        j = i+1, A[i] holds the smallest number in A[i .. A.length]
c.  invariant:
        at the end of each iteration, A[1..i] consists of ith smallest elements and is sorted in non-decreasing order
    initialization:
        at the end of the first iteration, the smallest element in A[1 .. A.length] is placed in A[1]
        it is the smallest element, A[1 .. 1] is trivially sorted
    maintenance:
        the inner loop finds the smallest number in A[i .. A.length] and puts it in A[i]
        A[1 .. i-1] consists of the i-1 smallest elements in A, therefore A[i] is the ith smallest number
        by definition A[i] >= A[i-1], A[1..i] is sorted 
    termination:
        A[1..A.length - 1] consists of A.length - 1 smallest numbers and is sorted
        thereby A[A.length] must be the greatest element in A
        A is sorted in non-decreasing order
d.  inner loop Θ(n)
    outer loop run n - 1 times
    overall running time (n-1) * Θ(n) = Θ(n^2)
    both the best and worst case of bubble sort performs Θ(n^2) comparsions
    while insertion sort in best case has running time Θ(n)

2-3
a.  the algorithm performs n additions and n multiplications
    assuming both are contant time, T(n) = Θ(n)
b.  ./CLRS/start/index.ts#naivePolynomial
    k = Θ(n), Math.pow(x, k) = x^k if implemented naively takes time Θ(k), if not takes time Θ(lgk)
    overall running time Θ(n^2) or Θ(nlgn)
c.  initialization:
        initially y = 0, the sum of an empty sequence
    maintenance:
        y = Σ(k ∈ {0..n-(i+1)})a(k+i+1)x^k = a(i+1) + a(i+2)x + .. + an * x^(n-(i+1)) at the start
        y = ai + xy = ai + a(i+1)x + .. + an * x^(n-i) = Σ(k ∈ {0..n-i})a(k+i)x^k
    termination:
        the end of the last iteration ends with i = 0, the next iteration (not executed) starts with i = -1
        y = Σ(k ∈ {0..n})ak * x^k
d.  as above

2-4
a.  (0, 4), (1, 4), (2, 3), (2, 4), (3, 4)  // zero-based index
b.  [n, n-1 .. 1], every pair is an inversion
    there are C(n, 2) = n(n-1)/2 pairs
c.  every assignment in the insertion sort reduces the total number of inversions by 1
    the sorted array has no inversions
    therefore the number of inversions in an array is a lower bound of the running time of insertion sort
d.  assume an array A[p..r] and some q that p < q < r, then the total number of inversions in A[p..r] is the sum of
    1.  the number of inersions in A[p..q]
    2.  the number of inversions in A[q+1..r]
    3.  the number of inversions as pairs (i, j) such that
            i in {p..q}, j in {q+1..r}
    for every index i in {p..q}, the number of type 3 inversions is exactly the number of indices j in {q+1..r} that
        A[i] > A[j]
    which can be calculated in a slightly modified merge function
    ./CLRS/start/mergesort.ts#inversionCount

Chapter 3
3.1-1
max(f(n), g(n)) <= f(n) + g(n) for all n
assume f(n) >= g(n), max(f(n), g(n)) = f(n) = (f(n) + f(n)) / 2 >= (f(n) + g(n)) / 2
symmetrically when g(n) >= f(n), max(f(n), g(n)) >= (f(n) + g(n)) / 2
therefore let c1 = 1, c2 = 1/2,
    1/2(f(n) + g(n)) <= max(f(n), g(n)) <= f(n) + g(n)
    max(f(n), g(n)) = Θ(f(n) + g(n))

3.1-2
(n + a)^b = Σ(k ∈ {0..b})(C(b, k) * n^k * a^(b-k))
the term with highest order is n^b, therefore (n + a)^b = Θ(n^b)

3.1-3
O(n^2) is an upper bound, the set O(n^2) contains all functions from constant to quadratic
denote the running time of algorithm A by T(n)
the statement can then be translated to "T(n) is at least any constant (including 0) for large enough n"
which is meaningless for a asymptotically non-negative function

3.1-4
2^(n+1) = 2 * 2^n = Θ(2^n)
2^2n / 2^n = 2^n, no constant can be asymptotically larger than 2^n

3.1-5
=>: f(n) = Θ(g(n)), c1g(n) <= f(n) <= c2g(n) for n >= n0, then trivally f(n) = O(g(n)) and f(n) = Ω(g(n))
<=: f(n) = O(g(n)) implies f(n) <= c1g(n) for n >= n1
    f(n) = Ω(g(n)) implies f(n) >= c2g(n) for n >= n2
    take n3 = max(n1, n2), c1g(n) <= f(n) <= c2g(n) for n >= n3, f(n) = Θ(g(n))
therefore f(n) = Θ(n) <=> f(n) = O(g(n)) and f(n) = Ω(g(n))

3.1-6
f(n) = Θ(g(n)) => f(n) = O(g(n)), for all inputs g(n) is an upper bound of f(n)
so even in the worst case f(n) = O(g(n))
similarly in the best case f(n) = Ω(g(n))

3.1-7
assume f(n) = o(g(n)) and f(n) = ω(g(n)), then
lim(f(n) / g(n)) = ∞ and lim(f(n) / g(n)) = 0, contradiction
so no such f(n) exist, o(g(n)) ∩ ω(g(n)) = ∅

3.1-8
Ω(g(n, m)) = {f(n, m):  there exist positive constants c, n0, m0 such that
                        cg(n, m) <= f(n, m) for all n >= n0 or m >= m0 }
Θ(g(n, m)) = O(g(n, m)) ∩ Ω(g(n, m))

3.2-1
for n1 >= n2, f(n1) >= f(n2), g(n1) >= g(n2), f(n1) + g(n1) >= f(n2) + g(n2)
thereby f(n) + g(n) is monotonically increasing
for n1 >= n2, g(n1) >= g(n2), f(g(n1)) >= f(g(n2))
thereby f(g(n)) is monotonically increasing

3.2-2
a^log(b, c) = (b^log(b, a))^log(b, c)
            = (b^log(b, c))^log(b, a)
            = c^log(b, a)

3.2-3
n! = (2πn)^(1/2) * (n/e)^n * (1 + Θ(1/n))
lg(n!)  = lg((2πn)^(1/2)) + lg((n/e)^n) + lg(1 + Θ(1/n))
        = 1/2lg(2πn) + nlg(n/e) + lg(1 + Θ(1/n))
        = Θ(lgn) + Θ(nlgn) + O(lgn)
        = Θ(nlgn)
n! = Πn, n! / 2^n = Π(k/2), lim(Π(k/2)) -> ∞, n! = ω(2^n)
n! / n^n = Π(k/n) <= 1/n, lim(1/n) -> 0, n! = o(n^n)

3.2-4
lg((lgn)!) = Θ(lgn * lglgn)
for large enough n,
c1(lgn * lglgn) <= lg((lgn)!) <= c2(lgn * lglgn)
e^c1(lgn * lglgn) <= (lgn)!
n^(c1 * lglgn) <= (lgn)!
as c1 * lglgn is not a constant, (lgn)! cannot be polynomially bounded
thanks https://ita.skanev.com/03/02/04.html
lg((lglgn)!)    = Θ(lglgn * lglglgn)
                = o(lglgn * lglgn)
                = o((lglgn)^2)
                = o(lgn)
asymptotically,
lg((lglgn)!) < lgn
(lglgn)! < e^lgn = n
therefore (lglgn)! is polynomially bounded

3.2-5
by definition, 
lg*lgn = lg*n - 1 = Θ(lg*n)
lg(lg*n) = Θ(lg(lg*n))
therefore lg*lgn is asymptotically larger

3.2-6
((1 + 5^(1/2)) / 2)^2 = (1 + 2 * 5^(1/2) + 5) / 4 = (3 + 5^(1/2)) / 2 = (1 + 5^(1/2)) / 2 + 1
((1 - 5^(1/2)) / 2)^2 = (1 - 2 * 5^(1/2) + 5) / 4 = (3 - 5^(1/2)) / 2 = (1 - 5^(1/2)) / 2 + 1

3.2-7
let g and g' denote golden ratio and its conjugate, r5 denotes square root of 5
g - g' = r5
g^2 = g + 1, g'^2 = g' + 1
F1 = 1 = (g - g') / r5
F2 = 1 = (g^2 - g'^2) / r5
assume Fi = (g^i - g'^i) / r5, Fi+1 = (g^(i+1) - g'^(i+1)) / r5
    (g^(i+2) - g'^(i+2)) / r5   = (g^i * g^2 - g'^i * g'^2) / r5
                                = (g^i * (g + 1) - g'^i * (g' + 1)) / r5
                                = (g^i - g'^i) / r5 + (g^(i+1) - g'^(i+1)) / r5
                                = Fi + Fi+1
                                = Fi+2

3.2-8
by symmetry law
    n = Θ(klnk)
as ln(n) is monotonically increasing
    c1klnk <= n <= c2klnk
    ln(c1klnk) <= ln(n) <= ln(c2klnk)
    lnk + lnlnk + c1' <= ln(n) <= lnk + lnlnk + c2'
    ln(n) = Θ(lnk)
    lnk = Θ(ln(n))
    k = Θ(n) / lnk = Θ(n) / Θ(ln(n)) = Θ(n / ln(n))

3-1
a.  k >= d, p(n) / n^k = Σ(ai * n^(i - k))
    each i - k <= 0, therefore lim(p(n) / n^k) <= ad
    take c = ad + ε, where ε is an arbitrary positive number
    there must exist n0 such that for n >= n0, lim(p(n) / cn^k) < 1, p(n) = O(n^k)
b.  k <= d, p(n) / n^k = Σ(ai * n^(i - k))
    lim(p(n) / n^k) >= ad
    take c = ad/2, with large enough n, cn^k <= p(n), p(n) = Ω(n^k)
c.  k == d <=> k <= d && k >= d
    combine a and b, p(n) = O(n^k) && p(n) = Ω(n^k) => p(n) = Θ(n^k)
d.  if k > d, lim(p(n) / n^k) = 0, p(n) = o(n^k)
e.  if k < d, lim(p(n) / n^k) = ∞, p(n) = ω(n^k)

3-2
a.  y   y   n   n   n
b.  y   y   n   n   n
c.  n   n   n   n   n
    n^sin(n) swings between 1/n and n
d.  n   n   y   y   n
    lim(2^n / 2^(n/2)) = lim(2^(n/2)) = ∞
e.  y   n   y   n   y 
    by 3.16, n^lgc = c^lgn
f.  y   n   y   n   y
    lg(n!) = Θ(nlgn)
    lg(n^n) = nlgn = Θ(nlgn)

3-3
a.  1
    lg(lg*n)
    lg*(lgn) = lg*n - 1
    lg*n
    lnln(n)
    // polylogarithmics:
    2^lg*n // unsure
    (lgn)^(1/2)
    ln(n)
    (lgn)! = Θ(lgn * lglgn)
    (lgn)^2
    2^((2lgn)^(1/2)) // unsure
    // polynomials:
    n^(1/lgn)
    (2^(1/2))^lgn = n^(1/2)
    n 
    2^lgn = n
    nlgn
    lg(n!) = Θ(nlgn)
    n^2
    4^lgn = n^2
    n^3
    // exponentials:
    (lgn)^lgn = n^lglgn
    n^lglgn
    (3/2)^n
    2^n
    n * 2^n
    e^n
    // super-exponentials:
    n!
    (n+1)!
    2^(2^n)
    2^(2^(n+1))
b.  the fastest growing function here is 2^(2^(n+1))
    2^(2^(n+2)) * |sin(n)|

3-4
a.  false, n = O(n^2), n^2 != O(n)
b.  false, let f(n) = n^2, g(n) = n, min(f(n), g(n)) = n, f(n) + g(n) = Θ(n^2) != Θ(n)
c.  f(n) = O(g(n))
    f(n) <= c1g(n)
    lg(f(n)) <= lg(c1(g(n))) = lg(g(n)) + c2 = O(lg(g(n)))
d.  false
    f(n) = O(g(n))
    f(n) <= c1g(n)
    2^f(n) <= 2^c1g(n) = (2^c1)^g(n)
    let f(n) = 2n, g(n) = n
    2^f(n) = 2^2n, 2^g(n) = 2^n, 2^2n != O(2^n)
e.  false, let f(n) = 1/n, f^2(n) = (1/n)^2 = 1/n^2
    lim(f(n) / f^2(n)) = ∞, f(n) = ω(f^2(n))
f.  f(n) = O(g(n))
    f(n) <= c1g(n)
    (1/c1)f(n) <= g(n)
    g(n) = Ω(f(n))
g.  false, let f(n) = 2^n, f(n/2) = 2^(n/2), lim(f(n) / f(n/2)) = ∞, f(n) = ω(f(n/2))
h.  for any g(n) ∈ o(f(n)), lim(g(n) / f(n)) = 0
    for large enough n, lim((f(n) + g(n)) / f(n)) = 1
    let c1 = 1, c2 = 1 + ε, there must exist n0 such that for n >= n0,
        c1f(n) <= f(n) + g(n) <= c2f(n)
    and f(n) + g(n) = Θ(f(n))

3-5
a.  if f(n) != O(g(n)), there's no n0 and c that cg(n) >= f(n) for all n >= n0
    let c be an arbitrary constant, if only for finitely many n, f(n) >= cg(n)
    then take n0 be the greatest of such n, then for n >= n0+1, f(n) < cg(n), f(n) = O(g(n))
    thereby there must be infinitely many n such that f(n) >= cg(n) >= 0, f(n) = ∞Ω(g(n))
    so f(n) != O(g(n)) => f(n) = ∞Ω(g(n)) and f(n) != ∞Ω(g(n)) => f(n) = O(g(n))
    if f(n) = n and g(n) = n * |sin(n)|, then neither f(n) = O(g(n)) or f(n) = Ω(g(n))
b.  it is the complement of set O(g(n)), may work smoother in certain proofs
    it's harder to reason and less intuitive, f(n) = ∞Ω(g(n)) no longer gives an lower bound of f(n)
c.  =>: f(n) = Θ(g(n))  => c1g(n) <= f(n) <= c2g(n)
                        => f(n) = Ω(g(n)) and f(n) <= c2g(n)
        let f(n) = -n, g(n) = -n, take c1 = c2 = 1, f(n) = Θ(g(n))
        but |f(n)| = n > cg(n) for all positive constant c, f(n) != O'(g(n))
    <=: |f(n)| <= cg(n) => f(n) <= cg(n), so f(n) = O'(g(n)) implies f(n) = O(g(n))
        therefore f(n) = O'(g(n)) && f(n) = Ω(g(n)) => f(n) = Θ(g(n))
d.  ~Ωg(n) = {f(n): there exist positive constants c, k and n0 that
                    0 <= cg(n)lg^k(n) <= f(n) for all n >= n0 }
    ~Θg(n) = {f(n): there exist positive constants c1, c2, k1, k2 and n0 that
                    c1g(n)lg^k1(n) <= f(n) <= c2g(n)lg^k2(n) for all n >= n0 }
    =>: f(n) = ~Θ(g(n)) => c1g(n)lg^k1(n) <= f(n) <= c2g(n)lg^k2(n) for all n >= n0
        instantly f(n) = ~O(g(n)) and f(n) = ~Ω(g(n))
    <=: similar, take n0 be the maximum of the two

3-6
a.  n - c
b.  lg*(n)
c.  lg(n)
d.  lg(n) - 1
e.  lglg(n)
f.  ∞
g.  lglg(n)
h.  iter 0: n
    iter 1: n / lgn = (iter 0) / lgn
    iter 2: (n / lgn) / lg(n / lgn) = (iter 1) / (lgn - lglgn)
    iter 3: ((n / lgn) / (lgn - lglgn)) / lg((n / lgn) / (lgn - lglgn))
            = (iter 2) / ((lgn - lglgn) - lg(lgn - lglgn))
    the divisor is never greater than lgn
    therefore lower bound is Ω(log(lgn, n)) = Ω(lgn / lglgn)
    upper bound unknown

Chapter 4
4.1-1
still the maximum subarray, the left and right sum is initialized to -Infinity

4.1-2
./CLRS/start/max-subarray.ts#findMaximumSubarrayBrute

4.1-3
crossover happens between 1024 <= n0 <= 2048
mixing recursive and brute-force algorithms then the crossover is no longer noticeable

4.1-4
return tuple of (Option<Idx>, Option<Idx>, Sum)
initialize left-sum and right-sum to 0, left-max and right-max to None
if all array elements between low and high are non-positive, left-max and right-max will not be reassigned
return value will be (None, None, 0)

4.1-5
if tail_max is the maximum subarray of the form A[i .. j] in an array A[0 .. j]
then all subarrays of the form A[k .. i-1] where k <= i-1 sum to non-positive value
all subarrays of the form A[i .. k] where k < j sum to non-negative value
considering A[k .. j+1],
    if k < i
        the slice can be divided to A[k .. i-1] and A[i .. j+1], where A[k .. i-1] sums to non-positive
        sum of this slice is not greater than A[i .. j+1]
    if i < k <= j
        the sum of the slice can be expressed as sum(A[i .. j+1]) - sum(A[i .. k-1])
        where k - 1 < j and sum(A[i .. k-1]) >= 0
        sum of this slice is not greater than A[i .. j+1]
    if k = j+1
        the sum equals to A[j+1], and A[j+1] > sum(A[i .. j+1]) only if sum(A[i .. j]) < 0
therefore the new tail_max is either A[i .. j+1] or A[j+1], depends on whether sum(A[i .. j]) < 0
./CLRS/start/max-subarray.ts#findMaximumSubarrayLinear

4.2-1
((1, 3), (7, 5)) * ((6, 8), (4, 2))
S1 = B12 - B22 = 6;
S2 = A11 + A12 = 4;
S3 = A21 + A22 = 12;
S4 = B21 - B11 = -2;
S5 = A11 + A22 = 6;
S6 = B11 + B22 = 8;
S7 = A12 - A22 = -2;
S8 = B21 + B22 = 6;
S9 = A11 - A21 = -6;
S10 = B11 + B12 = 14;
P1 = A11 . S1 = 6;
P2 = S2 . B22 = 8;
P3 = S3 . B11 = 72;
P4 = A22 . S4 = -10;
P5 = S5 . S6 = 48;
P6 = S7 . S8 = -12;
P7 = S9 . S10 = -84;
C11 = P5 + P4 - P2 + P6 = 18;
C12 = P1 + P2 = 14;
C21 = P3 + P4 = 62;
C22 = P5 + P1 - P3 - P7 = 66;

4.2-2
./CLRS/start/matrix-mul.ts#strassen

4.2-3
extend size of matrix to the next power of 2
assume size of matrix A is n x n, the next power of 2 is 2^b, the extended matrix looks like
    A   0   and     B   0
    0T  1           0T  1
where 1 denotes (2^b - n) x (2^b - n) unit matrix, 0 denotes n x (2^b - n) zero metrix
the multiplication will be
    AB  0
    0T  1
then AB can be extracted from the result
as n is not a power of 2, 2^b <= 2n
the extension takes time at most (2^b)^2 = O((2n)^2) = O(n^2)
O(n^2) + T(2^b) <= O(n^2) + T(2n) = O(n^2) + Θ((2n)^lg7) = Θ(n^lg7) using strassen's method

4.2-4
assume the meaning of matrices in "3 x 3 matrices" and "n x n matrices" are the same
the problem didn't state what will happen when n > 3
it just gives a potentially easier way to calculate the base case, which is Θ(1) anyway
it's not even clear what kind of multiplication it means by "k multiplications", maybe scalar
so this assumption will not affect the overall complexity, o(n^lg7) not achievable this way

4.2-5
same as above, only gives an easier way to calculate the base case, which is Θ(1) anyway
states nothing about the complexity when n > 72

4.2-6
let A = transpose([A1, A2 .. Ak]), B = [B1, B2 .. Bk], each of Ai, Bj is a n x n matrix
then A . B will be kn x kn
A . B = (Ai . Bj), k^2 multiplications of n x n matrices in total
assume matrix multiplication is O(g(n)), then T(n) = O(k^2 * g(n))
using strassen's algorithm g(n) = n^ln7, T(n) = O(k^2 * n^ln7)

4.2-7
let p1 = (a+b)(c+d) = ac + ad + bc + bd
    p2 = ac
    p3 = bd
then 
    real component = p2 - p3
    complex component = p1 - p2 - p3

4.3-1
assume T(n-1) <= (n-1)^2
T(n)    <= (n-1)^2 + n
        = n^2 - 2n + 1 + n 
        <= n^2
implicitly c = 1, T(n) = O(n^2)

4.3-2
assume T([n/2]) <= lg(n/2)
T(n)    <= lg(n/2) + 1
        = lgn - 1 + 1
        <= lgn
implicitly c = 1, T(n) = O(lgn)

4.3-3
assume T([n/2]) >= c(n/2)lg(n/2)
T(n)    >= 2 * c(n/2)lg(n/2) + n
        = cnlg(n/2) + n
        = cnlgn - cn + n
take 0 < c < 1, then T(n) >= cnlgn, T(n) = Ω(nlgn)

4.3-4
assume T([n/2]) <= c(n/2)lg(n/2) + 1
T(n)    <= 2 * c(n/2)lg(n/2) + 1 + n
        = cnlgn - cn + n + 1
        <= cnlgn when c > 2
T(1)    <= clg1 + 1 = 1

4.3-5
assume T([n/2]) <= c(n/2)lg(n/2) + 1
for any c1n = Θ(n)
T(n)    <= 2 * c(n/2)lg(n/2) + 1 + c1n
        = cnlgn - cn + 1 + c1n
        <= cnlgn + 1 when c <= c1
thus T(n) = O(nlgn)
assume T([n/2]) >= c(n/2)lg(n/2) + 1
for any c1n = Θ(n)
T(n)    >= 2 * c(n/2)lg(n/2) + 1 + c1n
        = cnlgn - cn + 1 + c1n
        >= cnlgn + 1 when c <= c1
thus T(n) = Ω(nlgn)
T(1)    = clg1 + 1 = 1 = Θ(1)
therefore T(n) = Θ(nlgn)

4.3-6
assume T(n) <= nlgn
T(n)    <= 2 * (n/2 + 17)lg(n/2 + 17) + n
        <= 2 * (n/2)lg(n/2) + n
        = nlgn - n + n = nlgn
T(n) = O(nlgn)

4.3-7
assume T(n) <= cn^log(3, 4)
T(n)    <= 4 * c(n/3)^log(3,4) + n
        = 4 * n^log(3,4)/4 + n
        = n^log(3,4) + n
        stuck
assume T(n) <= c1n^log(3,4) - c2n
T(n)    <= 4 * c1(n/3)^log(3,4) - 4 * c2(n/3) + n
        = c1n^log(3,4) - (4/3) * c2n + n
        <= c1n^log(3,4) - c2n when 4/3 * c2 - 1 >= c2
T(n) = O(n^log(3,4))
assume T(n) >= c1n^log(3,4) + c2n
T(n)    >= 4 * (c1(n/3)^log(3,4) - c2(n/3)) + n
        = c1n^log(3,4) - (4/3)*c2n + n
        >= c1n^log(3,4) - c2n when (4/3) * c2 - 1 <= c2
T(n) = Ω(n^log(3,4))
therefore T(n) = Θ(n^log(3,4))

4.3-8
the conclusion is incorrect, the recurrence
    T(n) = 4T(n/2) + n^2
is case 2 of master theorem, which means T(n) = Θ(n^2lgn)

4.3-9
T(n) = 3T(n^(1/2)) + lgn
let m = lgn, then
T(2^m)  = 3T((2^m)^(1/2)) + m
        = 3T(2^(m/2)) + m
let S(m) = T(2^m)
S(m) = 3S(m/2) + m
assume S(m) <= c1m^lg3 - c2m
S(m)    <= 3c1(m/2)^lg3  - (3/2)c2m + m
        = c1m^lg3 - (3/2)c2m + m
        <= c1m^lg3 - c2m when (3/2)c1 - 1 < c2
S(m) = O(m^lg3)
similarly, S(m) = Ω(m^lg3), S(m) = Θ(m^lg3)
T(n) = T(2^m) = S(m) = Θ(m^lg3) = Θ(lgn^lg3)

4.4-1
T(n) = 3T(n/2) + n
n/2 every level, lgn levels in total
for i = 0, 1 .. lgn, ith level has 3^i nodes, each node is n/2^i
the base level has 3^lgn = n^lg3 nodes, each is Θ(1)
Σ(3/2)^i will not converge
T(n)    = Σ(i = {0..lgn - 1})(3/2)^i * n + Θ(n^lg3)
        = ((3/2)^lgn - 1) / (3/2 - 1) * n + Θ(n^lg3)
        = 2(n^(lg3 - 1)/(3/2) - 1) * n + Θ(n^lg3)
        = O(n^lg3) + Θ(n^lg3)
        = O(n^lg3)
assume T(n) <= c1n^lg3 - c2n
T(n)    <= 3c1(n/2)^lg3 - 3c2(n/2) + n
        = cn^lg3 - (3/2)c2n + n
        <= c1n^lg3 - c2n when (3/2)c2 - 1 >= c2

4.4-2
T(n) = T(n/2) + n^2
n/2 every level, lgn levels in total 
for i = 0, 1 .. lgn, ith level has a single node, each node is (n/2^i)^2 = n^2/4^i
the base level has 1 node, Θ(1) in total
T(n)    = Σ(i = {0 .. lgn - 1})(1/4)^i * n^2 + Θ(1)
        <= 1/(1 - 1/4) * n^2 + Θ(1)
        = O(n^2)
without induction, this must be a tight bound, as T(n) >= n^2

4.4-3
T(n) = 4T(n/2 + 2) + n, assume it's asymptotically equivalent to T(n) = 4T(n/2) + n
n/2 every level, lgn levels in total
for i = 0, 1 .. lgn, ith level has 4^i nodes, each node is n/2^i
the base level has 4^lgn nodes, Θ(n^2) in total
T(n)    = Σ(i = {0 .. lgn - 1})2^i * n + Θ(n^2)
        = (2^lgn - 1) / (2 - 1) * n + Θ(n^2)
        = (n/2 - 1) * n + Θ(n^2)
        = O(n^2)
assume T(n) <= c1n^2 - c2n
T(n)    <= 4 * (c1(n/2 + 2)^2 - c2(n/2 + 2)) + n
        = c1n^2 + 4c1n + 4c1 - 2c2n + 8 + n
        = c1n^2 + (4c1 - 2c2 + 1)n + 8
        <= c1n^2 - c2n when 2c2 - 4c1 >= c2 and n is big enough
therefore T(n) = O(n^2)

4.4-4
n - 1 every level, n levels in total
for i = 0, 1, .. n, ith level has 2^i nodes, each node is 1
the base level has 2^n nodes, Θ(2^n) in total
T(n)    = Σ(i = {0 .. n - 1})2^i + Θ(2^n)
        = O(2^n)
assume T(n) <= c2^n - 1
T(n)    <= 2 * c2^(n-1) - 2 + 1
        = c2^n - 1
therefore T(n) = O(2^n)

4.4-5
T(n) = T(n-1) + T(n/2) + n
the longest simple path is of length n
as n - 1 + n/2 < (3/2)n, the sum of ith level is smaller than (3/2)^i * n
the base level have at most 2^n nodes, Θ(2^n) in total
T(n)    <= Σ(i = {0 .. n - 1})(3/2)^i * n + Θ(2^n)
        = Θ((3/2)^n * n) + Θ(2^n)
        = O(2^n)
assume T(n) <= c2^n
T(n)    <= c2^(n-1) + c2^(n/2) + n
        <= c2^n for large enough n

4.4-6
thanks https://ita.skanev.com/04/04/06.html
the shortest simple path from top to root is log(3, n)
each level still cn, this time the binary tree up to level log(3, n) is guarenteed to be complete
therefore T(n) >= log(3, n) * cn = Θ(nlgn), T(n) = Ω(nlgn)

4.4-7
cn
4c(n/2)
16c(n/4)
...
lgn levels in total, ith level has 4^i nodes, each is cn/2^i
the base level has 4^lgn = n^2 nodes, Θ(n^2) in total
T(n)    = Σ(i = {0 .. lgn - 1})2^i * cn + Θ(n^2)
        = Θ(2^lgn * cn) + Θ(n^2)
        = Θ(n^2)
assume T(n) <= c1n^2 - c2n
T(n)    <= 4 * (c1(n/2)^2 - c2(n/2)) + cn
        = c1n^2 - 2c2n + cn
        <= c1n^2 - c2n when c2 >= c
T(n) = O(n^2), similarly T(n) = Ω(n^2)

4.4-8
as a is a constant, T(a) = Θ(1)
T(n) = T(n-a) + Θ(1) + cn
n/a levels in total, ith level has 1 node, each node c(n - ia) + Θ(1)
base level a single node of Θ(1)
T(n)    = Σ(i = {0 .. n/a - 1})(c(n - ia) + Θ(1)) + Θ(1)
        = Θ(n/a) + cn^2/a - Θ((n/a)^2) * a
        = Θ(n^2)

4.4-9
reuse the solution to T(n) = T(n/3) + T(2n/3) + O(n) in text and problem 4.4-6
T(n) = Ω(nlgn) and T(n) = O(nlgn), T(n) = Θ(nlgn)

4.5-1
a.  a = 2, b = 4, log(b, a) = 1/2, f(n) = 1 = n^0, 1/2 > 0
    T(n) = Θ(n^(1/2))
b.  a = 2, b = 4, log(b, a) = 1/2, f(n) = n^(1/2) = n^log(b, a)
    T(n) = Θ(n^(1/2)lgn)
c.  a = 2, b = 4, log(b, a) = 1/2, f(n) = n, 1/2 < 1
    T(n) = Θ(n)
d.  a = 2, b = 4, log(b, a) = 1/2, f(n) = n^2, 1/2 < 2
    T(n) = Θ(n^2)

4.5-2
log(4, a) < log(2, 7) = log(4, 49)
a < 49

4.5-3
a = 1, b = 2, log(b, a) = 0, f(n) = 1 = n^0 = n^log(b, a)
T(n) = Θ(lgn)

4.5-4
a = 4, b = 2, log(b, a) = 2, f(n) = n^2lgn
f(n) = Ω(n^log(b, a)) but not polynomially larger, master method doesn't apply

4.5-5
f(n) = n^(ε + |sin(n)|), a = 1, b = 2 for some small positive constant very close to 0
log(b, a) = 0, ε + |sin(n)| >= ε > 0
for any n/2 = 2kπ + π/2, sin(n/2) = 1, sin(n) = 0
af(n/b) = (n/2)^(ε + |sin(n/2)|) >= n/2
when n is large
cf(n) <= n^ε < n/2 for infinitely many k and n

4.6-1
n0 = n, n1 = [n/b], n2 = [[n/b]/b]
if b is an integer
n = kb + r, 0 <= r < b, [n/b] = k if r = 0, k + 1 if r > 0
as b is an integer, b > 1 => b >= 2, k = k'b + r', 0 <= r' < b, then
[[n/b]/b]   = k' if r = r' = 0
            = k' + 1 otherwise
n = kb + r = (k'b + r')b + r = k'b^2 + r'b + r
where r < b, r'b <= b(b-1), r'b + r < b^2
[n/b^2] = k' if r = r' = 0
        = k' + 1 otherwise
therefore [[n/b]/b] = [n/b^2] for all integer n
n2 = [[n/b]/b] = [n/b^2]
n3 = [n2/b] = [n/b^3]
...
nj = [n/b^j]

4.6-2
f(n) = Θ(n^log(b, a)lg^kn), then
g(n)    = Σ(j{0 .. log(b, n) - 1})(a^j * f(n/b^j))
        = {0 .. log(b, n) - 1})(a^j * Θ((n/b^j)^log(b, a) * lg^k(n/b^j)))
where
    Θ((n/b^j)^log(b, a) * lg^k(n/b^j)))
    = Θ((n^log(b, a) / a^j) * lg^k(n/b^j)
g(n)    <= Σ{0 .. log(b, n) - 1})(a^j * c1(n^log(b, a) / a^j) * lg^k(n/b^j))
        = Σ(c1 * n^log(b, a) * lg^k(n/b^j))
        = Σ(c1 * n^log(b, a) * lg(n / b^j)^k)
        = Σ(c1 * n^log(b, a) * (lgn - j * lgb)^k)
        <= c1 * n^log(b, a) * Σ(lg^k(n))
        = c1n^log(b, a) * log(b, n) * lg^k(n)
        = c1n^log(b, a) * O(lgn) * O(lg^k(n))
        = O(n^log(b, a) * lg^k+1(n))
similarly
g(n)    >= c2 * n^log(b, a) * Σ(j = {0 .. log(b, n) - 1})(lg(n/b^j)^k)
take only half of the summation terms,
g(n)    >= c2 * n^log(b, a) * Σ(j = {0 .. log(b, n) / 2})(lg(n/b^j)^k)
take the minimum over all summation terms
        >= c2 * n^log(b, a) * Σ(j = {0 .. log(b, n) / 2})(lg(n/b^(log(b, n) / 2))^k)
        = c2 * n^log(b, a) * (log(b, n) / 2)(lg(n^(1/2))^k)
        = c2 * n^log(b, a) * (log(b, n) / 2)(1/2 * lgn)^k
        = c2 * n^log(b, a) * Θ(lgn) * Θ(lg^kn)
        = Ω(n^log(b, a) * lg^(k+1)(n))
therefore T(n) = Θ(n^log(b, a)) + Θ(n^log(b, a) * lg^(k+1)(n))

4.6-3
thanks https://ita.skanev.com/04/06/03.html
af(n/b) <= cf(n)
=>  f(n)    >= (a/c)f(n/b)
            >= (a/c)^2f(n/b^2)
            ..
            >= (a/c)^if(n/b^i)
take i = log(b, n)
    f(n)    >= (a/c)^log(b, n)f(1)
            = Θ((a/c)^log(b, n))
            = Θ(n^log(b, a/c))
            = Θ(n^(log(b, a) - log(b, c)))
as c < 1, log(b, c) < 0, -log(b, c) > 0, let ε = -log(b, c)
    f(n)    >= Θ(n^(log(b, a) + ε))
    f(n)    = Ω(n^log(b, a) + ε)

4-1
a.  a = 2, b = 2, log(b, a) = 1, f(n) = n^4, 4 > 1
    2f(n/2) = n^4 / 8, c = 1/8 < 1
    T(n) = Θ(n^4)
b.  a = 1, b = 10/7, log(b, a) = 0, f(n) = n^1, 1 > 0
    c = 7/10 < 1
    T(n) = Θ(n)
c.  a = 16, b = 4, log(b, a) = 2, f(n) = n^2
    T(n) = Θ(n^2lgn)
d.  a = 7, b = 3, log(b, a) = log(3, 7) < 2, f(n) = n^2
    7f(n/3) = 7n/9, c = 7/9
    T(n) = Θ(n^2)
e.  a = 7, b = 2, log(b, a) = lg7 > 2, f(n) = n^2
    T(n) = Θ(n^lg7)
f.  a = 2, b = 4, log(b, a) = 1/2, f(n) = n^(1/2)
    T(n) = Θ(n^(1/2)lgn)
g.  n - 2 every level, n/2 levels in total
    every level has a single node, each contributes (n - 2i)^2
    the base level has a single node of Θ(1)
    T(n)    = Σ(i = {0 .. n/2 - 1})(n - 2i)^2 + Θ(1)
            <= n/2 * n^2 + Θ(1) = O(n^3)
    similarly, take only half of the summation terms
    T(n)    >= Σ(i = {0 .. n/4})(n - 2i)^2 + Θ(1)
            >= Σ(i = {0 .. n/4})(n - n/2)^2 + Θ(1)
            = (n/4) * (n/2)^2 + Θ(1) = Ω(n^3)
    therefore T(n) = Θ(n^3)

4-2
a.  1.  Θ(lgN) as usual
    2.  now each call have to copy the whole array
        the function at most recursively call itself lgn times
        total cost NlgN
    3.  T(n) = T(n/2) + n
        T(N) = Θ(N) by master method
b.  1.  Θ(NlgN) as usual
    2.  all recursive call to the function itself forms a complete binary tree of height lgN
        2^lgN = N nodes in total, the whole array is copied at each node, contributes N * N = N^2 in total
        the number of merge is half the number of nodes, again Θ(N) and contributes Θ(N^2) in total
        overall running time Θ(N^2)
    3.  T(n) = 2T(n/2) + 2 * (n/2) + n = 2T(n/2) + Θ(n) = Θ(nlgn)

4-3
a.  a = 4, b = 3, log(b, a) = log(3, 4) > 1, f(n) = nlgn = O(n^(1 + ε))
    T(n) = Θ(n^log(3, 4))
b.  T(n) = 3T(n/3) + n/lgn = 3T(n/3) + cn/log(3, n)
    3/n every level, log(3, n) levels in total
    ith level has 3^i nodes, contributes 3^i * c(n/3^i) / log(3, (n/3^i)) = cn / (log(3, n) - i)
    the base level has 3^log(3, n) = n nodes, Θ(n) in total
    T(n)    = Σ(i = {0 .. log(3, n) - 1})(n / (log(3, n) - i)) + Θ(n)
            = n * Σ(i = {0 .. log(3, n) - 1}(1 / (log(3, n) - i))) + Θ(n)
    the harmonic series Σ(i = {0 .. n - 1})(1 / (n - i)) is asymptotically close to ln(n)
    T(n)    = n * Θ(ln(log(3, n))) + Θ(n)
            = Θ(nlglgn)
c.  a = 4, b = 2, log(b, a) = 2, f(n) = n^2.5, 2.5 > 2
    T(n) = Θ(n^2.5)
d.  guess with master method, T(n) = Θ(nlgn)
    assume T(n) <= nlgn - cn
    T(n)    <= 3((n/3 - 2) * lg(n/3 - 2)) - 3c(n/3 - 2) + n/2
            <= nlg(n/3 - 2) - 3c(n/3 - 2) + n/2
            <= nlg(n/3) - cn + 6c + n/2
            = nlgn - (c + lg3 - 1/2)n + 6c
            <= nlgn - cn when n is large enough
    simlarly T(n) >= nlgn + cn for some c, T(n) = Θ(nlgn)
e.  similar to b, T(n) = Θ(nlglgn)
f.  the shortest path from bottom to root passes log(8, n) = lgn/3 nodes
    immediate children of a node of value p has combined value p/2 + p/4 + p/8 = 7p/8
    therefore ith level contributes (7/8)^i * n
    there are 3^(lgn/3) = n^(lg3 / 3) nodes at level lgn/3, each Θ(1), Θ(n^(lg3 / 3)) in total
    T(n)    >= Σ(i = {0 .. lgn/3 - 1})((7/8)^i * n) + Θ(n^(lg3 / 3))
            = n * ((7/8)^(lgn/3) - 1) / (7/8 - 1) + Θ(n^(lg3 / 3))
            = 8n * (1 - n^(lg7 / 3) / n) + Θ(n^(lg3 / 3))
            = Θ(n) - Θ(n^(lg7 / 3)) + Θ(n^(lg3 / 3))
            = Ω(n)
    assume T(n) <= cn
    T(n)    <= c(n/2 + n/4 + n/8) + n
            = (7/8)cn + n
            <= cn when c >= 8
    therefore T(n) = Θ(n)
g.  n - 1 every level, n levels in total, a single node every level, contributes 1/(n-i)
    the base level is a single node of Θ(1)
    T(n)    = Σ(i = {0 .. n-1})(1/(n-i)) + Θ(1), the harmonic series
            = Θ(ln(n)) + Θ(1)
            = Θ(lgn)
h.  n - 1 every level, n levels in total, ith level sums to lg(n - i)
    T(n)    = Σ(i = {0 .. n-1})(lg(n-i)) + Θ(1)
            = Θ(nlgn) as int(lgx) = x(lgx - 1)
i.  n - 2 every level, n/2 levels in total, ith level sums to 1/lg(n - 2i)
    T(n)    = Σ(i = {0 .. n/2 - 1})(1/lg(n - 2i)) + Θ(1)
            = Θ(li(n)), where li(n) is the logarithmic integral function
j.  let n = 2^m, m = lgn, T(n) = T(2^m) = 2^(m/2)T(2^(m/2)) + 2^m
    let S(m) = T(2^m), S(m) = 2^(m/2)S(m/2) + 2^m
    m/2 each level, lgm levels in total
    first level has 2^(m/2) nodes, the next 2^(m/2) * 2^(m/4), ...
    ith level will have 2^(m - m/2^i) nodes, each contributes 2^(m/2^i), 2^m in total
    the base level has 2^(m - m/2^(lgm)) = 2^(m-1) nodes, Θ(2^(m-1)) in total
    S(m)    = lgm * 2^m + Θ(2^(m-1)) = Θ(lgm * 2^m)
    T(n) = T(2^m) = S(m) = Θ(2^mlgm) = Θ(nlglgn)

4-4
a.  F(z)    = Σ(i = {0 ..})(Fiz^i)
    zF(z)   = Σ(i = {0 ..})(Fiz^(i+1))
            = Σ(i = {1 ..})(F(i-1)z^i)
            = Σ(i = {2 ..})(F(i-1)z^i)  // as F(0) = 0
    z^2F(z) = Σ(i = {0 ..})(Fiz^(i+2))
            = Σ(i = {2 ..})(F(i-2)z^i)
    z + zF(z) + z^2F(z) = 0 + z + Σ(i = {2 ..})(F(i-1)z^i + F(i-2)^zi)
                        = 0 + z + Σ(i = {2 ..})(Fiz^i)
                        = F(z)
b.  F(z) = z + zF(z) + z^2F(z)
    F(z) - zF(z) - z^2F(z) = z
    F(z)(1 - z - z^2) = z
    F(z) = z / (1 - z - z^2)
    let g = (1 + r5) / 2, g' = (1 - r5) / 2, r5 = 5^(1/2)
    (1 - gz)(1 - g'z)   = (1 - (1 + r5)z / 2)(1 - (1 - r5)z / 2)
                        = 1 - (1 - r5)z / 2 - (1 + r5)z / 2 + (1 + r5)(1 - r5)z^2 / 4
                        = 1 - z + (-4)z^2 / 4
                        = 1 - z - z^2
    (1/r5) * (1 / (1 - gz) - 1 / (1 - g'z))
    = (1/r5) * (- g'z + gz) / ((1 - gz) * (1 - g'z))
    = (1/r5) * (r5z) / ((1 - gz)(1 - g'z))
    = z / ((1 - gz)(1 - g'z))

4-5
a.  divide the chips into three groups
    first group of size n1 are good chips, which will always give the correct answer
    second group of size n2 are bad chips immitating good chips
    third group of size n3 are other bad chips
    as the number of bad chips n2 + n3 > n/2
    it's always possible to take n2 = n1 and n3 = n - n1 - n2 will be non-negative, then
    1.  chips in the first group will always answer "good" for chips in that group, "bad" for chips in group 2 and 3
    2.  let chips in group 2 imitate group 1
        always answer "good" for chips in the same group, "bad" for chips in group 1 and 3
    3.  let chips in group 3 answer "good" for any chips
    then chips in group 3 can be easily detected: they answer "good" for all chips, but only n2 < n/2 chips are good
    however group 1 and 2 are totally symmetric:
        they both have size n1 = n2 < n/2
        they only answer "good" for chips in the same group, which also answers "good" in the pairwise test
        they answer "bad" for chips not in that group
    no matter how many test is performed, it's impossible to tell if a chip is in group 1 or group 2
b.  assume n1 in n chips are good, where n1 > n/2
    starting from a set S containing all n chips, and an empty set S'
    repeat the following procedure [n/2] times:
        randomly pop two chips c1 and c2 from S, perform the test
        if any of the two reports "bad", drop both chips
        if both chips answer "good", drop c2 and add c1 to S'
    let n1 be the number of good chips tested, n2 be the number of bad chips tested
    let n11 be the number of good chips tested against a good chip, n12 otherwise (tested against a bad chip)
    similarly define n21 and n22, obviously n12 = n21, both n11 and n22 have to be even
    when n is even, n1 = n11 + n12, n2 = n21 + n22, n1 > n2
    the number of good chips in S' at the end will be n11 / 2, bad chips n22 / 2
    n11 = n1 - n12, n22 = n2 - n21 = n2 - n12, so n11 > n22, still more good chips than bad chips in S'
    when n is odd, one chip cannot be tested
    if that chip is bad, n1 > n2 + 1, n1 >= n2 + 2, n11 >= n22 + 2, n11/2 >= n22/2 + 1
    the bad chip must be dropped or number of good and bad chips may equal when n11/2 = n22/2 + 1
    if that chip is good, n1 >= n2, n1 >= n2, n11/2 >= n22/2
    the good chip must be included or number of good and bad chips may equal when n11/2 = n22/2
    thanks http://cseweb.ucsd.edu/classes/su99/cse101/sample1.pdf
    (n11 + n12) / 2 can be observed as the number of tests answered "good, good"
    if (n11 + n12) / 2 is even, add the untested chip to S'
    if (n11 + n12) / 2 is odd, drop the untested chip
    then the algorithm will act correctly on boundary conditions
c.  the single good chip can be find in time T(n), where
        T(n) = T(n/2) + [n/2]
        T(n) = Θ(n) by master method
    once a single good chip is found, it can be used to find all other good chips in Θ(n) tests
    overall time cost Θ(n)

4-6
a.  given
        A[i, j] + A[i+1, j+1] <= A[i, j+1] + A[i+1, j]
    for some r that 1 <= r < m - i, assume
        A[i, j] + A[i+r, j+1] <= A[i, j+1] + A[i+r, j]
    combine the assumption with
        A[i+r, j] + A[i+r+1, j+1] <= A[i+r, j+1] + A[i+r+1, j]
        A[i, j] + A[i+r+1, j+1] <= A[i, j+1] + A[i+r+1, j]
    therefore for any 1 <= r < m,
        A[i, j] + A[i+r, j+1] <= A[i, j+1] + A[i+r, j]
    similarly, apply the induction on columns
        A[i, j] + A[i+r, j+c] <= A[i, j+c] + A[i+r, j]
    for 1 <= r < m - i and 1 <= c < n - j
    take r = k - i and c = l - j, this is exactly A[i, j] + A[k, l] <= A[i, l] + A[k, j]
    conversely, take k = i+1, l = j+1, 
        A[i, j] + A[k, l] <= A[i, l] + A[k, j] => A[i, j] + A[i+1, j+1] <= A[i, j+1] + A[i+1, j]
b.  change 22 on first line to 24
c.  if f(i) > f(i+1) instead, by definition of Monge,
        A[i, f(i+1)] + A[i+1, f(i)] <= A[i+1, f(i+1)] + A[i, f(i)]
    by definition of f(i), A[i, f(i)] and A[i+1, f(i+1)] is the leftmost minimum of their rows, therefore
        A[i, f(i+1)] >= A[i, f(i)], A[i+1, f(i)] >= A[i+1, f(i+1)]
        A[i, f(i+1)] = A[i, f(i)], A[i+1, f(i)] = A[i+1, f(i+1)]
    A[i, f(i+1)] is also the minimum of row i, but then f(i+1) < f(i) and A[i, f(i)] is not the leftmost minimum
d.  the leftmost minimum of even rows are
        f(2), f(4), f(6) ..
    as proven in part c, f(1) <= f(2) <= f(3) <= ..
    therefore it's sufficient to search f(1) as the minimum among A[1, 1] .. A[1, f(2)]
    f(3) among A[3, f(2)] .. A[3, f(4)] and so on
    at most 2m + n elements have to be compared, Θ(m + n) in total
e.  the base case of finding the minimum of a row is O(n)
    T(m, n) = O(n) when m = 1
            = T(m/2, n) + O(m + n) otherwise
    the recurrence tree has lgm levels
    ith level has a single node contributes O(m/2^i + n)
    the base level is a single node of O(n)
    T(n)    = Σ(i = {0 .. lgm})O(m/2^i + n) + O(n)
            <= Σ(i = {0 .. lgm})c1(m/2^i + n) + c2n
            <= c1m + c1nlgm + c2n
            = O(m + nlgm)

Chapter 5
5.1-1
it's always possible to decide the best between any two candidates
which means either a > b or b > a for two candidates a and b
for a fixed set of candidates C and any candidate c in it,
    its rank, as the number of candidates better than it - 1, is fixed
    no candidate can have rank lower than |C|
    no two candidates can have the same rank, assume c has rank k,
        exactly (k-1) candidates are better than it, none of which can have rank equal or higher than k
        exactly (|C| - k) candidates are worse than it, none of which can have rank equal or lower than k
    therefore the rank of the candidates are a bijection C => {1 .. |C|}, where {1 .. |C|} has a total order

5.1-2
let 2^p be the next power of two of b - a
take p results of RANDOM(0, 1), interpret the result array as a binary number n
than n is uniformly distributed between 0 and 2^p - 1
if n <= b - a, return n + a, otherwise run the procedure again
let x <- S denote that n follows discrete uniform distribution over set S
as n <- {0 .. 2^p - 1}, if n <= b - a, n <- {0 .. a - b}, n + a <- {a .. b}
as 2^p is the next power of two of b - a, 2^(p-1) <= b - a < 2^p
the number of calls to the procedure follows geometric distribution with success probability (b - a) / 2^p >= 1/2
therefore the expected number of calls is 2 and E[T(a, b)] = Θ(p) = Θ(lg(b - a))

5.1-3
let A and B denote two independent runs of procedure BIASED-RANDOM
p((A, B) = (1, 1)) = p^2
p((A, B) = (0, 0)) = (1-p)^2
p((A, B) = (1, 0)) = p((A, B) = (0, 1)) = p(1-p)
(A, B) = (1, 0) and (A, B) = (0, 1) happen with equal probability
define RANDOM as:
    run (a, b) = (BIASED-RANDOM(), BIASED-RANDOM());
    if (a, b) == (1, 0):
        return 1;
    else if (a, b) == (0, 1):
        return 0;
    else:
        recursively call RANDOM itself
the number of calls to RANDOM follows geometric distribution with success probability 2p(1-p) = 2p - 2p^2
the expected number of calls is 1/(2p - 2p^2), E[T(n)] = Θ(1/(p - p^2))

5.2-1
one time:   the first candidate is hired and is the best among all the candidates
            p = 1/n
n times:    every candidate is hired, implying the candidates are presented in strictly increasing order
            p = 1/n!

5.2-2
the first candidate is hired anyway
assume the first candidate has rank r1, the second hired candidate has rank r2
r1 != 1, or the second hire cannot happen
the best candidate definitely will be hired, thereby r2 = 1
candidate with rank 1 is the first candidate with rank higher than r1 after the first among all r1 - 1 such candidates
p = 1 / (r1 - 1)
as r1 <- {2 .. n}, p = (1 / n-1) * Σ(1 / (r1 - 1))

5.2-3
E[ΣXi] = Σ(E[Xi]) = 3.5n

5.2-4
define Xi as
Xi  = 1 when ith customer get back own hat
    = 0 otherwise 
for any Xi, E[Xi] = P(ith customer get back own hat) = 1/n
expected number of customers who get back their own hat = E[Σ(Xi)] = n * 1/n = 1

5.2-5
when A[1 .. n] is a uniform random permutation, A[i] <- {1 .. n} for all i when viewed independently
for a pair i < j, A[i] <- {1 .. n}, A[j] <- {1 .. n} - A[i]
p(A[i] < A[j])  = (1 / n) * Σ(A[i] = {1 .. n})((A[i] - 1) / (n - 1))
                = 1/2 asymptotically
p(inversion) = p(A[i] > A[j]) = 1 - p(A[i] < A[j]) = 1/2
define Ii,j as
Ii,j    = 1 when A[i] > A[j]
        = 0 otherwise
then the expected number of inversions is E[ΣIi,j] = C(n, 2) * E[Ii,j] = n(n - 1) / 4

5.3-1
swap A[1] with A[RANDOM(1, n)] before the loop, start the loop with i = 2
the same proof still implies but now starting with 1-permutations

5.3-2
after the procedure, A[1] is guarenteed not to be in it's original place
at least n!/n = (n-1)! permutations are excluded, not only the identity

5.3-3
for an array of size 3, A = [a1, a2, a3]
let A' denote the array after calling PERMUTE-WITH-ALL(A)
every swap may have 3 possible consequences, the procedure overall may have 3^3 = 27 consequences
there are 3! = 6 different permutations of A, there's no way to divide 27 comsequences evenly among 6 permutations
there must be some permutations Ap of A that p(A' = Ap) != 1/6

5.3-4
p(A[i] ends up in B[j]) = p(offset = (i - j) mod n) = 1/n
this procedure can only produce cyclic shifting of an array
for an array of size n, there are only n different shiftings
other n! - n permutations may never be produced

5.3-5
let Ei denote the event ith element in the array is different to all the previous elements
P[E1 ∩ E2 ∩ E3 .. En]   = P[E1] * P[E2 | E1] * P[E3 | E1 ∩ E2] .. 
                        = 1 * (n^3 - 1) / n^3 * .. * (n^3 - n) / n^3
                        >= ((n^3 - n) / n^3)^n
                        = ((n^2 - 1) / n^2)^n
                        = (1 - 1/n^2)^n
thanks https://ita.skanev.com/05/03/05.html
                        >= 1 - 1/n

5.3-6
the algorithm should also produce a uniform permutation when all n priorities are identical
the sorting algorithm is not specified, it can be stable or instable
when it's stable it will not change the array in that case, when unstable the result is UB
therefore the procedure either have to shuffle the array in other meanings (using no sorting)
or have to regenerate the priorities until no priorities are identical

5.3-7
when m = 0, ∅ is the only set with no member, returning ∅ is thus returning a uniformly random 0-subset
assume RANDOM-SAMPLE(m-1, m-1) returns uniformly random (m-1)-subset S' of U = {1 .. n-1}
each with probability 1/C(n-1, m-1)
i = RANDOM(1, n), p(i ∈ S) = (m-1) / n
for a particular m-subset S of U = {1 .. n}, S = {s1, s2 .. sm}
when n ∉ S, RANDOM-SAMPLE(m, n) will only return S when
    S'  = S - si for some i, p = 1/C(n-1, m-1)
        there are C(m, m-1) = m such (m-1)-subsets
    si  = RANDOM(1, n), p = 1/n, as si != n, si is included in S
p(S)    = 1/C(n-1, m-1) * m/n
        = (m-1)!(n-m)! / (n-1)! * m/n
        = m!(n-m)! / n! = C(n, m)
when n ∈ S, S' may not contain n, as S' is a subset of {1 .. n-1}
the only way RANDOM-SAMPLE(m, n) may return S is 
    S'  = S - n, only one (m-1)-subset satisfies, p = 1/C(n-1, m-1)
    i   = RANDOM(1, n) ∈ S' or i = n, p = (m-1)/n + 1/n = m/n
p(S)    = 1/C(n-1, m-1) * m/n = C(n, m)
therefore RANDOM-SAMPLE(m, n) returns any m-subset of {1 .. n} with probability C(n, m)

5.4-1
let n = 365 denote the days in a year
p(there is at least one in all k people whose birthday is a specific day i)
= 1 - ((n-1)/n)^k >= 1/2
1/2 >= ((n-1)/n)^k
-1 >= k(lg(n-1) - lgn)
k >= 1 / (lgn - lg(n-1))
k >= 253

5.4-2
// wasted several hours here by misintepreting the problem as "until all bins contain at least 2 balls"
the same as the birthday problem

5.4-3
the exact analysis depends on mutual independence of variables
the analysis with indicator variables will still apply if the variables are just pairwise independent
    for any i and j, E[Xij] still is 1/n

5.4-4
assume their birthday are mutually independent, n = 365, m people in total
define Xijk as
    Xijk    = 1 when i, j, k have the same birthday
            = 0 otherwise
p(i, j, k have the same birthday)
= p(j, k have the same birthday as i)
= 1/n^2
E[X]    = ΣΣΣ(Xijk)
        = C(m, 3) * 1/n^2
        = m!/6(m-3)! * 1/n^2
        = m(m-1)(m-2)/6n^2 >= 1
m(m-1)(m-2) > (m-2)^3 >= 6n^2
m >= 95

5.4-5
it's the complement of birthday paradox
a k-string is a k-permutation only if it doesn't repeat any set element
p   = 1 * 1/(n-1) * 1/(n-2) * .. * 1/(n-k+1)
    = 1/(n!/(n-k)!)
    = (n-k)!/n!

5.4-6
define indicator Xi as
Xi  = 1 when bin i is empty after n tosses
    = 0 otherwise
E[Xi]   = p(bin i is empty after n tosses)
        = ((n-1)/n)^n
        = (n-1)^n / n^n
E[X]    = E[ΣXi]
        = ΣE[Xi]
        = n * (n-1)^n / n^n
        = (n-1)^n / n^(n-1)
define indicator Yi as
Yi  = 1 when bin i has 1 ball after n tosses
    = 0 otherwise
E[Yi]   = p(bin i has 1 ball after n tosses)
        = C(n, 1) * (1/n) * ((n-1)/n)^(n-1)
        = (n-1)^(n-1) / n^(n-1)
E[Y]    = E[ΣYi]
        = Σ(E[Yi])
        = n * (n-1)^(n-1) / n^(n-1)
        = (n-1)^(n-1) / n^(n-2)

5.4-7
divide all coin tosses to slices of length lgn - 2lglgn, all slices are mutually independent
p(a single slice is all head)   = 1/2^(lgn - 2lglgn)
                                = 1/(2^lgn/2^2lglgn)
                                = lg^2n / n
p(no slice is all head) = (1 - lg^2n / n)^(n / (lgn - 2lglgn))
                        <= e^(-lg^2n / n * (n/(lgn - 2lglgn)))
                        = e^(-lg^2n / (lgn - 2lglgn))
                        = n^(-lgn / (lgn - 2lglgn))
                        <= n^(-lgn / lgn)
                        = 1/n
"no slice is all head" is the union of two events:
    1. the longest head streak is no longer than lgn - 2lglgn - 1
    2. the longest head streak is longer than lgn - 2lglgn - 1, but is divided between two slices
therefore 
p(longest head streak is no longer than lgn - 2lglgn - 1) <= 1/n
inject this into the original prove,
E[L] = Ω(lgn - 2lglgn)

5-1
a.  let Xk be the number represented by i after k increments
    X0 = 0 = n0
    assume E[Xk] = n
    X(k+1)  = Xk + (ni+1 - ni), p = 1/(ni+1 - ni)
            = Xk, p = 1 - (1 / (ni+1 - ni))
    E[X(k+1)]   = 1/(ni+1 - ni) * (E[Xk] + (ni+1 - ni)) + (1 - 1/(ni+1 - ni)) * E[Xk]
                = E[Xk] + 1/(ni+1 - ni) * (ni+1 - ni)
                = n + 1
    therefore E[Xn] = n
b.  i now follows binomial distribution with success rate 1/100
    Var(i) = np(1-p) = 99n/10000
    Var(Xn) = Var(100i) = 100^2Var(i) = 99n

5-2
a.  ./CLRS/start/index.ts#randomSearch
b.  the number of trials X follows geometric distribution with success rate 1/n
    E[X] = 1/(1/n) = n
c.  the same with part b but with success rate k/n
    E[X] = 1/(k/n) = n/k
d.  the same as balls and bins 
    E[X] = n(ln(n) + O(1))
e.  i <- {1 .. n}, the number of comparsions X = i
    E[X] = E[i] = (1/n) * n(1+n)/2 = (1+n)/2
f.  thanks http://sites.math.rutgers.edu/~ajl213/CLRS/Ch5.pdf
    define indicator variables {Xi} such that
    Xi  = 1 when A[i] is compared to x in a search
        = 0 otherwise
    when A[i] = x
        p(Xi = 1)   = p(i is the minimum among all indices that A[i] = x)
                    = 1/k
    when A[i] != x
        p(Xi = 1)   = 1/k+1 // why? what's the distribution of the minimum of a k-subset of {1 .. n}?
    which gives E[ΣXi] = ΣE[Xi] = k * 1/k + (n-k)/k+1 = (n+1)/(k+1)
    in worst case, the k matches are the last k elements of the array
    the algorithm has to perform n-k+1 comparsions
g.  both average and worst case running time Θ(n)
h.  exactly the same as part e, f and g
i.  DETERMINISTIC-SEARCH
    shuffling an array will cost Θ(n) time, which is similar to deterministic linear searching
    it's not worth the effort to do the shuffling unless comparsion is expensive and inputs are malicious
    and the first algorithm is O(nlgn), worse than deterministic linear searching

Chapter 6
6.1-1
a complete binary tree of height h has nodes 2^(h+1) - 1
of height h-1 has nodes 2^h - 1
therefore a heap with height h will have nodes between 2^h and 2^(h+1) - 1

6.1-2
as 6.1-1 shows, 2^h <= n <= 2^(h+1) - 1, where h is the height of the heap
therefore 
    lg(2^h) <= lgn <= lg(2^(h+1) - 1)
    h <= [lgn] <= h, h = [lgn]

6.1-3
for a subtree of a heap, there is a simple path from root to any child node
for an arbitrary node n, PARENT^(i)(n) = root for some i
as A[PARENT(n)] >= A[n] for all n, A[n] <= A[PARENT(n)] <= .. <= A[root]
root is the largest value occuring anywhere in that subtree

6.1-4
anywhere at the bottom level
it can not be anywhere else than the bottom level, or it will have children, and A[PARENT(i)] >= A[i] for all i
as the problem assumed that all values are distinct, A[i] won't be the minimum

6.1-5
yes, for a sorted array, for any i <= j, A[i] <= A[j]
as PARENT(i) < i for all i except the root, A[PARENT(i)] <= A[i] for all i, A is a min-heap

6.1-6
23
17  14
6   13  10  1
5   7   2
no, 6 has two children 5 and 7, where 7 > 6

6.1-7
for i >= [n/2] + 1, the index of its left child will be greater than 2 * ([n/2] + 1) = 2 * [n/2] + 2
if n is even, 2 * [n/2] + 2 = n + 2
if n is odd, 2 * [n/2] + 2 = n + 1 
both cases the index of its left child will be greater than n, thereby A[i] must be a leaf

6.2-1
                27
            17      3
        16  13      10  1
       5 7 12  4   8  9   0
3 = A[3] swapped with 10 = A[6], then with 9 = A[13]

6.2-2
./CLRS/sort/heap.ts#heapify
the code is abstract, subclasses can instantiate the abstract cmp function to anything they want

6.2-3
after comparing A[i], A[LEFT(i)] and A[RIGHT(i)]
the procedure terminates without modifying the underlying array or recursively call itself

6.2-4
both LEFT(i) and RIGHT(i) will be out-of-bound, defined by <= A.heap-size
the procedure terminates without modifying the underlying array or recursively call itself

6.2-5
./CLRS/sort/heap.ts#heapify

6.3-1
swapped A[3] = 10 and A[7] = 22
swapped A[2] = 17 and A[5] = 19
swapped A[1] = 3 and A[4] = 84
swapped A[0] = 5 and A[1] = 84
swapped A[1] = 5 and A[3] = 22
swapped A[3] = 5 and A[7] = 10

6.3-2
starting from 1, the non-leaf nodes may not meet the condition of MAX-HEAPIFY
which requires the left and right subtrees of A[i] be a max heap

6.3-3
for level i, there can only be 2^(h - i - 1) nodes if the level is complete
2^h <= n <= 2^(h+1) - 1
[n / 2^(i+1)] >= 2^(h-i-1) 

6.4-1
swapped A[2] = 2 and A[6] = 20
swapped A[1] = 13 and A[3] = 25
swapped A[0] = 5 and A[1] = 25
swapped A[1] = 5 and A[3] = 13
swapped A[3] = 5 and A[7] = 8
swapped A[0] = 4 and A[2] = 20
swapped A[2] = 4 and A[5] = 17
swapped A[0] = 5 and A[2] = 17
swapped A[0] = 2 and A[1] = 13
swapped A[1] = 2 and A[3] = 8
swapped A[0] = 4 and A[1] = 8
swapped A[1] = 4 and A[4] = 7
swapped A[0] = 4 and A[1] = 7
swapped A[0] = 2 and A[2] = 5
swapped A[0] = 2 and A[1] = 4
[ 2, 4, 5, 7, 8, 13, 17, 20, 25 ]

6.4-2
initialization:
    at the start of the first iteration, i = A.length, A[1 .. i] = A is a max heap
    A[i+1 ..] is empty
maintenance:
    assume at the start of ith iteration, A[1 .. i] is a max heap, A[i+1 .. n] contains n-i largest elements sorted
    the root of the max heap is largest among A[1 .. i] and smaller than any element in A[i+1 .. n]
    thereby A[1] is the n-i-1th largest element
    swapping A[1] with A[i], now A[i .. n] contains n-i+1 largest elemented in sorted order
    decrement the size of the heap and call MAX-HEAPIFY(1), elements in A[1 .. i-1] is now a max heap
termination:
    after the end of the last iteration, i = 1, A[2 .. n] contains n-1 largest elementes in sorted order
    A[1] thus must be the smallest element in A[1 .. n], and A is in sorted order

6.4-3
assuming all elements are distinct
increasing order:
    since all leaves are greater than internal nodes, at least half of the elements in the array have to be moved
    which takes Ω(n), increasing order is asymptotically the worst case of BUILD-MAX-HEAP
    every iteration will swap an element at bottom level to the root of the heap
    MAX-HEAPIFY have to pass it all the way down to the bottom level, taking time Θ(h) = Θ(lgi)
    Θ(Σlgi) = Θ(lg(n!)) = Θ(nlgn)
decreasing order:
    array in decreasing order is already a max heap, BUILD-MAX-HEAP takes constant time
    every iteration will swap the minimum element to the root of the heap
    MAX-HEAPIFY have to pass it all the way down to the bottom level, taking time Θ(h) = Θ(lgn)
    Θ(Σlgi) = Θ(lg(n!)) = Θ(nlgn)
if all elements are identical, both BUILD-MAX-HEAP and MAX-HEAPIFY will take constant time
overall running time Θ(n)    

6.4-4
the same to decreasing order in 6.4-3

6.4-5
The Analysis of Heapsort
Schaffer R., Sedgewick R. 
Journal of Algorithms Volume 15, Issue 1, July 1993, Pages 76-100

6.5-1
swapped A[0] = 15 and A[11] = 1
swapped A[0] = 1 and A[1] = 13
swapped A[1] = 1 and A[4] = 12
swapped A[4] = 1 and A[9] = 6
Maximum key is 15

6.5-2
Inserting 10...
swapped A[12] = 10 and A[5] = 8
swapped A[5] = 10 and A[2] = 9

6.5-3
again the code is abstract, subclasses can override cmp to anything they like (as long as it's a total order)
./CLRS/sort/heap.ts#MinPriorityQueue

6.5-4
because it's bad code
the function HEAP-INCREASE-KEY is multi-purpose: it both increases the key and fixes the position of the key in heap
the fix part should be seperated from HEAP-INCREASE-KEY, then HEAP-INSERT no longer has to call it or set -∞
the guard condition is only necessary when A[i] may have children, in this case it hasn't
the heap should work with all types which has a total order over it
many of them do not have a global minimum like -∞

6.5-5
initialization:
    A[1 .. A.heap-size] is a max heap, key is inserted to A[A.heap-size + 1], i = A.heap-size + 1
    then A[i] is guarenteed to have no left or right child
    A[1 .. A.heap-size+1] is a max heap except A[i] may be larger than A[PARENT(i)]
    then A.heap-size is incremented before the first iteration
maintenance:
    assume A[1 .. A.heap-size] is a max heap except A[i] may be larger than A[PARENT(i)]
    if A[PARENT(i)] >= A[i], then A[1 .. A.heap-size] is a max heap, loop terminated
    or A[PARENT(i)] is swapped with A[i], A[PARENT(i)] > A[i]
    but now A[PARENT(i)] may be larger than A[PARENT(PARENT(i))], otherwise A[1 .. A.heap-size] is a max heap
    by setting i = PARENT(i)
    A[1 .. heap-size] is a max heap except A[i] may be larger than A[PARENT(i)] at the start of next iteration
termination:
    i = 1 after the last iteration
    i has no parent, A[1 .. A.heap-size] is a max heap

6.5-6
./CLRS/sort/heap.ts#fix

6.5-7
FIFO queue: based on a min priority queue, data keyed with a auto incrementing counter
./CLRS/sort/heap.ts#FIFOQueue
Stack (or FILO queue): the same as FIFO queue, but based on a max priority queue
./CLRS/sort/heap.ts#Stack

6.5-8
swap A[i] with A[A.heap-size], decrement A.heap-size
the value of A[A.heap-size] is uncertain: it can be either greater than A[PARENT(i)] or not
depending on the value of A[A.heap-size], it may need to go up or down the heap to restore max heap property
if it's greater than its parent, call INCREASE-KEY(i, 0); otherwise call MAX-HEAPIFY(i)

6.5-9
if used a min heap instead of a max heap, elements have to be removed from the head of the array when extracting
there's no way to do this efficiently in javascript
(can be done in Haskell by tail and in Rust by slicing)
./CLRS/sort/heap.ts#mergeArrays
build the max heap with k arrays: O(k)
extract and heapify the heap: O(lnk), O(nlnk) in total

6-1
a.  Original input:   [ 1, 2, 3, 4, 5 ]
    BUILD-MAX-HEAP:   [ 5, 4, 3, 1, 2 ]
    Repeated insert:  [ 5, 4, 2, 1, 3 ]
b.  when inputs are in increasing order
    every element inserted at the bottom level have to be swapped all the way to the root
    T(n) = Σ(hi) = Σ(Θ(lgi)) = Θ(lg(n!)) = Θ(nlgn)

6-2
a.  assume array index starts from 0
    the first element is the root, next d are the children of the root, next d^2 are their children, etc.
    let FIRST-CHILD(i) return the index of the first child of A[i]
    FIRST-CHILD(i+1) = FIRST-CHLID(i) + d
    FIRST-CHILD(0) = 1, FIRST-CHILD(i) = id + 1
    FIRST-CHILD(i) to FIRST-CHILD(i) + d - 1 (if in bound) will be the children of A[i]
    let PARENT(i) be the index of parent of i
    PARENT(i + d) = 1 + PARENT(i)
    PARENT(1) = PARENT(d) = 0, PARENT(i) = Math.floor((i - 1)/d)
b.  the complete d-ary tree of height h-1 has Σ(i = {0 .. h})(d^h) = (d^h - 1) / (d - 1) nodes
    the complete d-ary tree of height h has (d^(h+1) - 1) / (d - 1) nodes
    (d^h - 1) / (d - 1) + 1 <= n <= (d^(h+1) - 1) / (d - 1)
    d^h + d - 2  <= (d-1)n <= d^(h+1) - 1
    d^h <= (d-1)n - d + 2 <= d^(h+1) - d + 1
    Math.floor(log(d, (d-1)n - d + 2)) = h
    h = Θ(log(d, dn)) = Θ(lgn)
c.  has to find the maximum among d nodes at every level, Θ(lgn) levels in total
    T(n) = Θ(dlgn)
d.  the working part is function fix, which is the same to part e
e.  at most have to swap all nodes on a simple path from root to bottom
    the length of the path is no longer than the height of the heap, which is Θ(lgn)
    T(n) = Θ(lgn)

6-3
a.  [[2, 3, 4, 5],
     [8, 9, 12, 14],
     [16, -, -, -],
     [-, -, -, -]]
b.  for any i <= l and j <= k
    A[i, j] <= A[i, k] <= A[l, k]
    therefore if Y[1, 1] = ∞, for all i, j, Y[i, j] >= ∞, all entries are empty
    if Y[m, n] < ∞, for all i, j, Y[i, j] <= Y[m, n] < ∞, all entries are filled
c.  ./CLRS/sort/young-tableau#extractMin
    correctness can be proved similarly as min heap
    the smallest of Y[i, j], Y[i+1, j] and Y[i, j+1] is swapped to Y[i, j]
    if Y[i+1, j] is the minimum, tableau property of ith row now restored, reduced to a problem one row smaller 
    if Y[i, j+1] is the minimum, tableau property of jth column now restored, reduced to a problem one column smaller
    p = m + n is incremented every iteration and every iteration takes constant time
    the loop ends either i = m and j = n (out of bound) or eariler
        T(p) = T(p-1) + Θ(1), T(p) = O(p) by stright-forward recurrence tree analysis
    T(m + n) = O(m + n) 
d.  ./CLRS/sort/young-tableau#insert
    correctness can be proved similarly as insert in priority queue
    p = m + n is decremented every iteration and every iteration takes constant time
        T(p) = T(p-1) + Θ(1), T(p) = O(p)
    T(m + n) = O(m + n)
e.  ./CLRS/sort/index.ts#problem_6_3
    insert n^2 numbers into the tableau, then call EXTRACT-MIN n^2 times
    T(p) = T(2n) = O(n) for both INSERT and EXTRACT-MIN, Θ(n^2) operations in total
    T(p) = O(n) * Θ(n^2) = O(n^3)
    which is not optimal since
        1. it's not in-place
        2. heapsort can be done in O(n^2lg(n^2)) = O(n^2lgn) time
f.  ./CLRS/sort/young-tableau#find
    starting from Y[i, j] = Y[0, n - 1]
    if Y[i, j] > key, the whole column j contains numbers greater than key 
    the problem size is reduced by 1 column
    if Y[i, j] == key, [i, j] is the answer
    if Y[i, j] < key, all numbers Y[0, j] to Y[i, j] < key
    the problem size is reduced by 1 row
    as p = i + j is decremented every iteration, overall running time is O(m + n)

Chapter 7
7.1-1
Swapped A[0] = 9, A[2] = 13
[ 9, 19, 13, 5, 12, 8, 7, 4, 21, 2, 6, 11 ]
Swapped A[1] = 5, A[3] = 19
[ 9, 5, 13, 19, 12, 8, 7, 4, 21, 2, 6, 11 ]
Swapped A[2] = 8, A[5] = 13
[ 9, 5, 8, 19, 12, 13, 7, 4, 21, 2, 6, 11 ]
Swapped A[3] = 7, A[6] = 19
[ 9, 5, 8, 7, 12, 13, 19, 4, 21, 2, 6, 11 ]
Swapped A[4] = 4, A[7] = 12
[ 9, 5, 8, 7, 4, 13, 19, 12, 21, 2, 6, 11 ]
Swapped A[5] = 2, A[9] = 13
[ 9, 5, 8, 7, 4, 2, 19, 12, 21, 13, 6, 11 ]
Swapped A[6] = 6, A[10] = 19
[ 9, 5, 8, 7, 4, 2, 6, 12, 21, 13, 19, 11 ]
Swapped A[7] = 11, A[11] = 12
[ 9, 5, 8, 7, 4, 2, 6, 11, 21, 13, 19, 12 ]
Swapped A[0] = 5, A[1] = 9
[ 5, 9, 8, 7, 4, 2, 6, 11, 21, 13, 19, 12 ]
Swapped A[1] = 4, A[4] = 9
[ 5, 4, 8, 7, 9, 2, 6, 11, 21, 13, 19, 12 ]
Swapped A[2] = 2, A[5] = 8
[ 5, 4, 2, 7, 9, 8, 6, 11, 21, 13, 19, 12 ]
Swapped A[3] = 6, A[6] = 7
[ 5, 4, 2, 6, 9, 8, 7, 11, 21, 13, 19, 12 ]
Swapped A[0] = 2, A[2] = 5
[ 2, 4, 5, 6, 9, 8, 7, 11, 21, 13, 19, 12 ]
Swapped A[1] = 4, A[1] = 4
[ 2, 4, 5, 6, 9, 8, 7, 11, 21, 13, 19, 12 ]
Swapped A[2] = 5, A[2] = 5
[ 2, 4, 5, 6, 9, 8, 7, 11, 21, 13, 19, 12 ]
Swapped A[4] = 7, A[6] = 9
[ 2, 4, 5, 6, 7, 8, 9, 11, 21, 13, 19, 12 ]
Swapped A[5] = 8, A[5] = 8
[ 2, 4, 5, 6, 7, 8, 9, 11, 21, 13, 19, 12 ]
Swapped A[6] = 9, A[6] = 9
[ 2, 4, 5, 6, 7, 8, 9, 11, 21, 13, 19, 12 ]
Swapped A[8] = 12, A[11] = 21
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]
Swapped A[9] = 13, A[9] = 13
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]
Swapped A[10] = 19, A[10] = 19
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]
Swapped A[11] = 21, A[11] = 21
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]
Swapped A[9] = 13, A[9] = 13
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]
Swapped A[10] = 19, A[10] = 19
[ 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 19, 21 ]

7.1-2
every number in the array is smaller or equal to pivot
i = j = r - 1 after the loop
A[r] exchanged with A[i + 1] = A[r], return value is r
adding a specific check if all array elements are equal to the pivot, return Math.floor((p + r) / 2)
./CLRS/sort/quicksort#partition

7.1-3
the loop on lines 3-6 runs at most p - r + 1 times, bounded by j
each iteration takes constant time
other operations not in the loop takes constant times
T(n)    = Θ(p - r + 1) + Θ(1)
        = Θ(n)

7.1-4
change line 4 of PARTITION to
    if A[j] >= x
now the loop invariants are
    1.  if p <= k <= i, A[k] >= x
    2.  if i+1 <= k <= j-1, A[k] < x 
    3.  if k = r, A[k] = x

7.2-1
assume T(n) <= cn^2
T(n)    <= c(n-1)^2 + dn
        = cn^2 - 2cn + 1 + dn
        <= cn^2 by taking c > d/2
similarly, T(n) >= cn^2 
T(n) = Θ(n^2)

7.2-2
without the modification in problem 7.1-2, the problem is partitioned into two subproblems of size n-1 and 0
T(n) = T(n-1) + Θ(n) = Θ(n^2)
with the modification in problem 7.1-2, the problem is partitioned into two subproblem of size n/2
T(n) = 2T(n/2) + Θ(n) = Θ(nlgn)

7.2-3
when PARTITION is called with a sorted subarray A[p .. r], all elements in the slice is smaller or equal to r
return value will be r, the problem is partitioned into two sub-problems of size n-1 and 0
T(n) = Θ(n^2)

7.2-4
quiksort will take time Θ(n^2) for an already sorted array
insertion sort will take time Θ(n)

7.2-5
as α <= 1/2, 1 - α >= α
the shortest path from root to bottom is has length log(1/α, n) = lgn / lg(1/α) = -lgn/lgα
the longest path form root to bottom has length log(1/(1-α), n) = -lgn/lg(1-α)

7.2-6
thanks https://ita.skanev.com/07/02/06.html
as the input is uniformly random
the chance that the pivot falls within the αn smallest numbers or (1-α)n largest numbers is
    p = α + α = 2α
thereby with probability 1 - 2α, αn <= q <= (1-α)n, the partition is better than α to 1-α

7.3-1
the worst case of a randomized algorithm occurs rarely, also independent to the input

7.3-2
RANDOM is called once for each call to PARTITION, PARTITION is called for each call to QUICKSORT
for worst case, all partition are of size n - 1 and 0, PARTITION is called Θ(n) times
for best case, all partition are of size n/2
the number of calls to PARTITION is the same to the internal nodes in the recurrence tree
which is the number of nodes of a binary tree of height Θ(lgn), which is Θ(n)

7.4-1
assume T(n) >= cn^2
T(n)    >= max(cq^2 + c(n - q - 1)^2) + dn
        >= cn^2 - 2cn + 1 + dn
        >= cn^2 when c < d/2
T(n) = Ω(n^2)

7.4-2
T(n) = Θ(nlgn) => T(n) = Ω(nlgn)

7.4-3
the text already showed that the function is convex

7.4-4
E[X]    = Σ(i = {1 .. n-1})(Σ(k = {1 .. n-i})(2/(k+1)))
        = Σ(i = {1 .. n-1})(Σ(k = {1 .. n-i})(2/k) - 2)
        = Σ(i = {1 .. n-1})(Θ(lg(n-i)))
        = Θ(lg((n-1)!))
        = Ω(nlgn)

7.4-5
this time Xij = 1 only if i - j + 1 > k
E[X]    = Σ(i = {1 .. n-1})(Σ(j = {k+1 .. n-i})(2/(j+1)))
        <= Σ(i = {1 .. n-1})(Σ(k = {k+1 .. n})(2/j))
        = Σ(i = {1 .. n-1})(O(lgn) - O(lgk))
        = O(nlg(n/k))
the quicksort stops when the subarray has length <= k
thereby an element A[i] is guarenteed to be greater or equal to A[i - k]
when looking for a position to insert A[i], the insertion sort procedure will never have to search beyond A[i-k]
for all 0 <= i <= n-1, O(nk) in total
overall O(nk + nlg(n/k))

7.4-6
the median order of the three random variables falls within [αn, (1-α)n] only if at least two of them is in that range
it's a binomial distribution with success rate (1 - 2α)
P(X >= 2)   = C(3, 2)(1-2α)^2(2α) + C(3, 3)(1-2α)^3
            = 6α(1-2α)^2 + (1-2α)^3

7-1
a.  Swapped A[0] = 6, A[10] = 13
    [ 6, 19, 9, 5, 12, 8, 7, 4, 11, 2, 13, 21 ]
    Swapped A[1] = 2, A[9] = 19
    [ 6, 2, 9, 5, 12, 8, 7, 4, 11, 19, 13, 21 ]
    Return value:  8
b.  invariant: at the end of each iteration, p <= i, j <= r
    initialization:
        repeat clauses will be executed at least once, so i and j start with p and r
        as x = A[p], i will always be p after the first iteration
        if there's no element <= A[p] in the subarray, j will be p after the first iteration, !(i < j) and termination
        if there's some element <= A[p] in the subarray, the procedure swaps the element with A[p]
        denote this index as q
        after the first iteration:
            A[i] = A[p] <= x
            A[j] = A[q] = x
    maintenance:
        i and j is incremented at least once in each iteration
        the value they originally point to will not be changed
    termination:
        either j first reaches p or i first reaches q
        as A[p] <= x, j will stop at j = p
        i = p in the first iteration, thus i > p in this iteration, !(i < j) and the procedure is terminated 
        similarly, as A[q] = x, i will stop at i = q
        !(i < j) and termination
        therefore p <= i, j <= q <= r
c.  refine part 1 a little bit with assumption that r >= p + 1, subarray at least has length 2
    the procedure is only terminated at the first iteration when i = j = p, which means j < r
    otherwise j is decremented at least twice, j <= (r+1) - 2 = r - 1, j < r
d.  invariant:
        at the start of each iteration,
        A[p .. i-1] contains elements smaller or equal to the pivot
        A[j+1 .. r] contains elements greater or equal to the pivot
    initialization:
        A[p .. i-1] and A[j+1 .. r] are empty
    maintenance:
        after the two repeat clauses:
            A[p .. i-1] contains elements <= x
            A[j+1 .. r] contains elements >= x
            A[i] >= x
            A[j] <= x
        swap A[i] and A[j] then invariant maintained
    termination:
        !(i < j) => i >= j
        i = j only when A[i] >= x and A[i] <= x, A[i] = x
        every element in A[p .. i] = A[p .. j] <= x
        every element in A[j+1 .. r] >= x
    therefore every element in A[p .. i-1] <= x <= every element in A[j+1 .. r]
e.  ./CLRS/sort/quicksort.ts#hoareQuicksort

7-2
a.  any pivot will be equal to all array elements 
    the return of PARTITION will always be r, subarray partitioned to size n-1 and 0
    T(n) = Θ(n^2)
b.  ./CLRS/sort/quicksort.ts#partition2
    k incremented every iteration, starting from p, end condition is k > r - 1
    T(n) = Θ(p - r)
c.  ./CLRS/sort/quicksort.ts#quicksort2
d.  with QUICKSORT',
        if zi < x < zj, zi and zj will not be compared
        if zi or zj is first chosen as a pivot among {zi .. zj}, zi and zj will be compared
        if x = zi but not zi itself is first chosen as a pivot among {zi .. zj}
            zi will be in neither subproblems, zi will not be compared to zj
        simlarly if x = zj but not zj itself, zi will not be compared to zj
    the expected time analysis is still valid, E[X] = Θ(nlgn)

7-3
a.  pivot is chosen randomly from A[1] to A[n], 1/n for any particular element
    E[Xi] = 1/n
b.  if the qth smallest element is chosen as the pivot
    exactly q elements are smaller or equal
    the problem is partitioned into two subproblems of size q-1 and n-q
    T(n)    = ΣXq(T(q-1) + T(n-q) + Θ(n))
    as for a particular run, only one Xq can be 1, all others 0
    E[T(n)] = E[ΣXq(T(q-1) + T(n-q) + Θ(n))]
c.  the subproblems are independent to the value of Xq
    E[T(n)] = Σ(E[Xq](E[T(q-1)] + E[T(n-q)] + Θ(n)))
            = 1/n * Σ(E[T(q-1)] + E[T(n-q)] + Θ(n))
            = 1/n * (ΣE[T(q-1)] + ΣE[T(n-q)] + nΘ(n))
            = 1/n * (2ΣE[T(q)] + nΘ(n))
            = 2/n * ΣE[T(q)] + Θ(n)
d.  Σ(k = {2 .. n-1})(klgk)
    = Σ(k = {2 .. n/2 - 1})(klgk) + Σ(k = {n/2 .. n-1})(klgk)
    <= Σ(k = {1 .. n/2 - 1})(klg(n/2)) + Σ(k = {n/2 .. n-1})(klgn)
    <= (lgn - 1)(n/2)n/4 + lgn(3n/2 - 1)n/4
    = n^2lgn/8 - n^2/8 + 3n^2lgn/8 - Θ(nlgn)
    <= n^2lgn/2 - n^2/8
e.  assume E[T(n)] <= anlgn
    E[T(n)] <= 2/n * Σ(q = {2 .. n-1})(aqlgq) + dn
            <= 2/n * a(n^2lgn/2 - n^2/8) + dn
            = anlgn - an/4 + dn
            <= anlgn when a/4 > d
    E[T(n)] = O(nlgn)
    the best case is Ω(nlgn), so E[T(n)] = Ω(nlgn), E[T(n)] = Θ(nlgn)

7-4
a.  induction on problem size
    when p == r, the slice of one element is trivially sorted
    when p < r, after calling PARTITION(A, p, r),
        every element in A[p .. q-1] <= A[q]
        every element in A[q+1 .. r] > A[q]
    by induction assumption, TAIL-RECURSIVE-QUICKSORT(A, p, q-1) correctly sorts A[p, q-1]
    p set to q+1, equivalent to calling TAIL-RECURSIVE-QUICKSORT(A, q+1, r)
    by induction assumption, starting from the second iteration the procedure correctly sorts A[q+1, r]
    every element in A[p .. q-1] <= A[q] <= every element in A[q+1 .. r], therefore A[p .. r] is sorted
b.  the worst case of partition, subproblems of size n-1 and 0
    q = r - 1, TAIL-RECURSIVE-QUICKSORT(A, p, r) calls TAIL-RECURSIVE(A, p, r-1) recursively
    the stack keeps growing until p = r
    stack depth r - p + 1 = Θ(n)
c.  recursively solve the smaller subproblem first
    as the smaller of the subproblem has size <= n/2, stack depth <= lgn

7-5
a.  the three element chosen can be any 3-subset {Ap, Aq, Ar} of {A'1 .. A'n}
    for the median to be a particular i, 
        one of them should be Ai
        one of them should be smaller than Ai
        one of them should be greater than Ai
    pi = 1/n * (i-1)/n * (n-i)/n * A(3, 3) = 6(i-1)(n-i)/n^3
b.  with ordinary implementation, A'[(n+1)/2] is chosen with probability 1/n, the same with any other element
    with median-of-3 implementation, p = 6(n/2)(n/2)/n^3 = 3/2 * 1/n
    limit = 3/2
c.  for random pivot: p = Σ(i = {n/3 .. 2n/3})(1/n) = 1/3
    for median-of-3 pivot:
        p   = Σ(i = {n/3 .. 2n/3})(6(i-1)(n-i)/n^3)
            ≒ int(n/3 <= i <= 2n/3, 6(i-1)(n-i)/n^3)
            = 13/27 - 1/n
    as n -> ∞, p -> 13/27, better than 1/3 = 9/27
d.  as best possible split still gives Ω(nlgn) running time
    median-of-3 implementation can only be a constant factor better than the ordinary implementation on average

7-6
a.  the same idea as problem 7-2 can be used here 
    by comparing with a pivot interval [ap, bp], an array of interval [a, b] can be divided into three groups:
        1. strictly smaller than the pivot, b < ap
        2. strictly greater than the pivot, a > bp
        3. overlaps with the pivot, b >= ap && a <= bp
    the problem is the relation of overlapping is not transitive:
        [1, 2] overlaps with [2, 3]
        [2, 3] overlaps with [3, 4]
        [1, 2] doesn't overlap with [3, 4]
    thus group 3 may not overlap with each other
    the procedure must then maintain an interval that's the intersection of all overlapping intervals
    an interval must not be added to group 3 if it will make the intersection interval empty
    the intersection also must be computed beforehand, the left bound of the pivot must be constant during partition    
    ./CLRS/sort/quicksort.ts#fuzzysort
b.  the procedure is equivalent to quicksort in 7-2 on running time 
    which is Θ(nlgn) on average, Θ(n) when all elements are equivalent (i.e. contains the intersection)

Chapter 8
8.1-1
let array elements be vertices of a undirected graph
edge exists between vertices a and b iff a and b are compared
if the graph is not connected, i.e. array elements can be divided into two non-empty sets A1 and A2 that,
comparsions are only performed within these two sets but not between them
then any comparsion result between an elements from A1 and A2 are uncertain, the sort may not be accurate
thus for the comparsion sort algorithm to be correct, the graph must be connected
connected graph with n vertices has at least n-1 edges, which is the lower bound of comparsions
this lower bound is achievable
assume the input array is in sorted order, insertion sort only performs n-1 comparsions

8.1-2
Σ(k = {1 .. n})(lgk)    = lg(n!)
Σ(k = {1 .. n})(lgk)    <= Σ(k = {1 .. n})(lgn)
                        = nlgn = O(nlgn)
Σ(k = {1 .. n})(lgk)    = Σ(k = {1 .. n/2})(lgk) + Σ(k = {n/2 + 1 .. n})(lgk)
                        >= n/2 * lg(n/2)
                        = n/2 * (lgn - 1)
                        = Ω(nlgn)
lg(n!) = Θ(nlgn)

8.1-3
the unique simple path to half of n! leaves of a comparsion tree have length O(n)
a complete binary tree of height O(n) may only have 2^O(n) leaves
if it's possible, n!/2 = O(2^O(n)), n! = O(2^O(n)), which is not true
change 1/2 to any constant fraction and the argument still holds
n!/2^n = (1/2) * (2/2) * (3/2) ... >= (n/2)! = ω(2^O(n/2)) = ω(2^O(n))
it's not possible even for a 2^n fraction

8.1-4
each permutation of each subsequence is a possible sub-result, there are k! permutations for a length k subsequence
overall there are (k!)^(n/k) results, height of the comparsion tree at least 
    lg((k!)^(n/k))  = n/k * lg(k!)
                    = n / k * Ω(klgk)
                    = Ω(nlgk)
which is a lower bound of the worst case performance

8.2-1
[ 2, 4, 6, 8, 9, 9, 11 ]
[ null, null, null, null, null, 2, null, null, null, null, null ]
[ 2, 4, 5, 8, 9, 9, 11 ]
[ null, null, null, null, null, 2, null, 3, null, null, null ]
[ 2, 4, 5, 7, 9, 9, 11 ]
[ null, null, null, 1, null, 2, null, 3, null, null, null ]
[ 2, 3, 5, 7, 9, 9, 11 ]
[ null, null, null, 1, null, 2, null, 3, null, null, 6 ]
[ 2, 3, 5, 7, 9, 9, 10 ]
[ null, null, null, 1, null, 2, null, 3, 4, null, 6 ]
[ 2, 3, 5, 7, 8, 9, 10 ]
[ null, null, null, 1, null, 2, 3, 3, 4, null, 6 ]
[ 2, 3, 5, 6, 8, 9, 10 ]
[ null, null, 1, 1, null, 2, 3, 3, 4, null, 6 ]
[ 2, 2, 5, 6, 8, 9, 10 ]
[ null, 0, 1, 1, null, 2, 3, 3, 4, null, 6 ]
[ 1, 2, 5, 6, 8, 9, 10 ]
[ null, 0, 1, 1, 2, 2, 3, 3, 4, null, 6 ]
[ 1, 2, 4, 6, 8, 9, 10 ]
[ 0, 0, 1, 1, 2, 2, 3, 3, 4, null, 6 ]
[ 0, 2, 4, 6, 8, 9, 10 ]
[ 0, 0, 1, 1, 2, 2, 3, 3, 4, 6, 6 ]

8.2-2
assume Al = Ak, l < k
as j iters from A.length down to 1
Ak will first be placed into B at B[C[A[k]]]
C[A[j]] is then decremented by 1
as l < k, when j = l, C[A[l]] = C[A[k]] is smaller than when it was in iteration j = k
therefore if Al = Ak, l < k, they are placed at Bi, Bj that i < j
for n elements that are mutually equivalent
as the relative order of any two of them are preserved, the overall order must also be preserved

8.2-3
the argument in the text didn't specify the order of A[j]
reversing the order of A[j] and the argument still holds
but this time any two Al = Ak, l < k, are placed in Bi, Bj, i > j
the sorting algorithm is no longer stable

8.2-4
the array C can be used to solve this problem:
the number of elements falls into the range [a .. b]
can be computed as the number of elements equal or less than b - the number of elements equal or less than a - 1
which in turn is C[b] - C[a-1]
./CLRS/sort/linear-sort.ts#countingRange

8.3-1
[ 'SEA', 'TEA', 'MOB', 'TAB', 'DOG', 'RUG', 'DIG', 'BIG', 'BAR', 'EAR', 'TAR', 'COW', 'ROW', 'NOW', 'BOX', 'FOX' ]
[ 'TAB', 'BAR', 'EAR', 'TAR', 'SEA', 'TEA', 'DIG', 'BIG', 'MOB', 'DOG', 'COW', 'ROW', 'NOW', 'BOX', 'FOX', 'RUG' ]
[ 'BAR', 'BIG', 'BOX', 'COW', 'DIG', 'DOG', 'EAR', 'FOX', 'MOB', 'NOW', 'ROW', 'RUG', 'SEA', 'TAB', 'TAR', 'TEA' ]

8.3-2
insertion sort:
    stable, two element will be swapped only if the later is smaller than the former
merge sort:
    stable, in the merge procedure
    when element from left subarray is equal to the right one, the left one is always copied to A first
    within left or right subarray, elements are copied to A in the original order
heap sort:
    not stable
    e.g. [1a, 1b, 3]
        after BUILD-MAX-HEAP, will be [3, 1b, 1a]
        after first swap, will be [1a, 1b, 3]
        after second swap, will be [1b, 1a, 3]
quick sort:
    not stable     
    an element can be swapped to arbitrary place to its right if
        it is currently the first element greater than the pivot
        the element examined in the current iteration is smaller or equal to the pivot
    the original order of equivalent elements may not hold
zip the array with its index
comparsion now compares the index in the original array whenever two elements are equal
as array indices are distinct, the sort must be stable

8.3-3
invariant:
    after ith iteration, the array is sorted according to the i least significant digits of elements
inititialization:
    considering 0 digits (nothing), all elements are equal, trivially satisfied
maintenance:
    at the beginning of ith iteration, elements are sorted according to i-1 least significant digits 
    they are then sorted according to ith least significant digit
    at the end of ith iteration
        1.  they are sorted according to the ith least significant digit
        2.  for elements that have same ith least significant digit, the original order is preserved (stable)
            i.e. they are sorted according to i-1 least significant digits
    therefore the array is sorted according to i least significant digits
termination:
    i = d, the array is sorted

8.3-4
b = lg(n^3) = 3lgn >= lgn
choose r = lgn yields Θ(bn/lgn) = Θ(3nlgn/lgn) = Θ(3n) = O(n)

8.3-5
assume in n elements, Xi starts with digit i, Σ(i = {0 .. r-1})Xi = n, r is the radix
T(n, d) = Σ(T(Xi, d-1)) + Θ(n)
the height of the recurrence tree solely depends on d
in the worst case, n is evenly divided, the recurrence tree is a complete d-ary tree
number of sorting pass equals the number of interal nodes = r^d
a single call to the procedure creates r bins
when called recursively, the procedure keeps track of bins at most r * number of nodes in longest path = d

8.4-1
bucket 0:  []
bucket 1:  [ 0.13, 0.16 ]
bucket 2:  [ 0.2 ]
bucket 3:  [ 0.39 ]
bucket 4:  [ 0.42 ]
bucket 5:  [ 0.53 ]
bucket 6:  [ 0.64 ]
bucket 7:  [ 0.79, 0.71 ]
bucket 8:  [ 0.89 ]
bucket 9:  []
bucket 0 (sorted):  []
bucket 1 (sorted):  [ 0.13, 0.16 ]
bucket 2 (sorted):  [ 0.2 ]
bucket 3 (sorted):  [ 0.39 ]
bucket 4 (sorted):  [ 0.42 ]
bucket 5 (sorted):  [ 0.53 ]
bucket 6 (sorted):  [ 0.64 ]
bucket 7 (sorted):  [ 0.71, 0.79 ]
bucket 8 (sorted):  [ 0.89 ]
bucket 9 (sorted):  []
[ 0.13, 0.16, 0.2, 0.39, 0.42, 0.53, 0.64, 0.71, 0.79, 0.89 ]

8.4-2
when every element falls within the same bucket, insertion sort have to sort n elements in Θ(n^2) time
use better in-place algorithm than insertion sort when sorting the buckets

8.4-3
X ~ Bin(2, 1/2)
E[X]^2 = 1
E[X^2] = Var[X] + E[X]^2 = 3/2

8.4-4
the area is proportional to d^2
kth bucket should contain elements that 
    k/n <= di^2 < (k+1)/n
    k <= di^2 * n < k+1
    k = Math.floor(di^2 * n)

8.4-5
same as 8.4-4,
kth bucket should contains elements that
    k/n <= P(x) <= (k+1)/n

8-1
a.  each one of n! permutations of orders happens equally likely, with probaility 1/n!
    each one corresponds to a leaf in the comparsion tree as that's the only way to distinguish between them
    also an order of input can only corresponds to a single leaf
    if two leaves have the same value, as they start from the same root, they must have branched somewhere
    but for a fixed input, no comparsion can give different result on two runs
    the comparsion tree thus has n! leaves with 1/n! probability, other leaves unreachable
b.  assume LT has lk leaves, RT has rk leaves
    lk + rk = k, also when considered as the leaves of T their depth is one higher than in LT or RT
    D(T)    = D(LT) + lk + D(RT) + rk
            = D(LT) + D(RT) + k
c.  basically dynamic programming 
    the minial tree may have 0 <= i <= k leaves in its left subtree and k-i leaves in its right subtree
    if the left subtree didn't achieve d(i), swap one that does will reduce D(T)
    similarly the right subtree must have achieved d(k-i)
    d(k) = min(0 <= i <= k)(d(i) + d(k-i) + k)
    also when i = 0 or k, d(i) + d(k-1) + k = d(k) + k, which cannot be the minimal
    d(k) = min(1 <= i <= k-1)(d(i) + d(k-i) + k)
d.  d/di(ilgi + (k-1)lg(k-1))   = (lni - ln(k - x))/ln(2)
    has root i = k/2
    for 1 <= i < k/2, the first derivative is negative
    for k/2 < i <= k-1, the first derivative is positive
    therefore i = k/2 is a local maximum in range [1, k-1]
    assume d(k) >= cklgk
    d(k)    >= min{cilgi + c(k-i)lg(k-i) + k}
            = c(k/2)lg(k/2) + c(k/2)lg(k/2) + k
            = ck(lgk - 1) + k
            = cklgk - ck + k
            >= cklgk when c < 1
    d(k) = Ω(klgk)
e.  as d(k) is the minimum of D(k), D(k) = Ω(klgk), the average depth of leaves is D(k)/k = Ω(klgk) / k = Ω(lgk)
    D(T) = D(n!) = Ω(n!lgn!)
    average-case time is Ω(lgn!) = Ω(nlgn)
f.  as a randomization node didn't compare any two elements of the array, it gains no information of the order
    thus a randomization node didn't eliminate any possbility of the order of an array
    all children of a randomization node therefore must have the same set of leaves
    replace all randomization node with its child with minimal D(T)
    the result is still a valid comparsion tree which contains all possible n! permutations as leaves
    but the resulting tree will be deterministic
    as the child is chosen as having minimal D(T), the resulting tree has no worse average-case performance

8-2
a.  counting sort
b.  one pass of quicksort
c.  heap sort
d.  with counting sort, each bit has maximum 2, counting sort takes Θ(n + 2) = Θ(n)
    radix sort in turn takes Θ(bΘ(n)) = Θ(bn)
e.  ./CLRS/sort/linear-sort.ts#inplaceCountingSort
    not stable, whatever in C[A[i]] is swapped with A[i], it may not be the last element that equals to A[i]

8-3
a.  1.  divide numbers of different order of magnitudes into different sets
        the order of magnitude of a number k can be find in time d = log10(k) by repeatedly dividing 10
        the order of all numbers thereby can be computed in time Σd = n
    2.  radix sort each set of size ni, contains number with di digits
        each set takes time Θ(di * ni), Σdini = n, Θ(n) in total
    3.  concat the results in the correct order
        a number with more digits is always greater than a number with less digits
        as Σni <= n, this step takes O(n) time
    overall Θ(n)
b.  1.  first divide strings of different length into different list L[i]
        the length of all strings can be computed in time O(n)
    2.  initialize i as length of the longeset string, S an empty list, repeatedly:
            S = concat L[i] and S
            counting sort S with ith character (by definition of L, all strings in S now has i characters at least)
            decrement i
        when i > 0
        let ni = number of strings with at least i characters 
        each iteration takes O(ni) and Σni = n
    3.  on termination, S contains all strings of length at least 1 in sorted order
        return concatenation of all empty strings in L[0] with S
    overall Θ(n)
    at the start of each iteration, S contains strings sorted according to i+1th and later characters
    strings in L[i] has length i, can be treated as empty strings (i.e. least) considering i+1th and later characters
    thus prepending L[i] to S, the resulting list still sorted according to i+1th and later characters
    counting sort with ith character and the invariant carried to the next iteration
    ./CLRS/sort/linear-sort.ts#stringSort

8-4
a.  pick one red jug, test it with all blue jugs, repeat for all red jugs
    T(n) = n * n = Θ(n^2)
b.  for a fixed permutation of red jugs, any permutation of blue jugs may be the correct grouping
    n! possible results and the comparsion tree has height at least nlgn
    the worst case performance of the algorithm is Ω(nlgn) 
c.  by simultaneously quicksort red and blue jugs, repeatedly:
        1.  pick a random red jug r, test with all blue jugs
            divide blue jugs into groups that 
                R1: hold more water than r
                R2: hold less water than r
                R3: hold the same amount water as r (denote this jug as b)
        2.  test all red jugs with b, similarly divide red jugs into three groups B1, B2 and B3
        3.  recursively solve (R1, B1), (R2, B2)
    the set of red and blue jugs R and B can be treated as two equivalent set of numbers
    by picking r randomly, r works as a random pivot of B
    as b = a, R is partitioned in exactly the same way as B
    expected running time analysis of quicksort than applies

8-5
a.  just sorted normally
b.  1, 3, 2, 4, 5, 6, 7, 8, 9, 10 
c.  for any i,
        Σ(j = {i .. i+k-1})(A[j])/k <= Σ(j = {i+1 .. i+k})(A[j])/k
        A[i] <= A[i+k]  // other array elements cancelled each other
    conversely,
        A[i] <= A[i+k]
        //  add Σ(j = {i+1 .. i+k-1})(A[j]) to both sides
        Σ(j = {i .. i+k-1})(A[j]) <= Σ(j = {i+1 .. i+k})(A[j])
        Σ(j = {i .. i+k-1})(A[j])/k <= Σ(j = {i+1 .. i+k})(A[j])/k
d.  divides the array into k subarrays, each of length n/k
    sort each in time O(n/klg(n/k)), O(nlg(n/k)) in total
    merge the sorted subarrays to form A' that
        A'[i], A'[i+k], A'[i+2k] .. are from ith sorted subarray
    overall running time O(nlg(n/k))
e.  for 0 <= i <= k-1,
        A[i] <= A[i+k] <= A[i+2k] ..
    hence a k-sorted array can be divided into k sorted arrays
    by 6.5-9, k sorted arrays of length n/k can be merged into a single sorted array in time O(nlgk)
f.  when k is a constant, O(nlgk) = O(n)
    if k-sorting an array of size n can be done in time o(nlgn)
    o(nlgn) + O(n) = o(nlgn), the array can be completely sorted in time o(nlgn)
    in contradiction to Ω(nlgn) lower bound
    therefore k-sorting an array of size n must take Ω(nlgn)

8-6
a.  there are C(2n, n) ways to choose n elements from 2n ones
    C(2n, n) = (2n)! / (n!)^2
    the other n elements are automatically what not chosen
b.  all C(2n, n) leaves must be reachable from the root of the decision tree
    height of the tree at least lg(C(2n, n))
    by Stirling's approximation, 
        (2n)! / (n!)^2  = (4πn)^(1/2) * (2n/e)^2n * (1 + d/2n) / (2πn * (n/e)^2n * (1 + d/n)^2)
                        = (2^2n / (πn)^(1/2)) * (1 + d/2n) / (1 + d/n)^2
    where
        (1 + d/2n) / (1 + d/n)^2    = (1 + d/n - d/2n) / (1 + d/n)^2
                                    = 1/(1 + d/n) + (d/2n) / (1 + d/n)^2
                                    = 1 + O(1/n) as n -> ∞
        (2n)! / (n!)^2  = (2^2n)(1 + O(1/n)) / (πn)^(1/2)
    lg(C(2n, n))    = 2n + lg(1 + O(1/n)) - lg(πn)/2
                    = 2n - o(n) as n -> ∞
c.  if two elements a and b should be placed consecutively in sorted order, a <= b
    if a and b are not compared
        any element smaller than or equal to a will be smaller than or equal to b
        any element greatre than a will be greater than b
    no matter how much comparsions are made, a and b cannot be distinguished
    for the result to be correctly sorted, a and b must be compared
d.  there are 2n-1 consecutive pairs in an array of size 2n
    thus 2n-1 comparsions at least

8-7
-

Chapter 9
9.1-1
thanks https://ita.skanev.com/09/01/01.html
recursively:
    1.  divide the array into two
    2.  recursively find minimum of both subarrays, each with a list of elements compared to the minimum associated 
    3.  find minimum of the array as smaller of the two
    4.  append the greater to the list associated to the smaller
when the procedure terminates, it returns a list of elements been comapared to the minimum so far
number of comparsions performed equals to the number of internal nodes, which is n - 1
the list has size equal to the height of the recurrence tree, which is lgn
invariant:
    at each level, all elements in the subarray except the minimum is greater of equal to an element in the list
initialization:
    array size is 1, consists of a single element, which is the minimum, trivially satistied
maintenance:
    assume l, r are minimum of subarrays
    L, R are lists associated to them
    without loss of generality, if l <= r, L' = L ∪ {r} is the new list
    all elements in the left subarray except l >= one element in L
    all elements in the right subarray are >= r, thus >= one element in L'
termination:
    -
therefore the second minimum must be in the list associated to the minimum value
the minimum of them can be find with lgn - 1 comparsions, n - 1 + lgn - 1 = n + lgn - 2 in total

9.1-2
initially any element can be the maximum or the minimum
the number of potential maximum and minimum both equal to n, denote them as MIN and MAX
assume all elements are distinct, elements can be divided into 4 groups:
    1.  may be either maximum or minimum
    2.  may be maximum, may not be minimum
    3.  may be minimum, may not be maximum
    4.  may be neither maximum or minimum
comparing two elements a and b from group 1 will:
    if a < b, a now in group 3, b now in group 2, both MIN and MAX decremented by 1
comparsions between any combinations of elements from 2, 3 or 4, depends on the result, may be in vain
comparsions between a from group 1 and b from group 2, 3 or 4, depends on the result, may only decrement MIN+MAX by 1
thereby in worst case, it's optimal to perform comparsions between elements in group 1 first until group 1 is empty
such comparsions can only be performed n/2 times, eliminate n/2 potential maximum and minimum independent of the input
then the input array is divided into two disjoint groups, n/2 potential maximum and n/2 potential minimum
in worst case, maximum and minimum can be find among them in (n/2 - 1) * 2 = n - 2 comparsions
n/2 + n - 2 = 3n/2 - 2 in total

9.2-1
assume initially p < r, 1 <= i <= r - p + 1
if the left subproblem is empty, q = p, k = p - p + 1 = 1
i cannot be less than 1, so the procedure will not recursively solve the left subproblem
if the right subproblem is empty, q = r, k = r - p + 1
i cannot be greater than r - p + 1, so the procedure will not recursively solve the right subproblem

9.2-2
T(max(k-1, n-k)) is the same whether Xk = 0 or Xk = 1

9.2-3
./CLRS/sort/order.ts#randomizedSelect2

9.2-4
when pivot is always the maximum value

9.3-1
when divided into groups of 7, 
number of elements greater than x is at least
    4(1/2 * n/7 - 2) >= 2n/7 - 8
T(n)    <= c[n/7] + c(5n/7 + 8) + dn
        = 6cn/7 + 8c + dn
        = cn + (8c + dn - cn/7)    
        <= cn for c > 7d and large enough n
when divided into groups of 3,
number of elements greater than x is at least
    2(1/2 * n/3 - 2) >= n/3 - 4
T(n)    = T(n/3) + T(2n/3 + 4) + O(n)
        >= T(n/3) + T(2n/3) + O(n)
        = Θ(nlgn), no longer linear

9.3-2
3n/10 - 6 >= n/4
6n - 120 >= 5n
n >= 120

9.3-3
the lower median can be find in time O(n)
by finding the index of the lower median in O(n)
the array can be partitioned into subproblems of equal size in O(n)
a good split is then guarenteed, worst case running time thus O(nlgn)

9.3-4
assume all elements are distinct
let array elements be vertices of a graph, an edge a -> b exists iff some comparsion gives a > b
for vertices a and b
    if there is a path a -> b, a > b
    if there is a path b -> a, b > a
    otherwise it's uncertain whether a > b or b > a
also the graph is acyclic, otherwise for some element a on the cycle, a > a
for a procedure to correctly find the ith smallest element x, the comparsions it makes must ensure that:
    i-1 elements are smaller than x
    n-i elements are greater than x
therefore by additionally update the graph according to every comparsion
the set of i-1 elements smaller than x can be found by dfs from the vertex x
the set of i-1 elements greater than x can be found by dfs the reverse graph from the vertex x

9.3-5
by simulating binary search
let mid be the order of lower median, to find the ith smallest element
    if i = mid, one run of black-box can solve the problem
    if i > mid:
        find the median in O(n)
        filter elements smaller than the median from the array, O(n)
        find (i - mid)th smallest element in the resulting array recursively
    if i < mid:
        similarly filter the array
        find ith smallest element in the resulting array recursively
T(n) = T(n/2) + O(n) = O(n)

9.3-6
using select, an array can be partitioned around the median in time O(n)
therefore in time O(nlgk), the array can be divided into n/k chunks that
    1.  each chunk is of length k
    2.  elements in each chunk is greater than elements in previous chunks, smaller than elements in succeeding ones
then the maximum of each chunk forms the kth quantiles, which can be found in time O(n)
O(nlgk) + O(n) = O(nlgk) in total

9.3-7
find S in O(n)
substract S from every element, take abstract value in O(n)
find kth smallest element x of these abstract value in O(n)
filter the original input array for elements that has distance to S smaller or equal to x in O(n)

9.3-8
thanks https://ita.skanev.com/09/03/08.html
recursively:
    1.  find the medians ma, mb of the two array A, B
    2.  if the two medians equal, return either one
    3.  if ma > mb
            more than half of the elements in both arrays are greater than mb
            more than half of the elements in both arrays are smaller than ma
            the median of both arrays must be between ma and mb
            by dropping same amount of elements > ma and < mb, the overall median will not change
        drop elements > ma in A, elements < mb in B, get a subproblem of half size

9.3-9
denote the y coordinate of the main pipeline as y0, then
    y0 = min{Σ(|yi - y|)}
where (xi, yi) is the coordiante of ith well
when y is greater than the y coordinate of k wells and smaller than n-k,
    increasing y by an amount of ε will increase cost by εk, while decrease cost by ε(n-k) at the same time
therefore before k = n/2, increasing y will improve the solution
starting from = n/2 + 1, increasing y will increase the total cost
the problem is equivalent to finding the median of all y coordinates
the optimal solution is either the median, or any value between lower and higher medians

9-1
a.  O(nlgn)
b.  O(n) + O(nlgi)
c.  O(n) + O(ilgi)

9-2
a.  the median satisfies that, exactly [n/2] - 1 numbers are smaller than it
    each one has weight 1/n
        Σ(i = {1 .. [n/2] - 1})(1/n)
        = ([n/2] - 1)(1/n) < 1/2
        Σ(i = {[n/2] + 1 .. n})(1/n)
        = ([n/2] - 1)(1/n) < 1/2
b.  sort the elements
    find the greatest k that Σwi < 1/2 in sorted order
    then
        Σ(i = {1 .. k})(wi) < 1/2
        Σ{i = {1 .. k+1}}(wi) >= 1/2
        Σ(i = {k+2 .. n})(wi) >= 1/2
    and xk+1 is the median
c.  by modifying SELECT
    still partition the array around median of medians
    then compute the weight sum of elements smaller and greater than the pivot wl and wg
    if wl < 1/2 and wg <= 1/2, pivot is the weighted median
    if wl >= 1/2, the weighted median is among elements smaller than the pivot
        recursively find the weighted median in the subproblem
    if wg > 1/2, the weighted median is among elements greater than the pivot
        recursively find the element that's greater than elements sum to (1/2 - wl) in the subproblem
    running time O(n) as in text
d.  the same argument as 9.3-9
    increasing p a small amount ε will increase the sum by Σ(pi < p)(wiε) and decrease the sum by Σ(pi > p)(wiε)
    thus when Σ(pi > p)(wi) > 1/2, increasing p will reduce the total sum of weights
    when Σ(pi > p) < 1/2, inceasing p will increase the total sum of weights
    the minimum therefore is at greatest p where Σ(pi > p) >= 1/2
d.  min(p){Σd(a, b)} = min(x, y){Σ|xi - x| + Σ|yi - y|} = min(x){Σ|xi - x|} + min(y){Σ|yi - y|}
    when the x or y coordiate of the solution is changed, the other half of the sum won't change
    by finding the weighted median of x and y seperately, both part are minimized

9-3
a.  ?
b.  assuming Ui(n) <= n + cT(2i)lg(n/i)
    Ui(n)   <= n/2 + (n/2 + cT(2i)lg(n/2i)) + T(2i)
            = n + cT(2i)(lg(n/i) - 1) + T(2i)
            = n + cT(2i)lg(n/i) - cT(2i) + T(2i)
            <= n + cT(2i)lg(n/i) when c >= 1
c.  when i is constant,
    Ui(n)   = n + O(T(2i)lg(n/i))
            = n + O(lgn)
d.  when when i = n/k,
    Ui(n)   = n + O(T(2i)lg(n/i))
            = n + O(T(2n/k)lg(n/(n/k)))
            = n + O(T(2n/k)lgk)

9-4
a.  same as quicksort, zi and zj will be compared only if either zi or zj is first chosen as the pivot
    but this time, if i < j < k and an element between zj and zk is first chosen as pivot,
    the procedure will not recurse into the subproblem containing zi and zj
    Xijk = 1 only when zi or zj are the first pivot among {zi .. zk}
    similarly when k < i < j and an element between zk and zi is first chosen as pivot, zi and zj will not be compared
    Xijk = 1 only when zi or zj are the first pivot among {zk .. zj}
    namely
        E[Xijk] = 2/(k - i + 1) if i < j < k
                = 2/(j - k + 1) if k < i < j
                = 2/(j - i + 1) if i <= k <= j, i < j
                = 0 if i = j
b.  E[Xk]   = E[Σ(i = {1 .. n})(Σ(j = {i .. n})(Xijk))]
            = E[Σ(i = {1 .. k})(Σ(j = {k .. n})(Xijk))]
            + E[Σ(i = {k+1 .. n})(Σ(j = {i .. n})(Xijk))]
            + E[Σ(i = {1 .. k})(Σ(j = {i .. k-1})(Xijk))]
            = Σ(i = {1 .. k})(Σ(j = {k .. n})(2/(j - i + 1)))
            + Σ(i = {k+1 .. n})(Σ(j = {i .. n})(2/(j - k + 1)))
            + Σ(i = {1 .. k-2})(Σ(j = {i .. k-1})(2/(k - i + 1)))
            = 2Σ(i = {1 .. k})(Σ(j = {k .. n})(1/(j - i + 1)))
            + 2Σ(j = {k+1 .. n})(Σ(i = {k+1 .. j})(1/(j - k + 1)))
            + 2Σ(i = {1 .. k-2}(k-i-1)/(k-i+1))
            <= 2Σ(i = {1 .. k})(Σ(j = {k .. n})(1/(j - i + 1)))
            + 2Σ(j = {k+1 .. n})(j - k - 1)/(j - k + 1))
            + 2Σ(i = {1 .. k-2}(k-i-1)/(k-i+1))
c.  (j - k - 1)/(j - k + 1) < 1
    (k - i - 1)/(k - i + 1) < 1
    2Σ(j = {k+1 .. n})(j - k - 1)/(j - k + 1)) + 2Σ(i = {1 .. k-2}(k-i-1)/(k-i+1))
    <= Σ(i = {1 .. n}1) = n
    2Σ(i = {1 .. k})(Σ(j = {k .. n})(1/(j - i + 1)))
    = 1/k + 1/(k+1) + .. + 1/n
    + 1/(k-1) + 1/k + .. + 1/(n-1)
    + ...
    + 1/1 + 1/2 + .. + 1/(n-k+1)
    starting from 1/1, the term 1/i appears at most on i lines
    therefore the sum <= Σi/i = n
    E[Xk] <= 2 * 2n = 4n
d.  as E[Xk] <= 4n = O(n)

Chapter 10 
10.1-1
[ 4 ]
[ 4, 1 ]
[ 4, 1, 3 ]
Pop:  3
[ 4, 1 ]
[ 4, 1, 8 ]
Pop:  8
[ 4, 1 ]

10.1-2
two stacks, one starts from index 0 and grows upward, one starts from index n - 1 and grows downward

10.1-3
head: 0, tail: 1
[ 4, <5 empty items> ]
head: 0, tail: 2
[ 4, 1, <4 empty items> ]
head: 0, tail: 3
[ 4, 1, 3, <3 empty items> ]
Dequeue:  4
head: 1, tail: 3
[ 4, 1, 3, <3 empty items> ]
head: 1, tail: 4
[ 4, 1, 3, 8, <2 empty items> ]
Dequeue:  1
head: 2, tail: 4
[ 4, 1, 3, 8, <2 empty items> ]

10.1-4
./CLRS/collection/queue.ts#Queue
by maintaining the size of the queue explicitly

10.1-5
./CLRS/collection/queue.ts#Deque

10.1-6
two stacks A and B
enqueue push elements into A
dequeue pops elements from B
when B is empty, pop all elements from A and push into B in turn
enqueue: constant time
dequeue: amortized constant time

10.1-7
keep track of the number of elements in the queue A
push enqueues an element into A
when currently there are n elements in the queue, repeat n - 1 times:
    dequeue an element
    enqueue it immediately
then the next element dequeued is the last element pushed 
one queue is sufficient 
push: constant time
pop: linear time

10.2-1
insert still O(1), inserted before the head of the list
delete is now O(n), the previous node of can no longer be find in O(1), must traverse the list

10.2-2
PUSH:   insert a new node at the head of the list
POP:    delete the head, make head.next the new head, return the value contained by the head
        if head = NIL, throw underflow

10.2-3
additionally maintain the tail of the list
ENQUEUE:    append a new node to the tail of the list, update the tail to the new node
DEQUEUE:    delete the head, make head.next the new head, return the value contained by the head
            if head = NIL, throw underflow

10.2-4
set L.nil.key = k before the loop
when the loop terminates, either x = L.nil or another node x.key = k is found

10.2-5
./CLRS/collection/slist.ts#SList
INSERT: O(1)
DELETE: O(n)
SEARCH: O(n)

10.2-6
by explicitly maintaining the tail of the list as a field
./CLRS/collection/dlist.ts#concat

10.2-7
traverse the list, repeatedly delete and insert nodes
./CLRS/collection/slist.ts#reverse

10.2-8
assume the pointer to NIL is NULL = 0x0
this.head.np = this.head.next ^ NULL = this.head.next
for any two conservative nodes x and y,
    x.np = x.prev ^ x.next = x.prev ^ &y
    y.np = y.prev ^ y.next = &x ^ y.next
starting from any two concervative nodes, the dlist can be traversed in any direction
hence search can be performed in a similar manner
insert updates this.head.np to this.head.np ^ &new_head
delete cannot be performed in constant time, must traverse the list to get two conservative nodes
by swapping the value of head and tail, the list is reversed in constant time

10.3-1
double list
        1   2   3   4   5   6
next    2   3   4   5   6   -
key     13  4   8   19  5   11
prev    -   1   2   3   4   5
single list
        1   2   3   4   5   6
next    2   3   4   5   6   -
key     13  4   8   19  5   11

10.3-2
the same procedure
x.next now points to the word at x+1

10.3-3
the procedure never need to traverse the free list, only insert and delete from head
insertion only have to set the next of the new head
deletion only have to follow the next of the current head

10.3-4
will have to copy and move nodes as long as a node can be deleted from the middle of the list

10.3-5
assume a move operation that moves the content of node x to y
overwrites array entry y, while maintains the correctness of prev and next pointers
traverse the list L, for ith list node x
    inspect node in ith entry of the array
    if ith entry is free, move x to ith entry, free x
    if ith entry is another list node, allocate a new object y, move i to y, move x to i, free x
after n iterations, ith list node is stored at ith entry of the list

10.4-1
-

10.4-2
./CLRS/collection/tree.ts#printTree

10.4-3
./CLRS/collection/tree.ts#printTreeStack

10.4-4
./CLRS/collection/tree.ts#printSiblingTree

10.4-5
./CLRS/collection/tree.ts#printTreeConstant

10.4-6
use a boolean is_last_child to indicate whether this child is the last one of its parent
the first pointer is still the left-child
the second pointer, when is_last_child == false, is still the right-sibling
when is_last_child == true, the second pointer points to the parent

10-1
search      O(n)    O(n)    O(n)    O(n)
    search is always linear
    there's no way in linked list to reach a particular node without traversing all nodes before it
insert      O(1)    O(n)    O(1)    O(n)
    insert into unsorted lists can be done in constant time by inserting to the head
    while insertion into sorted lists have to maintain the order
delete      O(n)    O(1)    O(n)    O(1)
    deletion always has to modify the previous node
    in singly linked list, there's no efficient way to find the previous node, have to traverse from the head
successor   O(n)    O(1)    O(n)    O(1)
    in unsorted lists, successor have to search the whole list
    in sorted lists, successor only have to call next on the input node
predecessor O(n)    O(n)    O(n)    O(1)
    in unsorted lists, predecessor have to search the whole list
    in sorted lists, successor only have to call prev on the input node
    but singly linked list have no pointer points to the previous node, have to traverse the whole list
minimum     O(n)    O(1)    O(n)    O(1)
    have to search the whole lists when unsorted
    in sorted list minimum is just the head
maximum     O(n)    O(1)    O(n)    O(1)
    assumes the tail of the list is explicitly maintained
    otherwise if the lists are circular, O(1) for doubly linked sorted list, O(n) for singly linked
    both O(n) if the lists are not circular

10-2
a.  insert:         have to find the right position of the key, O(n)
    minimum:        at the head, O(1)
    extract-min:    delete and return the head, O(1)
    union:          merging two sorted list, O(n)
b.  insert:         insert at the head, O(1)
    minimum:        by searching the whole list, O(n)
    extract-min:    by searching the whole list then delete, O(n)
    union:          must dedup, O(n^2) by naive double loop
                    can be improved to O(nlgn) by first sort both lists then merge
c.  same to b except
    union:          dedup not necessary, simple concatenation will suffice, O(1)

10-3
a.  both algorithm is correct, returning the first node i in the list that key[i] = k or NIL if no such node exists
    if the while loop of COMPACT-LIST-SEARCH takes t iterations
    then none of the first t-1 random j can have key[j] == k
    otherwise by the loop condition, key[i] < k, i will be updated to j, the procedure will return at line 7
    therefore the for loop of COMPACT-LIST-SEARCH' will run for at least t iterations
b.  the for loop runs for t iterations, each O(1)
    after t iterations of the for loop, the distance from i to key k will be Xt
    the while loop sets i = next[i], thus will run for Xt iterations
    T(n) = O(n + Xt)
    E[T(n)] = O(n + E[Xt])
c.  for a particular r, there are
        1.  nodes with distance to the key greater or equal than r
        2.  nodes with distance to the key smaller than r
        3.  nodes after the key
    there are exactly r nodes in group 2
    if no random node j falls within group 2, Xt >= r
    E[Xt]   <= ΣP[Xt >= r]
            = Σ(1 - r/n)^t
d.  bounding by integral
    Σ(r = {0 .. n-1})(r^t)  <= int(0 <= r <= n, r^t)
                            = n^(t+1)/(t+1) - 0^(t+1)/(t+1)
                            <= n^(t+1)/(t+1)
e.  E[Xt]   <= Σ(1 - r/n)^t
            = Σ((n-r)/n)^t
            = Σ(r = {1 .. n})((n-r)^t)/n^t
            = Σ(r = {0 .. n-1})(r^t)/n^t
            <= n^(t+1)/(t+1)n^t
            = n/(t+1)
f.  combine b. and e.
g.  ?
h.  otherwise even node j is further down the list than i, i will not be updated to j as key[i] = key[j]
    when all but the last node contains the same key k
    searching any key smaller or equal to will be O(1)
    searching any key greater than k will be O(n) with or without random skip

Chapter 11
11.1-1
examine every slot, compare with the current maximum and update if not empty 
O(m), m the number of slots in the array

11.1-2
make a bijection between elements and a finite number set {0 .. n - 1} of size n
A[i] = 1 if i ∈ S, A[i] = 0 otherwise
INSERT(i) sets A[i] to 1, DELETE(i) set A[i] = 0
SEARCH(i) returns A[i] == 1

11.1-3
each slot stores a pointer to a doubly linked list
SEARCH(k) inspects whether the linked list at slot k is empty
INSERT(k) inserts at the head of the list
DELETE(x) removes the nodes from the list

11.1-4
thanks Instructor's Manual
by initializing two huge arrays which validate each other
array A stores index of array S, array S stores index of array A
additionally array S has a field S.top
if array A contains key k, A[k] < S.top && S[A[k]] == k, both insert and delete maintains this property
if array A does not contain key k, A[k] is not initialized thus can be any number
if A[k] >= S.top, A[k] is trivially invalid
if A[k] < S.top, it must be set by INSERT(k') with a different k', so S[A[k]] !== k

11.2-1
define indicator variable Xij as
    Xij = 1 when h(ki) = h(kj)
        = 0 otherwise
by simple uniform hashing, Pr{Xij = 1} = 1/m
the expected total number of collisions is
    E[Σ(i = {1 .. n})(Σ(j = {i+1 .. n})(Xij))]
    = C(n, 2)(1/m)
    = n(n-1)/m

11.2-2
A = [5, 28, 19, 15, 20, 33, 12, 17, 10]
B = A.map(n => n % 9);
B = [5, 1, 1, 6, 2, 6, 3, 8, 1]
three collisions in slot 1
two collisions in slot 6

11.2-3
deletion still O(1)
insertion now has to insert the key to the correct position, equivalent to unsuccessful search in average performance
unsuccessful search now stops when the node examined has a key larger than the search key
assume all inserted elements are drawn from a uniform distribution
about half of the α keys that collide with the search key will be smaller or greater than it
expected running time O(1 + α/2), which is O(1 + α)
performance of successful search now depends not on the keys inserted after k, but the keys smaller than k
    Pr{ Xij = 1 } = Pr{ h(ki) = h(kj) ∧ hi > hj } = 1/2m
expected number of nodes examined when searching ki is then
    E[1 + Σ(j = {1 .. n} - i)(Xij)]
    = 1 + (n-1)/2m
on average over all i:
    1/n * n(1 + (n-1)/2m)
    = 1 + (n-1)/2m
    = 1 + α/2 - 1/2m
    = Θ(1 + α)
so search and delete are asymptotically the same to unsorted lists
insertion performance is reduced from O(1) to (1 + α)

11.2-4
set a slot in the hash table not in the range of the hash function
that is, for a h_free, no k will give h(k) = h_free
can add 1 to any existing hash function, so the range changes from {1 .. m} to {2 .. m+1}
slot 1 then is the free slot now
search does not involve allocation and deallocation
insert operation now has to acquire a free node from the free list
    simply delete the head from list in slot h_free, O(1)
delete operation now has to return the node to the free node
    simply prepend the node to list in slot h_free, O(1)
a simply linked list will suffice

11.2-5
pigeonhole principle
if all slots contains list of length smaller than n
the total number of keys stored in the hash table is smaller than nm = |U|
thereby at least one slot contains a list of length greater or equal to n

11.2-6
thanks https://stackoverflow.com/questions/8629447/
repeatedly:
    1.  select a slot <- {1 .. m}
    2.  select a number i <- {1 .. L}
        if i <= length of the list in this slot, take the key in ith node
        otherwise go back to 1.
the procedure succeeds when i <= length of the list
as the expected length of list is α, success rate is α/L
expected number of trials is then L/α by geometric distribution
then ith node is retrieved in time O(L), O(L + L/α) = O(L(1 + 1/α)) in total
consider the hash table as a m x L 2d-array with n entries non-empty
this procedure than uniformly chooses a slot from all m x L entries, both empty and non-empty
as the procedure is redone when an empty entry is chosen, it's a uniform sampling of non-empty entry

11.3-1
compare h(k) to the stored hash value first, only compare the stored strings when hash values equal
comparing two strings will take time proportional to the length of the shorter string
comparing two hash values usually will be constant time

11.3-2
the number s represented by the string is Σ(i = {1 .. r})128^(r-i)ci
assume rk is the number represented by the first k characters of the string modulo m
    rk      = Σ(i = {0 .. k})(128^(r-i)ci) mod m
    rk+1    = Σ(i = {0 .. k+1})(128^(r-i)ci) mod m
            = (Σ(i = {0 .. k})(128^(r-i)ci) + ck+1) mod m
            = 128rk mod m + ck+1 mod m
therefore s mod m can be computed iteratively

11.3-3
let x = c1 .. cn
h(x)    = Σ(i = {1 .. n})((2^p)^(n-i)ci) mod 2^p - 1
        = Σ(i = {1 .. n})(2^p(n-i)ci mod 2^p - 1)
        = Σ(i = {1 .. n})(ci)
therefore any permutation y of x has h(y) = h(x)

11.3-4
[ 700, 318, 936, 554, 172 ]

11.3-5
assume there are |B| slots containing b1 .. b|B| keys
    Σ(i = {1 .. |B|})bi = |U|
then the number of collisions is
    Σ(i = {1 .. |B|})(bi(bi - 1))
    = Σbi^2 - Σbi
by Cauchy-Schwarz inequality,
    (Σbi)^2 <= |B|Σbi^2
    Σbi^2 >= |U|^2 / |B|
    Σ(bi(bi - 1)) >= |U|^2/|B| - |U|
assume Pr{h(x) = h(y)} < 1/|B| - 1/|U|
then the total number of collisions is less than
    C(|U|, 2) * (1/|B| - 1/|U|)
    = |U|(|U| - 1) * (1/|B| - 1/|U|)
    = (|U| - 1)(|U|/|B| - 1)
    < |U|^2/|B| - |U|
therefore it must has Pr{h(x) = h(y)} >= 1/|B| - 1/|U|

11.3-6
-

11.4-1
Linear probing:
[ 22, 88, null, null, 4, 15, 28, 17, 59, 31, 10 ]
Quadratic probing:
[ 22, null, 88, 17, 4, null, 28, 59, 15, 31, 10 ]
Double hashing:
[ 22, null, 59, 17, 4, 15, 28, 88, null, 31, 10 ]

11.4-2
./CLRS/collection/hashtable.ts#OpenAddressing

11.4-3
α = 3/4:
    unsuccessful:   1/(1 - α) = 4
    successful:     (1/α)ln(1/(1-α)) < 2
α = 7/8:
    unsuccessful:   1/(1 - α) = 8
    successful:     (1/α)ln(1/(1-α)) < 3

11.4-4
when gcd(h2(k), m) = d, the subgroup of Zm generated by h2(k) has m/d elements
which means c = m/d is the smallest positive c such that ch2(k) ≡ 0 mod m
hash value is once again h1(k) when i = c = m/d, therefore 1/dth of m entries of the hashtable

11.4-5
1/(1-α) = (2/α)ln(1/(1-α))
α/(1-α) = 2ln(1/(1-α))
e^(α/(1-α)) = 1/(1-α)^2
α = 0.71533 by wolframalpha

11.5-1
"no collisions occur" means insert operation never increments i
for the set of key K inserted, all {h(k): k ∈ K} are distinct
assuming uniform hashing,
    Pr{h(k) = h(k')} <= 1/m for all distinct k and k'
    p(n, m) = (1 - 1/m)^C(n, 2)
            <= e^(-1/m * C(n, 2))
            = e^(-n(n-1)/2m)
therefore when n >= m^(1/2) + 1, p(n, m) <= e^(-1/2) decreases exponentially

11-1
a.  the hashtable is at most half-full when i = n
    by uniform hashing
    all n = 2m keys inserted before, and all k probes of the current key points to uniformly random position in the array
    for any probe, Pr{ith probe hashes the key to an occupied slot} <= 1/2
    the insertion operation will do more than k probes if all the first k probes hashes the key to an occupied slot
    which happens with probability (1/2)^k = 2^-k
b.  2^-2lgn = n^-2 = O(1/n^2)
c.  Pr{X > 2lgn}    = Pr{X1 > 2lgn ∨ X2 <= 2lgn ∨ .. ∨ Xn <= 2lgn}
                    <= ΣPr{Xi > 2lgn}
                    = nO(1/n^2)
                    = O(1/n)
d.  X is capped by n, the total number of keys inserted
    therefore
        E[X]    <= 2lgn * (1 - O(1/n)) + nO(1/n)
                = O(lgn) + O(1)
                = O(lgn)

11-2
a.  the probability that a certain key is hashed to a certain slot is 1/n
    so the number of keys in a slot after n insertion follows binomial distribution with success rate 1/n
        Qk  = P(X = k) 
            = C(n, k)p^k(1-p)^(n-k)
            = C(n, k)(1/n)^k(1 - 1/n)^(n-k)
b.  M = k means at least a slot contains exactly k keys
    let Mi be the number of keys in slot i
    Pr{M = k}   = Pr{∃i, Mi = k ∧ ∀j != i, Mi <= k}
                <= Pr{∃i, Mi = k}
                = Pr{M1 = k ∨ M2 = k .. Mn = k}
                <= ΣPr{Mi = k}
                = nQk
c.  as n -> ∞, (1 - 1/n) -> 1
    (1 - 1/n)^(n-k) < 1
    C(n, k) = n!/k!(n-k)! <= n^k/k!
    Qk  = C(n, k)(1/n)^k(1 - 1/n)^(n-k)
        <= n^k/k! * (1/n)^k
        = 1/k!
        = 1/((2πn)^(1/2) * (k/e)^k * (1 + Θ(1/k)))
        <= 1/(k/e)^k
        = e^k/k^k
d.  when k0 = clgn/lglgn,
        lg(e^k0 / k0^k0)    = k0lge - k0lgk0
                            = clgnlge/lglgn - clgn/lglgn * (lgc + lglgn - lglglgn)
                            = c(lgelgn / lglgn - lgn/lglgn * (lgc + lglgn - lglglgn))
                            = clgn(lge / lglgn - 1/lglgn * (lgc + lglgn - lglglgn))
                            = clgn(lge / lglgn - lgc/lglgn - 1 + lglglgn/lglgn)
        lg(1/n^3) = -3lgn > lgQk0
        -3 > c(lge / lglgn - lgc/lglgn - 1 + lglglgn/lglgn)
    as n -> ∞, lge/lglgn -> 0, lgc/lglgn -> 0, lglglgn/lglgn -> 0
    c(lge / lglgn - lgc/lglgn - 1 + lglglgn/lglgn) -> -c
    so for c > 3, Qk0 < 1/n^3 for large enough n
    as c > 3 > e, e/k < 1, e^k/k^k monotonically decreasing
    Qk <= Qk0 when k <= k0
    Pk <= nQk <= nQk0 = 1/n^2
e.  M is capped by n
    E[M]    <= Pr{M > clgn/lglgn} * n + Pr{M <= clgn/lglgn} * clgn/lglgn
            <= n * 1/n^2 * n + 1 * clgn/lglgn for large enough n
            = 1 + O(lgn/lglgn)
            = O(lgn/lglgn)

11-3
a.  the ith probe examines position 
        (j + 1 + 2 + .. + i) mod m
        = (j + i(i+1)/2) mod m
        = (j + i/2 + i^2/2) mod m
    c1 = 1/2, c2 = 1/2
b.  assume (j + k(k+1)/2) ≡ (j + l(l+1)/2) mod m for some 0 <= k < l <= m-1
        k(k+1)/2 ≡ l(l+1)/2 mod m
        k(k+1)/2 - l(l+1)/2 ≡ 0 mod m
    thanks Instructor's Manual
        (j-i)(j+i+1)/2 ≡ 0 mod m
        (j-i)(j+i+1) = 2dm = 2d2^p = d2^(p+1)
    exactly one of j-i and j+i+1 must be even, the other must be odd
    which means 2^(p+1) must divide one of j-i and j+i+1
    as j-i < m, 2^(p+1) cannot divide j-i
    as j+i <= 2m-2, j+i+1 <= 2m-1 < 2^(p+1), 2^(p+1) cannot divide j+i+1
    therefore k(k+1)/2 !≡ l(l+1)/2 mod m for all distinct k and l
    for all i ∈ {0 .. m-1}, (j + i(i+1)/2) mod m is distinct

11-4
-

Chapter 12
12.1-1
Height 2:
  ┌-21
┌-17
| └-16
10
| ┌-5
└-4
  └-1
Height 3:
  ┌-21
┌-17
| └-16
10
└-5
  | ┌-4
  └-1
Height 4:
21
|   ┌-17
|   | └-16
| ┌-10
└-5
  └-4
    └-1
Height 5:
┌-21
17
└-16
  | ┌-10
  | | | ┌-5
  | | └-4
  └-1
Height 6:
  ┌-21
  | | ┌-17
  | | | | ┌-16
  | | | └-10
  | └-5
┌-4
1
12.1-2
binary search tree:
    left <= parent <= right
min heap:
    left >= parent, right >= parent
it cannot print elements in sorted order in O(n)
as building a min heap takes time O(n)
if it can traverse its element in sorted order in O(n), n elements can be sorted in time O(n)
which is lower than the lower bound of comparsion sort Ω(nlgn)

12.1-3
the same idea as 10.4-5
adjusted when a the key is yielded as 10.4-5 is preorder
./CLRS/collection/tree.ts#inorder

12.1-4
./CLRS/collection/tree.ts#preorder
./CLRS/collection/tree.ts#postorder

12.1-5
as inorder traverses the tree keys in sorted order in O(n)
if a binary search tree can be built from n elements in time o(nlgn), n elements can be sorted in time o(nlgn)
therefore building a binary search tree must take time Ω(nlgn)

12.2-1
by the nature of search tree structure, for any sequences of nodes examined and an index i,
    if A[i] >= A[i+1], A[i] >= A[j] for all j >= i+1
    if A[i] <= A[i+1], A[i] <= A[j] for all j >= i+1
c is not possible as 911 > 240 but 911 < 912

12.2-2
./CLRS/collection/tree.ts#treeMinimum
./CLRS/collection/tree.ts#treeMaximum

12.2-3
./CLRS/collection/tree.ts#treePredecessor

12.2-4
  ┌-21
┌-17
| └-16
10
| ┌-5
└-4
  └-1
search for 21, 10 on path, 16 to the left, 16 > 10
search for 1, 10 on path, 5 to the right, 5 < 10

12.2-5
assume all keys are distinct, current node x has key k
the successor s has key greater than k
it's either 
    1.  in the right subtree of x, or, 
    2.  at some level from the root, x is in the left subtree and s is the parent
then all nodes in case 1 have keys smaller than all nodes in case 2
as x has two children, it's successor must be case 1, in the right subtree of x
then if s has a left child, it has key smaller than s but greater than x
in contradiction to s being the successor of x
similarly the predecessor has no right child

12.2-6
any node s greater than x is either
    1.  in the right subtree of x, or, 
    2.  at some level from the root, x is in the left subtree and s is the parent / in the right subtree
in case 2, as all nodes in the right subtree are greater than the parent, case 2 can be refined to
    2.  at some level from the root, x is in the left subtree and s is the parent
when there's no nodes in case 1, the smallest node in case 2 is the successor of x
consider two nodes s1 and s2, where s2 is higher in the tree than s1
by definition s1 is in the left subtree of s2, s2 > s1
thereby the smallest node in case 2 is just the lowest node in case 2
which in turn is the lowest ancestor of x that has x in its left subtree / whose left child is also an ancestor of x

12.2-7
see 12.2-8, as h = O(n), k = O(n), k + h = O(2n) = O(n)

12.2-8
consider the subtree formed by nodes traversed by the k calls to SUCCESSOR
exactly k nodes is yielded during the traverse
the subtree may contain nodes smaller than the minimum of the k nodes on the path from root to the minimum
similary the subtree may contains nodes greater than the maximum
both path has at most h nodes
the number of nodes in the subtree is at most O(k + 2h)
for any node x in the subtree, x is traversed first from its parent p
either during call to SUCCESSOR(p) or SUCCESSOR(y) for some y
both case the left subtree of x will be traversed before x is visited again
then if x has a right child, its right subtree will be traversed before x is visited the third time
once m the maximum node in the right subtree of x is traversed, SUCCESSOR will go directly to p
if x = p.left, SUCCESSOR(m) = p, the left subtree of p will never be visited again
if x = p.right, SUCCESSOR(m) = p' for which x is in the left subtree of p', the same to above
therefore a node will be visited at most 3 times
T(k) = 3O(k + 2h) = O(k + h)

12.2-9
when x is a leaf node, it has no left nor right child
either SUCCESSOR(x) will return y or PREDECESSOR(x) will return y, depends on x being left or right child of y

