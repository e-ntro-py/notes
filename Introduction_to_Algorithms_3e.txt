// rereading, lost all the notes / codes of the previous reading
Chapter 2
2.1-1
[ 31, 41, 59, 59, 41, 58 ]
[ 31, 41, 41, 59, 41, 58 ]
[ 31, 31, 41, 59, 41, 58 ]
[ 26, 31, 41, 59, 59, 58 ]
[ 26, 31, 41, 41, 59, 59 ]
[ 26, 31, 41, 41, 58, 59 ]

2.1-2
change line 5 to
    while i > 0 and A[i] < key

2.1-3
./CLRS/start/index.ts#linearSearch
loop invariant: 
    none of the first i items in the array equals to v
initialization:
    i == 0, loop invariant holds trivially
maintainance:
    every iteration, A[i] == v is checked
    the loop continues only when A[i] == v is false
termination:
    if the loop terminated early, then A[i] == v and the first i elements in the array are not equal to v
    therefore arr[i] is the first element equals to v
    if the loop terminated on loop condition, i = arr.length, the first i elements are the whole array
    none of the items in the array equals to v, so function returns NIL
    
2.1-4
Input: Two n-element sequence of 0 and 1s, representing two numbers a and b in binary form
Output: a (n+1)-element sequence of 0 and 1s, representing a number c == a + b in binary form
assumes little-endian
./CLRS/start/index.ts#addBinary

2.2-1
Θ(n^3)

2.2-2
invariant: 
    each of the the first i elements of the array are the ith smallest elements
the last element is greater or equal to all the previous items, thereby must be the greatest element
best-case and worst-case both Θ(n^2)

2.2-3
Σip(i) = (Σi) / n = (1 + n) * n / 2n = (1 + n) / 2 on average, Θ(n)
n on worst case, Θ(n)
assuming comparsion of integers takes constant time

2.2-4
hard-code the solution of a specific input in the program 
if input equals to the specific input, returns that solution immediately
base-case runtime reduced to time required to check the input

2.3-1
[ 3, 41, 52, 26, 38, 57, 9, 49 ]
[ 3, 41, 26, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 38, 57, 9, 49 ]
[ 3, 26, 41, 52, 9, 38, 49, 57 ]
[ 3, 9, 26, 38, 41, 49, 52, 57 ]
[ 3, 9, 26, 38, 41, 49, 52, 57 ]

2.3-2
./CLRS/start/mergesort.ts#mergeNoSentinel

2.3-3
when n = 2,
    T(n) = 2 = 2lg2
assume for n = 2^k, T(n) = nlgn = 2^klg(2^k) = k * 2^k
    T(2n)   = T(2^(k+1))
            = 2T(2^k) + 2^(k+1)
            = 2 * 2^k * k + 2^(k+1)
            = k * 2^(k+1) + 2^(k+1)
            = (k+1) * 2^(k+1)
            = (2n)lg(2n)
therefore for n = 2^k, k > 1,
    T(n) = nlgn

2.3-4
T(n)    = Θ(1)          when n = 1
        = T(n-1) + Θ(n) when n > 1

2.3-5
./CLRS/start/index.ts#binarySearch
T(n)    = Θ(1)          when n = 1
        = Θ(n/2) + Θ(1) when n > 1
by master theorem T(n) = Θ(lgn)

2.3-6
cannot improve
each iteration in insertion sort has to shift Θ(n) elements one place to the right
even if the right position to insert the element can be find in time Θ(lgn), shifting still takes Θ(n)
overall time still Θ(n^2)

2.3-7
first sort the array by mergesort
then for every element g in the sorted array, binary search x - g
(if the index of x - g equals the index of g, x = 2g, and such a pair doesn't exist)
./CLRS/index.ts#pairSum
mergesort: Θ(nlgn)
binary search: n * Θ(lgn) = Θ(nlgn)
overall: Θ(nlgn) + Θ(nlgn) = Θ(nlgn)

2-1
a.  insertion sort on an array of length k takes time Θ(k^2)
    there are n/k such arrays, overall runtime Θ(k^2) * n / k = Θ(nk)
b.  the same with figure 2.5
    the height of the tree is reduced to lg(n/k)
    base level performs n/2k merges with arrays of length k, n/2k * Θ(k) = Θ(n) in total
    overall runtime Θ(nlg(n/k))
c.  T(n) = Θ(nk + nlg(n/k))
    if k = ω(lgn), Θ(nk) = ω(nlgn), the runtime of the modified algorithm then is asymptotically greater
d.  k = O(lgn), the precise value of k depends on cache size, hidden constant factors in algorithms, etc.

2-2
a.  it terminates in finite time on all inputs
b.  invariant:
        at the end of each iteration, the smallest element in slice A[j-1 .. A.length] is in A[j-1]
    initialization:
        j = A.length, the first iteration compares A[A.length] to A[A.length - 1], put the smaller in A[A.length - 1]
        which is the smallest in A[A.length - 1 .. A.length]
    maintainance:
        the smallest number is compared with A[j-1], the smaller of the two is swapped to A[j-1]
        inductively A[j-1] now holds the smallest number in A[j-1 .. A.length]
    termination:
        j = i+1, A[i] holds the smallest number in A[i .. A.length]
c.  invariant:
        at the end of each iteration, A[1..i] consists of ith smallest elements and is sorted in non-decreasing order
    initialization:
        at the end of the first iteration, the smallest element in A[1 .. A.length] is placed in A[1]
        it is the smallest element, A[1 .. 1] is trivially sorted
    maintainance:
        the inner loop finds the smallest number in A[i .. A.length] and puts it in A[i]
        A[1 .. i-1] consists of the i-1 smallest elements in A, therefore A[i] is the ith smallest number
        by definition A[i] >= A[i-1], A[1..i] is sorted 
    termination:
        A[1..A.length - 1] consists of A.length - 1 smallest numbers and is sorted
        thereby A[A.length] must be the greatest element in A
        A is sorted in non-decreasing order
d.  inner loop Θ(n)
    outer loop run n - 1 times
    overall runtime (n-1) * Θ(n) = Θ(n^2)
    both the best and worst case of bubble sort performs Θ(n^2) comparsions
    while insertion sort in best case has runtime Θ(n)

2-3
a.  the algorithm performs n additions and n multiplications
    assuming both are contant time, T(n) = Θ(n)
b.  ./CLRS/start/index.ts#naivePolynomial
    k = Θ(n), Math.pow(x, k) = x^k if implemented naively takes time Θ(k), if not takes time Θ(lgk)
    overall runtime Θ(n^2) or Θ(nlgn)
c.  initialization:
        initially y = 0, the sum of an empty sequence
    maintainance:
        y = Σ(k ∈ {0..n-(i+1)})a(k+i+1)x^k = a(i+1) + a(i+2)x + .. + an * x^(n-(i+1)) at the start
        y = ai + xy = ai + a(i+1)x + .. + an * x^(n-i) = Σ(k ∈ {0..n-i})a(k+i)x^k
    termination:
        the end of the last iteration ends with i = 0, the next iteration (not executed) starts with i = -1
        y = Σ(k ∈ {0..n})ak * x^k
d.  as above

2-4
a.  (0, 4), (1, 4), (2, 3), (2, 4), (3, 4)  // zero-based index
b.  [n, n-1 .. 1], every pair is an inversion
    there are C(n, 2) = n(n-1)/2 pairs
c.  every assignment in the insertion sort reduces the total number of inversions by 1
    the sorted array has no inversions
    therefore the number of inversions in an array is a lower bound of the runtime of insertion sort
d.  assume an array A[p..r] and some q that p < q < r, then the total number of inversions in A[p..r] is the sum of
    1.  the number of inersions in A[p..q]
    2.  the number of inversions in A[q+1..r]
    3.  the number of inversions as pairs (i, j) such that
            i in {p..q}, j in {q+1..r}
    for every index i in {p..q}, the number of type 3 inversions is exactly the number of indexes j in {q+1..r} that
        A[i] > A[j]
    which can be calculated in a slightly modified merge function
    ./CLRS/start/mergesort.ts#inversionCount

Chapter 3
3.1-1
max(f(n), g(n)) <= f(n) + g(n) for all n
assume f(n) >= g(n), max(f(n), g(n)) = f(n) = (f(n) + f(n)) / 2 >= (f(n) + g(n)) / 2
symmetrically when g(n) >= f(n), max(f(n), g(n)) >= (f(n) + g(n)) / 2
therefore let c1 = 1, c2 = 1/2,
    1/2(f(n) + g(n)) <= max(f(n), g(n)) <= f(n) + g(n)
    max(f(n), g(n)) = Θ(f(n) + g(n))

3.1-2
(n + a)^b = Σ(k ∈ {0..b})(C(b, k) * n^k * a^(b-k))
the term with highest order is n^b, therefore (n + a)^b = Θ(n^b)

3.1-3
O(n^2) is an upper bound, the set O(n^2) contains all functions from constant to quadratic
denote the running time of algorithm A by T(n)
the statement can then be translated to "T(n) is at least any constant (including 0) for large enough n"
which is meaningless for a asymptotically non-negative function

3.1-4
2^(n+1) = 2 * 2^n = Θ(2^n)
2^2n / 2^n = 2^n, no constant can be asymptotically larger than 2^n

3.1-5
=>: f(n) = Θ(g(n)), c1g(n) <= f(n) <= c2g(n) for n >= n0, then trivally f(n) = O(g(n)) and f(n) = Ω(g(n))
<=: f(n) = O(g(n)) implies f(n) <= c1g(n) for n >= n1
    f(n) = Ω(g(n)) implies f(n) >= c2g(n) for n >= n2
    take n3 = max(n1, n2), c1g(n) <= f(n) <= c2g(n) for n >= n3, f(n) = Θ(g(n))
therefore f(n) = Θ(n) <=> f(n) = O(g(n)) and f(n) = Ω(g(n))

3.1-6
f(n) = Θ(g(n)) => f(n) = O(g(n)), for all inputs g(n) is an upper bound of f(n)
so even in the worst case f(n) = O(g(n))
similarly in the best case f(n) = Ω(g(n))

3.1-7
assume f(n) = o(g(n)) and f(n) = ω(g(n)), then
lim(f(n) / g(n)) = ∞ and lim(f(n) / g(n)) = 0, contradiction
so no such f(n) exist, o(g(n)) ∩ ω(g(n)) = ∅

3.1-8
Ω(g(n, m)) = {f(n, m):  there exist positive constants c, n0, m0 such that
                        cg(n, m) <= f(n, m) for all n >= n0 or m >= m0 }
Θ(g(n, m)) = O(g(n, m)) ∩ Ω(g(n, m))

3.2-1
for n1 >= n2, f(n1) >= f(n2), g(n1) >= g(n2), f(n1) + g(n1) >= f(n2) + g(n2)
thereby f(n) + g(n) is monotonically increasing
for n1 >= n2, g(n1) >= g(n2), f(g(n1)) >= f(g(n2))
thereby f(g(n)) is monotonically increasing

3.2-2
a^log(b, c) = (b^log(b, a))^log(b, c)
            = (b^log(b, c))^log(b, a)
            = c^log(b, a)

3.2-3
n! = (2πn)^(1/2) * (n/e)^n * (1 + Θ(1/n))
lg(n!)  = lg((2πn)^(1/2)) + lg((n/e)^n) + lg(1 + Θ(1/n))
        = 1/2lg(2πn) + nlg(n/e) + lg(1 + Θ(1/n))
        = Θ(lgn) + Θ(nlgn) + O(lgn)
        = Θ(nlgn)
n! = Πn, n! / 2^n = Π(k/2), lim(Π(k/2)) -> ∞, n! = ω(2^n)
n! / n^n = Π(k/n) <= 1/n, lim(1/n) -> 0, n! = o(n^n)

3.2-4
lg((lgn)!) = Θ(lgn * lglgn)
for large enough n,
c1(lgn * lglgn) <= lg((lgn)!) <= c2(lgn * lglgn)
e^c1(lgn * lglgn) <= (lgn)!
n^(c1 * lglgn) <= (lgn)!
as c1 * lglgn is not a constant, (lgn)! cannot be polynomially bounded
thanks https://ita.skanev.com/03/02/04.html
lg((lglgn)!)    = Θ(lglgn * lglglgn)
                = o(lglgn * lglgn)
                = o((lglgn)^2)
                = o(lgn)
asymptotically,
lg((lglgn)!) < lgn
(lglgn)! < e^lgn = n
therefore (lglgn)! is polynomially bounded

3.2-5
by definition, 
lg*lgn = lg*n - 1 = Θ(lg*n)
lg(lg*n) = Θ(lg(lg*n))
therefore lg*lgn is asymptotically larger

3.2-6
((1 + 5^(1/2)) / 2)^2 = (1 + 2 * 5^(1/2) + 5) / 4 = (3 + 5^(1/2)) / 2 = (1 + 5^(1/2)) / 2 + 1
((1 - 5^(1/2)) / 2)^2 = (1 - 2 * 5^(1/2) + 5) / 4 = (3 - 5^(1/2)) / 2 = (1 - 5^(1/2)) / 2 + 1

3.2-7
let g and g' denote golden ratio and its conjugate, r5 denotes square root of 5
g - g' = r5
g^2 = g + 1, g'^2 = g' + 1
F1 = 1 = (g - g') / r5
F2 = 1 = (g^2 - g'^2) / r5
assume Fi = (g^i - g'^i) / r5, Fi+1 = (g^(i+1) - g'^(i+1)) / r5
    (g^(i+2) - g'^(i+2)) / r5   = (g^i * g^2 - g'^i * g'^2) / r5
                                = (g^i * (g + 1) - g'^i * (g' + 1)) / r5
                                = (g^i - g'^i) / r5 + (g^(i+1) - g'^(i+1)) / r5
                                = Fi + Fi+1
                                = Fi+2

3.2-8
by symmetry law
    n = Θ(klnk)
as ln(n) is monotonically increasing
    c1klnk <= n <= c2klnk
    ln(c1klnk) <= ln(n) <= ln(c2klnk)
    lnk + lnlnk + c1' <= ln(n) <= lnk + lnlnk + c2'
    ln(n) = Θ(lnk)
    lnk = Θ(ln(n))
    k = Θ(n) / lnk = Θ(n) / Θ(ln(n)) = Θ(n / ln(n))

3-1
a.  k >= d, p(n) / n^k = Σ(ai * n^(i - k))
    each i - k <= 0, therefore lim(p(n) / n^k) <= ad
    take c = ad + ε, where ε is an arbitrary positive number
    there must exist n0 such that for n >= n0, lim(p(n) / cn^k) < 1, p(n) = O(n^k)
b.  k <= d, p(n) / n^k = Σ(ai * n^(i - k))
    lim(p(n) / n^k) >= ad
    take c = ad/2, with large enough n, cn^k <= p(n), p(n) = Ω(n^k)
c.  k == d <=> k <= d && k >= d
    combine a and b, p(n) = O(n^k) && p(n) = Ω(n^k) => p(n) = Θ(n^k)
d.  if k > d, lim(p(n) / n^k) = 0, p(n) = o(n^k)
e.  if k < d, lim(p(n) / n^k) = ∞, p(n) = ω(n^k)

3-2
a.  y   y   n   n   n
b.  y   y   n   n   n
c.  n   n   n   n   n
    n^sin(n) swings between 1/n and n
d.  n   n   y   y   n
    lim(2^n / 2^(n/2)) = lim(2^(n/2)) = ∞
e.  y   n   y   n   y 
    by 3.16, n^lgc = c^lgn
f.  y   n   y   n   y
    lg(n!) = Θ(nlgn)
    lg(n^n) = nlgn = Θ(nlgn)

3-3
a.  1
    lg(lg*n)
    lg*(lgn) = lg*n - 1
    lg*n
    lnln(n)
    // polylogarithmics:
    2^lg*n // unsure
    (lgn)^(1/2)
    ln(n)
    (lgn)! = Θ(lgn * lglgn)
    (lgn)^2
    2^((2lgn)^(1/2)) // unsure
    // polynomials:
    n^(1/lgn)
    (2^(1/2))^lgn = n^(1/2)
    n 
    2^lgn = n
    nlgn
    lg(n!) = Θ(nlgn)
    n^2
    4^lgn = n^2
    n^3
    // exponentials:
    (lgn)^lgn = n^lglgn
    n^lglgn
    (3/2)^n
    2^n
    n * 2^n
    e^n
    // super-exponentials:
    n!
    (n+1)!
    2^(2^n)
    2^(2^(n+1))
b.  the fastest growing function here is 2^(2^(n+1))
    2^(2^(n+2)) * |sin(n)|

3-4
a.  false, n = O(n^2), n^2 != O(n)
b.  false, let f(n) = n^2, g(n) = n, min(f(n), g(n)) = n, f(n) + g(n) = Θ(n^2) != Θ(n)
c.  f(n) = O(g(n))
    f(n) <= c1g(n)
    lg(f(n)) <= lg(c1(g(n))) = lg(g(n)) + c2 = O(lg(g(n)))
d.  false
    f(n) = O(g(n))
    f(n) <= c1g(n)
    2^f(n) <= 2^c1g(n) = (2^c1)^g(n)
    let f(n) = 2n, g(n) = n
    2^f(n) = 2^2n, 2^g(n) = 2^n, 2^2n != O(2^n)
e.  false, let f(n) = 1/n, f^2(n) = (1/n)^2 = 1/n^2
    lim(f(n) / f^2(n)) = ∞, f(n) = ω(f^2(n))
f.  f(n) = O(g(n))
    f(n) <= c1g(n)
    (1/c1)f(n) <= g(n)
    g(n) = Ω(f(n))
g.  false, let f(n) = 2^n, f(n/2) = 2^(n/2), lim(f(n) / f(n/2)) = ∞, f(n) = ω(f(n/2))
h.  for any g(n) ∈ o(f(n)), lim(g(n) / f(n)) = 0
    for large enough n, lim((f(n) + g(n)) / f(n)) = 1
    let c1 = 1, c2 = 1 + ε, there must exist n0 such that for n >= n0,
        c1f(n) <= f(n) + g(n) <= c2f(n)
    and f(n) + g(n) = Θ(f(n))

3-5
a.  if f(n) != O(g(n)), there's no n0 and c that cg(n) >= f(n) for all n >= n0
    let c be an arbitrary constant, if only for finitely many n, f(n) >= cg(n)
    then take n0 be the greatest of such n, then for n >= n0+1, f(n) < cg(n), f(n) = O(g(n))
    thereby there must be infinitely many n such that f(n) >= cg(n) >= 0, f(n) = ∞Ω(g(n))
    so f(n) != O(g(n)) => f(n) = ∞Ω(g(n)) and f(n) != ∞Ω(g(n)) => f(n) = O(g(n))
    if f(n) = n and g(n) = n * |sin(n)|, then neither f(n) = O(g(n)) or f(n) = Ω(g(n))
b.  it is the complement of set O(g(n)), may work smoother in certain proofs
    it's harder to reason and less intuitive, f(n) = ∞Ω(g(n)) no longer gives an lower bound of f(n)
c.  =>: f(n) = Θ(g(n))  => c1g(n) <= f(n) <= c2g(n)
                        => f(n) = Ω(g(n)) and f(n) <= c2g(n)
        let f(n) = -n, g(n) = -n, take c1 = c2 = 1, f(n) = Θ(g(n))
        but |f(n)| = n > cg(n) for all positive constant c, f(n) != O'(g(n))
    <=: |f(n)| <= cg(n) => f(n) <= cg(n), so f(n) = O'(g(n)) implies f(n) = O(g(n))
        therefore f(n) = O'(g(n)) && f(n) = Ω(g(n)) => f(n) = Θ(g(n))
d.  ~Ωg(n) = {f(n): there exist positive constants c, k and n0 that
                    0 <= cg(n)lg^k(n) <= f(n) for all n >= n0 }
    ~Θg(n) = {f(n): there exist positive constants c1, c2, k1, k2 and n0 that
                    c1g(n)lg^k1(n) <= f(n) <= c2g(n)lg^k2(n) for all n >= n0 }
    =>: f(n) = ~Θ(g(n)) => c1g(n)lg^k1(n) <= f(n) <= c2g(n)lg^k2(n) for all n >= n0
        instantly f(n) = ~O(g(n)) and f(n) = ~Ω(g(n))
    <=: similar, take n0 be the maximum of the two

3-6
a.  n - c
b.  lg*(n)
c.  lg(n)
d.  lg(n) - 1
e.  lglg(n)
f.  ∞
g.  lglg(n)
h.  iter 0: n
    iter 1: n / lgn = (iter 0) / lgn
    iter 2: (n / lgn) / lg(n / lgn) = (iter 1) / (lgn - lglgn)
    iter 3: ((n / lgn) / (lgn - lglgn)) / lg((n / lgn) / (lgn - lglgn))
            = (iter 2) / ((lgn - lglgn) - lg(lgn - lglgn))
    the divisor is never greater than lgn
    therefore lower bound is Ω(log(lgn, n)) = Ω(lgn / lglgn)
    upper bound unknown
