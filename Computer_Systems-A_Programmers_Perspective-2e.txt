//  whenever appropriate, all "Write a program" practices will be done in Rust instead of C
Chapter 2
2.1
A.  1110011010011111111000
B.  c97b
C.  11010101111001001100
D.  26e7b5

2.2
19  524288  0x80000
14  16384   0x4000
16  65536   0x10000
17  131072  0x20000
5   32      0x20
7   128     0x80

2.3
167 10100111    0xa7
62  00111110    0x3e
188 10111100    0xbc
55  00110111    0x37
136 10001000    0x88
82  01010010    0x52
172 10101100    0xac
231 11100111    0xe7

2.4
A. 0x503c + 0x8 = 0x5044
B. 0x503c − 0x40 = 0x4ffc 
C. 0x503c + 64 = 0x503c + 0x40 = 0x507c
D. 0x50ea − 0x503c = 0xae

2.5
A.  21
    87
B.  21 43
    87 65
C.  21 43 65
    87 65 43

2.6
A.  00000000001101011001000101000001
    01001010010101100100010100000100
B.  00000000001101011001000101000001
      01001010010101100100010100000100
    21 bits match
C.  the first non-zero bit in the representation of the integer number
    the first 9 bits in the representation of the float number
    the last 2 bits in the representation of the float number

2.7
61 62 63 64 65 66
will not include the terminating character

2.8
a = 01101001
b = 01010101
~a = 10010110
~b = 10101010
a & b = 01000001
a | b = 01111101
a ^ b = 00111100

2.9
A.  ~Black = White
    ~Blue = Yellow
    ~Green = Magenta
    ~Cyan = Red
    and vice versa
B.  Blue | Green = Cyan 
    Yellow  & Cyan = Green 
    Red ^ Magenta = Blue

2.10
a   a^b
b   a^b
b   a

2.11
A.  both equals k
B.  the function in the final iteration swaps the k+1-th elements with itself
    the two references applied to the function inplace_swap refers to the same address
    in step 1 of inplace_swap, *y = *x ^ *y = *x ^ *x = 0, further computations always result in 0
C.  change line 4 to
        first < last;

2.12
A.  x & 0xff
B.  x ^ ~0xff
C.  x | 0xff

2.13
x   y   bis(x, y)
0   0   0
0   1   1
1   0   1
1   1   1
therefore x | y == bis(x, y)
x   y   bic(x, y)
0   0   0
0   1   0
1   0   1
1   1   0
therefore x ^ y = bic(x, y) | bic(y, x) = bis(bic(x, y), bic(y, x))

2.14
x & y == 0x20
x | y == 0x7f
~x | ~y == 0xdf
x & !y == 0x01
x && y == 0x01
x || y == 0x01
!x || !y == 0x00
x && ~y == 0x01

2.15
!(x ^ y)

2.16
0xc3    11000011    11000       0x18    110000  0x30    11110000    0xf0
0x75    1110101     10101000    0xa8    11101   0x1d    11101       0x1d
0x87    10000111    111000      0x38    100001  0x21    11100001    0xe1 
0x66    1100110     110000      0x30    11001   0x19    11001       0x19

2.17
0x0 0000    0   0
0x5 0101    5   5
0x8 1000    8   -8
0xd 1101    13  -3
0xf 1111    15  -1

2.18
A.  440
B.  20
C.  -424
D.  -396
E.  68
F.  -312
G.  16
H.  12
I.  -276
J.  32

2.19
-8  8
-3  13
-2  14
-1  15
0   0
5   5

2.20
T2U4(x) =   x if x >= 0
            x + 16 if x < 0

2.21
unsigned    1
signed      1
unsigned    0
signed      1
unsigned    1

2.22
A.  1011 = -2^3 + 2^1 + 2^0 = -5
B.  11011 = -2^4 + 2^3 + 2^1 + 2^0 = -5
C.  111011 = -2^5 + 2^4 + 2^3 + 2^1 + 2^0 = -5

2.23
A.  118     118
    33      33
    201     -55
    135     -121
B.  returns the least significant 8 bits of a word, padded by either 0 or 1, interpreted as sa signed integer

2.24
0   0
2   2
1   1
3   3
7   -1

2.25
length - 1, when length == 0, will underflow and wrap to 2^w - 1, given w-bit word size
change loop condition from i <= length - 1 to i < length will fix the error

2.26
A.  whenever strlen(s) < strlen(t), the function will return 1
B.  when strlen(s) < strlen(t), the result of strlen(s) - strlen(t) will underflow and wrap to a positive number
C.  return strlen(s) > strlen(t);

2.27
fn uadd_ok(x: u32, y: u32) -> bool {
  let s = x.wrapping_add(y);
  s >= x
}

2.28
0   0   0   0
5   5   11  b
8   8   8   8
d   13  3   3
f   15  1   1

2.29
10100   10001
-12     -15     -27     5       1
11000   11000
-8      -8      -16     -16     2
10111   01000
-9      8       -1      -1      2
00010   00101
2       5       7       7       3
01100   00100
12      4       16      -16     4

2.30
fn tadd_ok(x: i32, y: i32) -> bool {
  let s = x.wrapping_add(y);
  !((x >= 0 && y >= 0 && s < 0) || (x < 0 && y < 0 && s >= 0))
}

2.31
cause I was being harsh against others
and the implementation is based on the exact meaning of signed substraction
when sum = x + y overflowed, sum - x and sum - y may also overflow, the result is UB in the specification of C

2.32
when y == -(2^w), w the size of the word, y doesn't have a positive counterpart representable as a w-bit word
when y == -(2^w), -y overflows, the result is UB and tadd_ok(x, -y) may return anything depend on -y

2.33
0   0   0   0
5   5   -5  b
8   -8  -8  8
d   -3  3   3
f   -1  1   1
they have the same bit representation

2.34
100     101
4       5       20[100100]      4[100]
-4      -3      12[001100]      -4[100]
010     111
2       7       14[001110]      6[110]
2       -1      -2[111110]      -2[110]
110     110
6       6       36[100100]      4[100]
-2      -2      4[000100]       -4[100]

2.35
when x == 0, xy will always be 0, no matter truncated to how many bits, thereby no overflow
tmult_ok(0, y) should return 1 for all y
when x == 0, !x == 1, (!x || p/x == y) == 1, the answer is correct
when x != 0, xy didn't overflow, xy == p
reversely, when xy == p, xy didn't overflow
when xy overflowed,
    p   = U2Tw(xy mod 2^w)
        = [xy mod 2^w] + k2^w, k = -1 or 0
    xy  = [xy mod 2^w] + r2^w
        = p + (r - k)2^w
define t = r - k then xy = p + t2^w
the specification of C language requires (p / x) * x + p % x == p for integers
http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf
hence for q = p/x, p == q * x + p % x, where p % x is the reminder of p divides x, therefore r = p % x and |r| < |x|
when t == 0, r == 0, xy didn't oveflow, xy == p, q == p / x == y
when t != 0, xy overflowed, xy == p + t2^w, p == xy - t2^w
if q == p / x == y, p == xy + r, |r| < |x|, which implies |t2^w| < |x|, contradiction
therefore when t != 0, q != y, and q == y <=> (t == 0 && r == 0)

2.36
fn tmult_ok(x: i32, y: i32) -> bool {
  // product of two w-bit signed integer can be represented by 2w bits
  // so product of two i32 will fit in an i64, the calculation can never overflow
  let p = (x as i64) * (y as i64);
  let min = i32::min_value() as i64;
  let max = i32::max_value() as i64;
  p >= min && p <= max
}

2.37
A.  not so much. the library function memcpy expects input of type size_t, and will truncate asize to that size
    by carefully choosing ele_cnt and ele_size, the trancated asize can still be small
B.  explicitly check for overflow using function tmult_ok
    immediately return NULL when the multiplication will overflow

2.38
a << k == a * 2^k
a << k + a == a * 2^k + a == a * (2^k + 1)
for k ∈ {0 .. 3}, LEA can calculate pa for p ∈ {1, 2 4, 8} ∪ {2, 3, 5, 9} = {1, 2, 3, 4, 5, 8, 9}

2.39
(x << n) << 1 - (x << m)

2.40
6[110]      (x << 2) + (x << 1)
31[11111]   (x << 6) - x
-6, 2 - 8   (x << 1) - (x << 3)
55[110111]  (x << 7) - (x << 3) - x

2.41
when (n - m) is greater than 2 and subtraction has similar cost to addition, use form B
otherwise (n - m <= 2 or substraction is significantly more costy than addition), use form A

2.42
fn div16(x: i32) -> i32 {
  let bits = x >> 31;
  let bias = 16 - 1;
  (x + (bias & bits)) >> 4
}

2.43
M == 2^5 - 1 == 31
N == 2^3 == 8

2.44
A.  for x = -2^31, x < 0, x - 1 == 2^31 - 1 > 0
B.  x & 7 truncates x to 3 bits
    when x & 7 intepreted as a 32-bit signed integer equals to 7, the least significant 3 bits of x is 111
    thereby x << 29 will have most significant bit equals to 1, is a negative number when interpreted as a signed int
C.  for x = 1234567891, x * x == -1521747479 < 0
D.  if x >= 0, -x is representable in 32 bits and will not overflow, -x <= 0
E.  for x = -2^31, -x is defined as -2^31, x < 0 && -x < 0
F.  this is how signed integer addition is defined according to 2.13
    x + y and ux + uy will have the same bit representation
    also == will cast the signed x + y to unsigned integer
G.  x * (~y + 1) == x * -y == - (x * y)
    x * y and ux * uy have the same bit representation
    for some signed z and its unsigned interpretation uz
    if z == -2^(w-1),
        -z          == -2^(w-1)
        T2Uw(-z)    == 2^w + -2^(w-1) == 2^(w-1)
        T2Uw(z)     == 2^(w-1)
        -T2Uw(z)    == 2^w - 2^(w-1) == 2^(w-1)
    if -2^(w-1) < z < 0,
        -z          == -(z) (integer)
        T2Uw(-z)    == -(z)
        T2Uw(z)     == 2^w + z
        -T2Uw(z)    == 2^w - (2^w + z) == -(z)
    if z == 0,
        -z          == 0
        T2Uw(-z)    == 0
        T2Uw(z)     == 0
        -T2Uw(z)    == 0
    if z > 0,
        -z          == -(z)
        T2Uw(-z)    == 2^w - z
        T2Uw(z)     == z 
        -T2Uw(z)    == 2^w - z
    therefore -z and -uz has the same bit representation, and 
        -(x * y) + ux * uy == 0
        x * (~y + 1) + ux * uy == 0
        x * ~y + x + ux * uy == 0
    by definition, x * ~y + ux * uy is the addictive inverse of ux
    again -ux and -x has the same bit representation, so
        x * ~y + ux * uy == -x

2.45
3/4     0.11    0.75
25/16   1.1001  1.5625
43/16   10.1011 2.6875
9/8     1.001   1.125
47/8    101.111 5.875
51/16   11.0011 3.1875

2.46
x = 0.00011001100110011001100
A.  0.1 - x == 0.0000000000000000000000011[0011]...
B.  0.1 - x ≒ 0.0000000953674316
C.  t_diff == 100 * 3600 * (0.1 - x) ≒ 0.034332275392634 second
D.  2000 * t_diff ≒ 68.664550785 meters

2.47
./CSAPP/float

2.48
the bit representation of 3510593 is 1101011001000101000001, 22 bit long
drop the leading 1, get 101011001000101000001
pad it to 23 bits with 0, get 10101100100010100000100
the fraction should be shifted to 21 positions to the right of binary point
21 + 127 = 149, has binary representation 10010101
combined with a sign bit 0, 01001010110101100100010100000100 is the final result

2.49
A.  for a floating-format with n-bit fraction, let f = [10^n1], then f * 2^k cannot be represented exactly for any k
    let sd be the smallest positive denormalized number and sn the smallest positive normalized number
    the smallest positive number np that cannot be represented exactly is
        np  == sd/2 + sn
            == 2^(-n - 2^(k-1) + 1) + 2^(-2^(k-1) + 2)
B.  for n = 23, k = 8,
        np == 2^-149 + 2^-125

2.50
A.  10.010(2 + 1/4)     10.0(2)
B.  10.011(2 + 3/8)     10.1(2 + 1/2)
C.  10.110(2 + 3/4)     11.0(3)
D.  11.001(3 + 1/8)     11.0(3)

2.51
A.  0.1 == 0.00011001100110011001100[1100]...
    x' == 0.00011001100110011001101
B.  x' - 0.1 == 0.10000002384185791
C.  t_diff == 100 * 3600 * (x' - 0.1) == 0.008583068845657849 seconds
D.  2000 * t_diff == 17.166137691315697 meters

2.52
101 1110    30      1001 111    30
010 1001    25/32   0110 100    12/16
110 1111    31/2    1011 000    16
000 0001    1/32    0001 000    1/32

2.53
#define POS_INFINITY (1e308 * 2)
#define NEG_INFINITY (1e308 * -2)
#define NEG_ZERO (1 / NEG_INFINITY)

2.54
A.  true, int -> double will be exact, no rounding performed on the way back
B.  x = 0x80000001
C.  x = 0.1234567890123
D.  true, float -> double will be exact, no rounding performed on the way back
E.  true, negation of a floating number only changes the sign bit
F.  true, integer literals will be implicitly converted to float
G.  guarenteed by IEEE format
H.  f = 1e10, d = 1e-10

2.55
most of them are little-endian

2.56
./CSAPP/float

2.57
a properly coded polynomial function show_bytes<T> in Rust can handle all types which implements trait Sized
i.e. show_short, show_long, show_double all unnecessary

2.58
./CSAPP/float

2.59
(0x00000001 & x) | (0xfffffffe & y)

2.60
./CSAPP/float

2.61
A.  !!x
B.  !(~x)
C.  !!(x & 0xff)
D.  !!(~x & (INT_MIN >> 1))

2.62
./CSAPP/float

2.63
./CSAPP/float

2.64
./CSAPP/float

2.65
thanks https://stackoverflow.com/questions/27467595/
./CSAPP/float
given a w-bit word x = [b1b2 .. bw], the parity function is defined as
    f(x) = b1 xor b2 xor .. xor bw
by commutativity and associativity of xor, every pair of 1s will cancel each other
if there are odd 1s in the bit representation of x, f(x) == 1, otherwise f(x) == 0
also for a 2w-bit word x = [b1..b2w],
    f(x)    = b1 xor .. xor b2w
            = (b1 xor bw+1) xor (b2 xor bw+2) .. xor (bw xor b2w)
            = f(x'), where x' = x[1..w] xor x[w+1..2w]
hence given a w-bit x = x1||x2, |x1| = |x2|, the parity of x can be computed as the parity of x1 xor x2
doing so iteratively and odd_ones can be computed with log2(w) xors and log2(w) shifts

2.66
./CSAPP/float
let x = [0 .. 0bk .. bw], where bk is the most significant non-zero bit
by computing x |= x >> 1, both bk and bk+1 now is guarenteed to be 1
such a computation will never change bits more significant than bk, as right shift is logical for unsigned integer
then x |= x >> 2, as bk and bk+1 are 1, bk+2 and bk+3 will be 1 after this step
after t steps, 2^t bits after bk will be 1
so 5 steps is sufficient to transfer any 32-bit x to [0 .. 01 .. 1], where k-th bit is still the first non-zero bit
let y be x after 5 iterations
then (y >> 1) + 1 will give the right answer for all x except 0
so ((y >> 1) + 1) & x is the answer

2.67
A.  shift count in C cannot be equal to or greater than the size of the integer
    for a 32-bit int, 1 << 32 will be UB
B.  change line 4 and 6 to
        int set_msb = 1 << 31;
        int beyond_msb = 1 << 31 << 1;
C.  change line 4 and 6 to
        int set_msb = 1 << 15 << 15 << 1;
        int beyond_msb = 1 << 15 << 15 << 2;

2.68
./CSAPP/float

2.69
./CSAPP/float

2.70
./CSAPP/float

2.71
A.  word is of type unsigned, and type casting in C between unsigned and int preserves bit representation, not value
    (word >> (bytenum << 3)) will always be extended with 0, the result will always be interpreted as positive
B.  return 0xff - ((word << ((3 - bytenum) << 3)) >> 24)

2.72
A.  the one of the operator of (maxbytes - sizeof(val)) is of type size_t, which is unsigned
    so the result will be casted to unsigned, and an unsigned number is always greater or equal to 0
B.  if (maxbytes >= 0 && maxbytes >= sizeof(val))

2.73
thanks https://zhangjunphy.github.io/csapp/chap2.html
./CSAPP/float

2.74
check if y == INT_MIN, then run tadd_ok(x, -y)

2.75
when x, y <= INT_MAX, the result of unsigned_high_prod(x, y) should be equal to signed_high_prod(x, y)
when both x, y > INT_MAX, denote tx = U2Tw(x) and ty = U2Tw(y)
    tx = x - 2^w, ty = y - 2^w
    tx * ty = 2^2w + xy - x2^w - y2^w
    xy = tx * ty + x2^w + y2^w - 2^2w = tx * ty + x2^w + y2^w mod 2^2w
both x2^w and y2^w have zeros in lower w bits
thus unsigned_high_prod(x, y) = signed_high_prod(x, y) + x + y
when x <= INT_MAX and y > INT_MAX, denote tx = U2Tw(x) and ty = U2Tw(y)
    tx = x, ty = y - 2^w
    tx * ty = xy - x2^w
    xy = tx * ty + x2^w
and unsigned_high_prod(x, y) = signed_high_prod(x, y) + x
when x > INT_MAX and y <= INT_MAX, symmetrically
unsigned_high_prod(x, y) = signed_high_prod(x, y) + y
./CSAPP/float

2.76
A.  x + (x << 4)
B.  x - (x << 3)
C.  (x << 6) - (x << 2)
D.  (x << 4) - (x << 7)

2.77
./CSAPP/float 

2.78
./CSAPP/float

2.79
thanks https://dreamanddead.gitbooks.io/csapp-3e-solutions/chapter2/2.80.html
./CSAPP/float

2.80
A.  -1 << k
B.  ~(-1 << k << j) & (-1 << j)

2.81
A.  when x == INT_MIN, y >= 0, x < y == 1 and -x > -y == 0
B.  (x + y) << 4 == 16 * (x + y) == 16 * x + 16 * y
    (x + y) << 4 + y - x == 17 * y + 15 * x
C.  ~(x + y) + 1 == -(x + y), ~(x + y) == -(x + y) - 1
    ~x + 1 == -x, ~y == -y - 1, ~x + ~y + 1 = -x + -y - 1
    -x + x + -y + y == 0, x + y + (-x + -y) == 0, (-x + -y) == -(x + y), negation distributes over addition
D.  substraction, addition and negation are all isomorphic in signed and unsigned arithmetics
    the bit representation is always the same after signed or unsigned computation
    -(y - x) == -(uy - ux)
    ux - uy + (uy - ux) == 0, -(uy - ux) == ux - uy
    therefore ux - uy == -(unsigned)(y - x)
E.  (x << 2) >> 2 erases the least significant 2 bits of x
    in two's complement representation, these two bits always have positive weights
    therefore (x << 2) >> 2 <= x holds

2.82
A.  0.yyyyy... == Y/2^k + Y/2^2k + ... == Y(1/2^k + 1/2^2k + ...) == Y(2^k/(2^k - 1) - 1) == Y/(2^k - 1)
B.  a.  5/(2^3 - 1) == 5/7
    b.  6/(2^4 - 1) == 6/15 == 2/5
    c.  35/(2^6 - 1) == 35/63 == 5/9

2.83
return sx == sy ? (sx ? ux << 1 >= uy << 1 : ux << 1 <= uy << 1) : (ux << 1 == 0 && uy << 1 == 0) || sx > sy

2.84
A.  E = 2, M = 7/4, f = 3/4, V = 7
    x = 0||e||m
    where e is the k-bit representation of 2^(k-1) + 1
    m is the n-bit representation of 3/4, binary point placed before the first bit
B.  for E > n + 1, every number representable will be even
    E = n, M = 2 - 1/2^n, f = 1 - 1/2^n, V = 2^(n+1) - 1
    x = 0||e||1^n
    where e is the k-bit representation of n
C.  the smallest positive normalized value = 2^(2 - 2^(k-1))
    its reciprocal is 2^(2^(k-1) - 2)
    E = 2^(k-1) - 2, M = 1, f = 0, V = 2^(2^(k-1) - 2)
    x = 0||e||0^n
    where e is the n-bit representation of 2^(k-1) - 2 + 2^(k-1) - 1 = 2^k - 3

2.85
2^-16445            about 1e-4950
2^-16382            about 1e-4931
2^16384 - 2^16320   about 1e4932

2.86
0x8000      0       -63     -0
0x2001      257/256 1       257 * 2^-7
0x4800      0       9       512
0x00ff      255/256 -62     255 * 2^-70
0x3bb0      432/256 -4      27 * 2^-8

2.87
routine

2.88
A.  casting from int -> double is accurate, int -> float is equivalent to int -> double -> float
B.  dx - dy will not underflow
    when x - y underflowed (x - y < INT_MIN), (double)(x - y) will be positive, while dx - dy is negative
C.  floating point arithmetics is not associative
    when dx = 1e-10, dy = 1e10, dz = -1e10
    (dx + dy) + dz == 0, dx + (dy + dz) == 1e-10
D.  again floating point arithmetics is not associative
    when dx = 1e300, dy = 1e300, dz = 1e-300
    (dx * dy) * dz == inf, dx * (dy * dz) == 1e300
E.  when dx = 0, dz = 1
    dx / dx == NaN, dz / dz == 1

2.89
x < -149
    exp = 0
    frac = 0
x < -126
    exp = 0
    frac = 1 << (x + 149)
x < 128
    exp = x + 127
    frac = 0
else 
    exp = 0xff
    frac = 0

2.90
A.  11.0010010000111111011011
B.  22/7 = 3 + 1/7, 1/7 = 0.[001]..., 22/7 = 11.[001]...
C.  at the 9th binary position

2.91 - 2.95
./CSAPP/float

Chapter 3
3.1
%eax            0x100
0x104           0xAB
$0x108          0x108
(%eax)          0xFF
4(%eax)         0xAB
9(%eax,%edx)    0x11
260(%ecx,%edx)  0x13
0xFC(,%ecx,4)   0xFF
(%eax,%edx,4)   0x11

3.2
movl
movw
movb
movb
pushl
movw
popl

3.3
1.  addresses have to be 32-bit long, while %bl is 8-bit
2.  movl moves 32-bit double words, while %ax is 16-bit
3.  mov instructions cannot move memory address to another memory address directly
4.  no register called %sh 
5.  the destination of movl cannot be an immediate value
6.  movl moves 32-bit double words, while %dx is 16-bit
7.  movb moves 8-bit bytes, while %si is 16-bit 

3.4
movsbl %al, (%edx)
movzbl %al, (%edx)
movsbl %al, (%edx)
movb %al, (%edx)
movb %al, (%edx)
movl %eax, (%edx)

3.5

fn decode1(xp: &mut i32, yp: &mut i32, zp: &mut i32) {
    let x = *xp;
    let y = *yp;
    let z = *zp;
    *xp = z;
    *yp = x;
    *zp = y;
}

3.6
x + 6
x + y
x + 4y
9x + 7
4y + 10
x + 2y + 9

3.7
0x100       0x100
0x104       0x99
0x10C       0x110
0x108       0x14
%ecx        0x0
%eax        0xFC

3.8
movl 8(%ebp), %eax 
sall $2, %eax
movl 12(%ebp), %ecx
sarl %cl, %eax

3.9
int t1 = y;
int t2 = t1 ^ x;
int t3 = t2 >> 3;
int t4 = -t3 - z;

3.10
A.  it sets %edx to 0x00000000, as for any number x, x ^ x == 0
B.  movl $0, %edx
C.  xorl %edx, %edx is two bytes (31 d2) in machine code
    movl $0, %edx is five bytes (ba 00 00 00 00), the last four bytes encode a 32-bit immediate value zero

3.11
movl 8(%edp), %eax
xorl %edx, %edx
divl 12(%edp)
movl %eax, 4(%esp)
movl %edx, (%esp)

3.12
A.  num_t is long long unsigned, or u64
    it has size twice a dword, and computing x * y compiled to mull, the unsigned full multiplication instructure
B.  movl 20(%edp), %ecx, on a little-endian machine, moves the higher 8 bytes of y to %ecx
    y == 20(%edp) * 2^32 + 16(%edp) == %ecx * 2^32 + 16(%edp)
    x * y == (x * %ecx mod 2^32) * 2^32 + x * 16(%edp) mod 2^64
    imull %eax, %ecx computes x * %ecx mod 2^32 and puts it at %ecx
    mull 16(%edp) computes x * 16(%edp) and puts the result at %edx:%eax
    leal (%ecx, %edx) %edx computes %ecx + %edx, the higher 32 bits of x * y mod 2^64, puts the result at %edx
    therefore %edx:%eax is the result of x * y mod 2^64 at the end

3.13
A.  int, <
B.  short, >=
C.  unsigned char, >
D.  int or unsigned, !=

3.14
A.  int or unsigned, !=
B.  short or unsigned short, ==
C.  char, >
D.  unsigned short, >

3.15
A.  0x8048296
B.  0x8048341
C.  0x804837f
D.  0x80482a5
E.  absolute address

3.16
A.  void cond(int a, int *p) {
        if (p == 0)
            goto done;
        if (a <= 0)
            goto done;
        *p += a;
    done:
    }
B.  the && operator in C is short-circuiting
    when p == 0, it will not, and generally should not evaluate a > 0
    therefore if the computer find that p == 0, it should immediately skip to the end of the function

3.17
A.  int gotodiff(int x, int y) {
        int result;
        if (x < y)
            goto x_l_y;
        result = y - x;
        goto done;
    x_l_y:
        result = x - y;
    done:
        return result;
    }
B.  if the if clause without the corresponding else clause is compiled in the same way
    this rule performs one more unnecessary jump

3.18
int test(int x, int y) {
    int val = x - y;
    if (x < -3) {
        if (x > y) {
            val = x * y;
        } else {
            val = x + y;
        }
    } else if (x <= 2)
        val = x ^ y;
    return val;
}


3.19
A.  12
B.  20

3.20
A.  %eax    x       x 
    %ecx    y       y
    %edx    n       n
B.  test-expr: n > 0 && y < n
    body-statemenet: x += n; y *= n; n--;
C.  movl    8(%edp), %eax       Get x
    movl    12(%edp), %ecx      Get y 
    movl    16(%edp), %edx      Get n
  .L2:                        loop:
    addl    %edx, %eax          Compute x += n 
    imull   %edx, %ecx          Compute y *= n 
    subl    $1, %edx            Decrement n
    testl   %edx, %edx          Compare n:0
    jle     .L5                 if <=, goto done
    cmpl    %edx, %ecx          Compare y:n
    jl      .L2                 if <, goto loop
  .L5:                        done:

3.21
A.  %edx == a + b
B.  %ecx    a       a
    %ebx    b       b
    %eax    result  1
    %edx    (a+b)   (a+b)
C.  -
D.  int loop_while(int a, int b) {
        int result = 1;
        int s;
        if (a >= b)
            goto done;
        s = a + b;
        result = 1;
    loop:
        result *= s;
        a += 1;
        s += 1;
        if (b > a)
            goto loop;
    done:
    }

3.22
A.  int fun_a(unsigned x) {
        int val = 0;
        while (x != 0) {
            val ^= x;
            x = x >> 1;
        }
        return val & 1;
    }
B.  after the while loop, val is a 32-bit word
    the kth most significant bit of val is the parity of the k most significant bits of x
    val & 1 gives the least significant bit of val, which is the parity of all 32 bits in x

3.23
A.  int fun_b(unsigned x) {
        int val = 0;
        int i;
        for (i = 0; i != 32; i++) {
            val = (x & 1) | (val + val);
            x = x >> 1;
        }
        return val;
    }
B.  the result val have reversed bit representation of x

3.24
A.  int sum = 0;
    int i = 0;
    while (i < 10) {
        if (1 & 1)
            continue;
        sum += i;
        i++;
    }
    continue in a for loop will still execute the update-expr
    however in a while loop continue will pass control to the condition-expr, skips update-expr along with loop body
B.  int sum = 0;
    int i = 0;
    while (i < 10) {
        if (1 & 1)
            goto update;
        sum += i;
    update:
        i++;
    }

3.25
A.  30 cycles 
B.  46 cycles

3.26
A.  /
B.  when x < 0, the result is (x + 3) >> 2
    hence the division is always rounded towards zero, instead of towards -∞

3.27
int test(int x, int y) {
    int val = x + y;
    if (y > 0) {
        if (x < y) {
            val = x - y;
        } else {
            val = y - x;
        }
    } else if (y >= -2) {
        val = 4 * x;
    }
    return val;
}

3.28
A.  -2  -> .L3
    0   -> .L4 
    1   -> .L5 
    2,3 -> .L6 
    4   -> .L7
    def -> .L2
B.  .L6, has labels 2 and 3

3.29
int switcher(int a, int b, int c) {
    int answer;
    switch (a) {
    case 5:
        c = b ^ 0xf;
    case 0:
        answer = c + 112;
        break;
    case 2:
    case 7:
        answer = (b + c) >> 2;
        break;
    case 4:
        answer = 4;
        break;
    default:
        answer = b;
    } 
    return answer;
}

3.30
A.  the absolute address of the instruction following the label next
B.  there's nowhere to go back: the return address already been poped to %eax
C.  to get an address on fly, so it can later be used in indirect calls/jumps

3.31
%edi, %esi and %ebx are callee-save registers
procedure been called has to restore them at the end

3.32
int fun(int c, int d, int *p, int x);

3.33
A.  0x80003c
B.  0x800014
C.  x at %edp - 4 == 0x800038
    y at %edp - 8 == 0x800034
D.  0x80003c    8x800060    %edp
    0x800038    0x53        x
    0x800034    0x46        y
    0x800030
    |
    0x800020
    0x80001c    0x800038    &x
    0x800018    0x800034    &y
    0x800014    0x300070    %esp and .LCO
E.  0x800030 - 0x800020

3.34
A.  x
B.  int rfun(unsigned x) {
        if (x == 0)
            return 0;
        unsigned nx = x >> 1;
        int rv = rfun(nx);
        return (x & 1) + rv;
    }
C. the number of 1s in the bit representation of x

3.35
short: 2 bytes
*short: 4 bytes
**short: 4bytes
long double: 10 bytes in IA32, 8 bytes otherwise
*long double: 4 bytes

3.36
S+1         *short      xE + 2      leal 2(%edx), %eax
S[3]        short       M[xE + 6]   movw 6(%edx), %ax
&S[i]       *short      xE + 2i     leal (%edx, %ecx, 2), %eax
S[4*i+1]    short       M[xE+2i+2]  movw 2(%edx, %ecx, 2), %ax
S+i-5       *short      xE+2i-10    leal -10(%edx, %ecx, 2), %eax

3.37
%eax == 7i + j before line 8, N == 7
%edx == 5j + i before line 9, M == 5

3.38
void fix_set_diag_opt(fix_matrix A, int val) {
    int i;
    for (i = 0; i != (N+1) * N; i += N+1) {
        *(A+i) = val;
    }
}

3.39
A.  p:      0
    s.x:    4
    s.y:    8
    next:   12
B.  16
C.  void sp_init(struct prob *sp) {
        sp->s.x = sp->s.y;
        sp->p = s.x;
        sp->next = sp;
    }

3.40
up->t1.v    short
    movw (%eax), %ax 
    movw %ax, %dx
&up->t1.d   *short
    leal 2(%eax), %edx
up->t2.a    int[2]
    movl (%eax), %edx
up->t2.a[up->t1.s]  int
    movl 4(%eax), %edx
    movl (%eax), %eax
    movl (%eax,%edx,4), %edx
*up->t2.p   char
    movl 8(%eax), %eax
    movb (%eax), %dl

3.41
A.  i: 0, c: 4, j: 8, d: 12
    size: 16, alignment: 4/8
B.  i: 0, c: 4, d: 5, j: 8
    size: 12, alignment: 4/4
C.  w: 0, c: 6
    size: 10, alignment: 2/2
D.  w: 0, c: 8
    size: 24, alignment: 4/4
E.  a: 0, p: 32
    size: 36, alignment: 4/4

3.42
A.  a   b   c   d   e   f   g   h
    0   4   8   16  20  24  32  40
B.  48
C.  struct {
        double      c;
        long long   g;
        float       e;
        void       *h;
        char       *a;
        char        d;
        char        f;
    }
    c   g   e   h   a   d   f
    0   8   16  20  24  28  29
    size: 32

3.43
A.  0x4     08 04 86 43 return address
    %ebp    bf ff fc 94 stored %ebp
    -0x4    00 00 00 02 stored %edi
    -0x8    00 00 00 03 stored %esi
    -0xc    00 00 00 01 stored %ebx
    ...
    -0x28               <- %esp
B.  0x4     00 04 86 43 return address, first byte overwritten by the terminate character
    %ebp    30 31 32 33 "0123", %ebp overwritten
    -0x4    36 37 38 39 "6789", %edi overwritten
    -0x8    32 33 34 35 "2345", %esi overwritten
    -0xc    38 39 30 31 "8901", %ebx overwritten
    -0x10   34 35 36 37 "4567"
    -0x14   30 31 32 33 "0123"
    ...
    -0x28   -0x14       <- %esp
C.  0x00048643
D.  %ebp, %edi, %esi and %ebx
E.  thanks CSAPP-2e
    result should be large enough to contain the terminate character, strlen(buf) + 1
    malloc may fail and return NULL pointer, this case has to be handled

3.44
A.  131072
B.  1024

3.45
A.  without protector
        v:      %edp - 8
        buf:    %edp - 20
    with protector
        canary: %edp - 8
        v:      %edp - 24
        buf:    %edp - 20
B.  in the original order, the canary can only detect the overflow if the overflow overwrites more than 4 bytes
    by putting canary value right below buf on the stack, the canary can detect buffer overflow ASAP

3.46
A.  2034
B.  2045
C.  2028 
    2039

3.47
int             long            movslq  %edi    %rax
char            long            movsbq  %dil    %rax
unsigned int    unsigned long   movq    %edi    %rax
unsigned char   unsigned long   movzbq  %dil    %rax
long            int             movl    %edi    %eax
unsigned long   unsigned        movl    %edi    %eax

3.48
long arithprob(int a, char b, long c, int d);

3.49
A.  long fun_c(unsigned long x) {
        long val = 0;
        int i;
        for (i = 0; i != 8; x >>= 1, i++) {
            val += 0x101010101010101 & x;
            // 0b0000000100000001000000010000000100000001000000010000000100000001 in binary
        }
        val += val >> 32;
        val += val >> 16;
        val += val >> 8;
        return val & 0xff;
    }
B.  view val and x as 8 chars
    after the for loop, every char in val records the number of 1s in the corresponding chars in x
    after val += val >> 32, ith char in the lower 4 chars of val encodes the number of 1s in ith and (i+4)th char in x
    similarly, after val += val >> 16 and val += val >> 8
    the lowest char in val encodes the number of 1s in the whole x
    therefore val & 0xff returns the number of 1s in x
    there are at most 64 1s in x, and a char can encode numbers <= 127, the calculation will not overflow

3.50
the first argument must be x, of 4-byte size, stored in %edi
the second argument must be q, of 8-byte size, stored in %rsi
as %edi is sign-extended to %rdi before adding to (%rsi), q has type (long *)
the third argument must be t, of 8-byte size, stored in %rdx
from addl %edi, (%rdx), %rdx points to a 4-byte integer, signed or unsigned
void incrprob(int x, long *q, int *t);
void incrprob(int x, long *q, unsigned *t);
void incrprob(unsigned x, long *q, int *t);
void incrprob(unsigned x, long *q, unsigned *t);

3.51
A.  -8
    -16 7
    -24 5
    -32 3
    -40 2
B.  -
C.  the array is allocated on %rsp - 7 to %rsp - 40, without actually substracing %rsp

3.52
A.  x 
B.  store and restore the callee-save register %rbx
C.  -
D.  it uses pushq to automatically increment %rsp and store the value at the same time
    other programs manually substracts the number of bytes it allocates from %rsp

3.53
A.  i   c   j   d
    0   4   8   16
    size: 24, alignment: 8
B.  i   c   d   j 
    0   8   9   12
    size: 16, alignment: 8
C.  w   c
    0   6
    size: 10, alignment: 2
D.  w   c
    0   8
    size: 24, alignment: 8
E.  a   p 
    0   48
    size: 56, alignment: 8

3.54
./CSAPP/asm

3.55
assume y = yh * 2^32 + yl
yh is the integer represented by the higher 32 bits of y
yl is the positive integer represented by the lower 32 bits of y
then x * y == x * yh * 2^32 + x * yl
as x * yh * 2^32 will have least significant 32 bits equal to 0
the lower 32 bits of x * yl is the lower 32 bits of x * y
when x >= 0, (x * yl) >> 32 + x * yh is the higher 32 bits of x * y
when x < 0, T2U(x) = 2^32 + x, T2U(x) * yl == (2^32 + x) * yl == 2^32 * yl + x * yl
the higher 32 bits of x * y can be computed as T2U(x) * yl >> 32 + x * yh - yl
assuming little-endian machine
movl    16(%ebp), %esi          retrieve lower 4 bytes of y, save to %esi
movl    12(%ebp), %eax          retrieve x, save to %eax 
movl    %eax, %edx              copy x to %edx
sarl    $31, %edx               if x < 0, %edx == -1; otherwise %edx == 0
movl    20(%ebp), %ecx          retrieve higher 4 bytes of y, save to %ecx
imull   %eax, %ecx              compute product of x and yh, save to %ecx
movl    %edx, %ebx              copy the sign mask to %ebx
imull   %esi, %ebx              compute product of yl and sign mask, save to %ebx
addl    %ebx, %ecx              if x >= 0, %ecx unchanged; otherwise %ecx += -yl
mull    %esi                    compute full unsigned product of yl and x, save to %edx:%eax
leal    (%ecx,%edx), %edx       add %ecx and %edx, save to %edx
movl    8(%edp), %ecx           retrieve dest, save to %ecx 
movl    %eax, (%ecx)            save %eax to lower 4 bytes of *dest
movl    %edx, 4(%ecx)           save %edx to higher 4 bytes of *dest

3.56
A.  %esi: x
    %ebx: n
    %edi: result 
    %edx: mask
B.  result = -1;
    mask = 1;
C.  mask != 0
D.  mask <<= n;
E.  result ^= x & mask;
F.  int loop(int x, int n) {
        int result = -1;
        int mask;
        for (mask = 1; mask != 0; mask <<= n) {
            result ^= x & mask;
        }
        return result;
    }

3.57
int cread_alt(int *xp) {
    let n = 0;
    return *(xp ? xp : &n);
}

3.58
typedef enum {MODE_A, MODE_B, MODE_C, MODE_D, MODE_E} mode_t;
int switch3(int *p1, int *p2, mode_t action)
{
    int result = 0;
    switch(action) {
    case MODE_A:
        result = *p1;
        *p1 = *p2;
        break;
    case MODE_B:
        result = *p2;
        result += *p1;
        *p2 = result;
        break;
    case MODE_C:
        *p2 = 15;
        result = *p1;
        break;
    case MODE_D:
        *p2 = *p1;
        result = 17;
        break;
    case MODE_E:
        result = 17;
        break;
    default:
}
    return result;
}

3.59
int switch_prob(int x, int n) {
    int result = x;
    switch(n) {
    case 50:
    case 52:
        result <<= 2;
        break;
    case 53:
        result >>= 2;
        break;
    case 54:
        result *= 3;
    case 55:
        result *= result;
    default:
        result += 10;
        break;
    }
    return result;
}

3.60
A.  T D[R][S][T]
    &D[i][j][k] == xD + L(S*T*i + T*j + k)
B.  according to errata: http://csapp.cs.cmu.edu/2e/errata.html
    imull I, S, T compute I * S, saves the result in T, the first operand has to be an immediate value
    R * S * T * 4 == 1980, R * S * T == 495
    after line 6, %eax == 99i + 11j + k
    therefore T = 11, S = 9, R = 5

3.61
int var_prod_ele_opt(int n, int A[n][n], int B[n][n], int i, int k) {
    int *Arow = &A[i][0];
    int *Bptr = &B[0][k] + n * (n-1);
    int result = 0;
    n--;
    while (n >= 0) {
        result += Arow[n] * *Bptr;
        Bptr -= n;
        n--;
    }
    return result;
}

3.62
A.  M = 13
B.  %ecx: j
    %edi: i
C.  void transpose_opt(Marray_t A) {
        int i, j, *Cptr, *Rptr;
        for (i = 0; i < M; i++) {
            Cptr = &A[i][0];
            Rptr = &A[0][i];
            for (j = 0; j < i; j++) {
                int t = Cptr[j];
                Cptr[j] = *Rptr;
                *Rptr = t;
                Rptr += M;
            }
        }
    }

3.63
line 19 in the loop increments %eax (row pointer) by %esi
on line 9, %esi == %ecx * 4
on line 3, %ecx == %edx + %eax == 3%eax == 3n
E2(n) = 3n
on line 14, %ecx get initialized to 1
on line 18 in the loop, %ecx is incremented by 1 then compared to %ebx, loop condition is %ebx != %ecx
on line 4, %ebx == %edx == 2%eax == 2n, then %ebx += 2 on line 15, %ebx == 2n + 2
E1(n) = 2n + 1

3.64
A.  8(%ebp): a pointer to a struct str2, allocated by the caller of word_sum
    12(%ebp): s1.a
    16(%ebp): s1.p
B.  %ebp
    +16     space allocated for s2.diff
    +12     space allocated for s2.sum
    +8      s1.p
    +4      s1.a
    %esp    the hidden "zeroth argument" to word_sum, of type (struct str2 *), a str2 allocated on %esp+12 and %esp+16
C.  the structure is allocated on the stack frame of the caller
    callee refers the structure as usual
D.  the structure is allocated on the stack frame of the caller
    the callee is implicitly being passed a pointer to the caller-allocated structure
    the callee then mutates the states of the structure by memory accessing
    the compiled word_sum is effectively:
    void word_sum(str2 *s2, str1 s1) {
        s2.sum = s1.a + *s1.p;
        s2.diff = s1.a - *s1.p;
    }

3.65
the alignment of str2 is 4
as q->t is accessed by 12(%eax), char array[B] and the padding following it (if any) takes 12 bytes of space, so
    9 <= B <= 12
as q->u is accessed by 36(%eax), short s[B] and the padding following it takes 20 bytes of space, so
    9 <= B <= 10
as p->y is accessed by 92(%eax), short x[A][B] and the padding following it takes 92 bytes of space, so
    45 <= AB <= 46
if B == 10, no integer A will satisfy this condition
therefore B == 9, A == 5

3.66
A.  bp->right is accessed by 0xb8(%ecx), a_struct a[CNT] and the padding following it takes 180 bytes of space
    after line 6, %eax == 5i
    line 7 adds *(int *)((void *)bp + 20i + 4) to %eax
    thereby a_struct takes 20 bytes of space, CNT == 9
B.  0x4(%ecx, %eax, 4) most likely refers to a[i].idx
    typedef struct {
        int idx;
        int x[4];
    }

3.67
A.  e1.p: 0
    e1.y: 4
    e2.x: 0
    e2.next: 4
B.  8 bytes
C.  up->next->y = *(up->next->p) - up->x;

3.68
thanks https://github.com/jlroo/Computer-Systems/blob/master/HW_6/good_echo.c
#define BUF_SIZE 16
void good_echo() {
    char c, buf[BUF_SIZE];
    int i;
    while (1) {
        if (fgets(buf, BUF_SIZE, stdin) == NULL)
            return;
        for (i = 0; i < BUF_SIZE; i++) {
            c = putc(buf[i], stdout);
            if (c == EOF || c == '\n')
                return;
        }
    }
}

3.69
A.  long trace(tree_ptr tp) {
        long result = 0;
        while (tp != NULL) {
            result = tp->val;
            tp = tp->right;
        }
        return result;
    }
B.  returns the right-most value in the tree

3.70
A.  -9223372036854775808 is 1 followed by 63 0 in binary form
    long traverse(tree_ptr tp) {
        // the minimal value of long;
        long result = 1 << 63;
        long l_val, r_val;
        if (tp == NULL)
            return result;
        l_val = traverse(tp->left);
        r_val = traverse(tp->right);
        if (l_val >= result)
            result = l_val;
        if (r_val > result)
            result = r_val;
        return result;
    }
B.  finds the greatest value in the tree
    return the minimal value of type long if the tree is empty
    
4.1
30F30F00000020314013FDFFFFFF6031700C000000

4.2
A.  irmovl $-4, %ebx
    rmmovl %esi, 2048(%ebx)
    halt
B.  pushl %esi
    call 0x208
    halt
    0x208 <L0>:
    irmovl $10, %ebx
    ret
C.  Decode error: InvalidInstSpec at 7
D.  0x400 <L0>:
    subl %ecx, %ebx
    je 0x400
    halt
E.  Decode error: InvalidRegisterCode at 4

4.3
Rsum:
    pushl   %ebp
    rrmovl  %esp, %ebp 
    mrmovl  8(%ebp), %ecx
    mrmovl  12(%ebp), %edx
    andl    %edx, %edx
    jg      Rec
    irmovl  $0, %eax
    jmp     End
Rec:
    irmovl  $4, %eax
    addl    %eax, %ecx
    irmovl  $-1, %eax
    addl    %eax, %edx
    pushl   %edx
    pushl   %ecx
    call    Rsum
    popl    %ecx
    popl    %edx
    mrmovl  8(%edp), %ecx
    mrmovl  (%ecx), %ecx
    addl    %ecx, %eax
End:
    rrmovl  %ebp, %esp
    popl    %ebp
    ret

4.4
Sum:
    pushl   %ebp
    rrmovl  %esp, %ebp 
    mrmovl  8(%ebp), %ecx
    mrmovl  12(%ebp), %edx
    xorl    %eax, %eax
    andl    %edx, %edx
    je      End
Loop:
    mrmovl  (%ecx), %esi
    andl    %esi, %esi
    jge     Pos
    rrmovl  %esi, %ebx
    irmovl  $0, %esi
    subl    %ebx, %esi
Pos:
    addl    %esi, %eax
    irmovl  $4, %ebx
    addl    %ebx, %ecx
    irmovl  $-1, %ebx
    addl    %ebx, %edx
    jne     Loop
End:
    rrmovl  %ebp, %esp
    popl    %ebp
    ret

4.5
Sum:
    pushl   %ebp
    rrmovl  %esp, %ebp 
    mrmovl  8(%ebp), %ecx
    mrmovl  12(%ebp), %edx
    xorl    %eax, %eax
    andl    %edx, %edx
    je      End
Loop:
    mrmovl  (%ecx), %esi
    irmovl  $0, %ebx
    subl    %esi, %ebx
    andl    %esi, %esi
    cmovl   %ebx, %esi
    addl    %esi, %eax
    irmovl  $4, %ebx
    addl    %ebx, %ecx
    irmovl  $-1, %ebx
    addl    %ebx, %edx
    jne     Loop
End:
    rrmovl  %ebp, %esp
    popl    %ebp
    ret
    
4.6
pushl %esp pushes the original %esp before decrementation
otherwise the procedure will return 4

4.7
popl increments %esp first, then moves the value pointed by %esp to the operand
irmovl $0xabcd, %eax

4.8
bool xor = (a && !b) || (!a && b)
xor == !eq

4.9
xor (for every ai and bi, 0 <= i <= 31) -> or (32 inputs) -> not

4.10
int Median3 = [
    (A <= B && B <= C) || (C <= B && B <= A):   B;
    (B <= A && A <= C) || (C <= A && A <= B):   A;
    1                                       :   C;
]

4.11
3:0 <- M1[0x00e]
f:4 <- M1[0x00f]
0x80 <- M4[0x010]
valP <- 0x014
R[%esp] <- 0x80
PC <- valP
PC += 6;
%esp = 128;

4.12
b:0 <- M1[0x01c]
0:f <- M1[0x01d]
valP <- PC + 2 == 0x01e
valA <- 124
valB <- 124
valE <- valB + 4 == 128
valM <- M1[valA] == 9
R[%esp] <- valE == 128
R[%eax] <- valM == 9
PC <- valP == 0x01e
PC += 2;
%esp += 4;
%eax = 9;

4.13
write then decrement
conforms to the desired behavior

4.14
increment then write
conforms to the desired behavior

4.15
Fetch       icode:ifun <- M1[PC]
            rA:rB <- M1[PC + 1]
            valP <- PC + 2
Decode      valA <- R[rA]
            valB <- R[rB]
Execute     valE <- 0 + valA
            Cnd <- Cond(CC, ifun)
Memory
Write back  R[rB] <- Cnd ? valA : valB
PC update   PC <- valP

4.16
8:0 <- M1[0x023]
valC <- 0x029
valP <- PC + 5 == 0x028
valB <- R[%esp] == 128
valE <- valB + (-4) == 124
M4[valE] <- valP == 0x028
R[%esp] <- valE == 124
PC <- valC == 0x029

4.17
need_valC = icode in { IIRMOVL, IRMMOVL, IMRMOVL, IJXX, ICALL }

4.18
int srcB = [
    icode in { IRMMOVL, IMRMOVL, IOPL }     : rB;
    icode in { ICALL, IRET, IPUSHL, IPOPL } : RESP;
    1                                       : RNONE;
]

4.19
int dstM = [
    icode in { IMRMOVL, IPOPL } : rA;
    1                           : RNONE;
]

4.20
write to port E should have higher priority than write to port M

4.21
int aluB = [
    icode in { IOPL, IRMMOVL, IMRMOVL, IPUSHL, IPOPL, ICALL, IRET } : valB;
    icode in { IRRMOVL, IIRMOVL, }                                  : 0;
]

4.22
int dstE = [
    icode in { IRRMOVL } && Cnd : rB;
    icode in { IIRMOVL, IOPL } : rB;
    icode in { IPUSHL, IPOPL, ICALL, IRET } : RESP;
    1 : RNONE;  # Don’t write any register
];

4.23
int mem_data = [
    icode in { IPUSHL, IRMMOVL } : valA;
    icode in { ICALL } : valP;
]

4.24
bool mem_write = icode in { IPUSHL, IRMMOVL, ICALL }

4.25
char Stat = [
    icode == IHALT : SHALT;
    !instr_valid : SINS;
    imem_error || dmem_error : SADR;
    1 : SAOK;
]

4.26
A.  between C and D
    190ps per stage
    latency 380ps
    throughput 2/380ps == 5.26 GIPS
B.  between B and C, between D and E
    130ps per stage
    latency 390ps
    throughput 3/390ps == 7.69 GIPS
C.  between AB, CD, DE
    110ps per stage
    latency 440ps
    throughput 4/440ps == 9.09 GIPS
D.  insert pipeline register between every two stages
    100ps per stage, 6 stages
    latency 600ps
    throughput 6/600ps == 10 GIPS

4.27
A.  (300/k + 20)ps per stage, k stages
    latency (300/k + 20) * k == (300 + 20k)ps
    throughput k/(300 + 20k) GIPS
B.  lim(k->∞)(k/(300 + 20k)) = 1/20
    throughput 1/20 * 1000 = 50 GIPS

4.28
byte f_stat = [
    f_icode == IHALT : SHALT;
    !f_instr_valid : SINS;
    f_imem_error : SADR;
    1 : SAOK;
]

4.29
int d_dstE = [
    D_icode in { IRRMOVL } : D_rB;
    D_icode in { IIRMOVL, IOPL } : D_rB;
    D_icode in { IPUSHL, IPOPL, ICALL, IRET } : RESP;
    1 : RNONE;
]

4.30
reversed: %eax == 0x104
correct: %eax == whatever at (0x104)

4.31
exactly the same program in 4.30

4.32
int d_valB = [
    d_srcB == e_dstE : e_valE;
    d_srcB == M_dstM : M_valM;
    d_srcB == M_dstE : M_valE;
    d_srcB == W_dstM : W_valM;
    d_srcB == W_dstE : W_valE;
    1 : d_rvalB;
]

4.33
dstE is defined in SEQ as:
int dstE = [
    icode in { IRRMOVL } && Cnd : rB;
    icode in { IIRMOVL, IOPL } : rB;
    icode in { IPUSHL, IPOPL, ICALL, IRET } : RESP;
    1 : RNONE;  # Don’t write any register
];
Cnd is computed at execution stage, thereby E_dstE do not always equal to e_dstE for the first case
for all CMOVXX instructions, E_dstE will always be rB
iirmovl $1, %edx
iirmovl %0, %eax
andl %eax, %eax
cmovne %edx, %eax
if E_dstE is used in place of e_dstE, %eax == 1, otherwise %eax == 0

4.34
"The basic rule is to put priority on the exception triggered by the instruction that is furthest along the pipeline."
byte m_stat = [
    dmem_error : SADR;
    1 : M_stat;
]

4.35
    xorl %edx, %edx
    jne Prod
    irmovl $1, %edx
    halt
Prod:
    ret
    irmovl $2, %edx
    halt
when a misprediction is detected in execution stage, pipeline register D and E will be set to bubble
the ret instruction at decode will be erased from the pipeline after the current cycle
the ret instruction causes D_icode == IRET and will stall pipeline register F
but f_pc is implemented as:
int f_pc = [
        # Mispredicted branch.  Fetch at incremented PC
        M_icode == IJXX && !M_Cnd : M_valA;
        # Completion of RET instruction.
        W_icode == IRET : W_valM;
        # Default: Use predicted value of PC
        1 : F_predPC;
];
so when misprediction happens (M_icode == IJXX && !M_Cnd), f_pc is irrelative to F_predPC
the instructions currently at fetch and decode stages will be overwritten by bubbles
the next instruction fetched will be that pointed by M_valA, the instruction following the jxx instruction
the control logic handles this problem correctly

4.36
ret reads from %esp
so load/use hazard can happen right before a ret instruction iff the previous instruction is mrmovl -(-), %esp
ret will return to the instruction pointed by (%esp + 4) when executed correctly
    irmovl ADDR, %edx
    mrmovl (%edx), %esp
    ret
ADDR:
    .long ORIGIN
ORIGIN:
    .align 4
    .long 0
    .long HALT
HALT:
    halt

4.37
bool D_stall = E_icode in { IMRMOVL, IPOPL } && E_dstM in { d_srcA, d_srcB };

4.38
bool mispred = E_icode == IJXX && !e_Cnd;
bool load_use = E_icode in { IMRMOVL, IPOPL } && E_dstM in { d_srcA, d_srcB };
bool D_bubble = mispred || load_use;

4.39
//Figure 4.64
bool exception = m_stat in { SHLT, SADR, SINS } || W_stat in { SHLT, SADR, SINS };
bool set_cc = E_icode == IOPL && exception;

4.40
// change of CC, memory write and register write back should be disabled when exception happens
bool M_bubble = exception;
// when an exception arised from memory stage
// the instruction in write back stage should still be fully executed
// register W should only stall when the exception has propagated to write back stage
bool W_stall = W_stat in { SHLT, SADR, SINS };

4.41
CPI = 0.2 * 0.35 * 2 + 0.05 + 0.06 + 1 = 1.25

4.42
A.  Problem 4.4: 12 instructions when negative, 9 instructions when non-negative, 10.5 on average
    Problem 4.5: 11 instructions, 11 on average
B.  mispredicted jxx instruction will introduce 2 bubbles
    while cmovxx will not introduce bubbles due to forwarding
    both problems will cause exactly one load/use hazard, introducing one bubble
    Problem 4.4: 3 bubbles with misprediction, 1 bubble with correct prediction, 2 on average
    Problem 4.5: 1 bubble on average
C.  Problem 4.4: 12.5 cycles on average 
    Problem 4.5: 12 cycles on average

4.43
A.  from the analysis in problem 4.6
    pushl pushes the original value of %esp to the stack before decrementing it
    this code sequence doesn't correctly describe the behavior of pushl %esp
B.  movl REG, -4(%esp)
    subl $4, %esp

4.44
A.  from the analysis in problem 4.7
    popl first decrements %esp, then move the value pointed by the original %esp to the operand register
    this code sequence does not correctly describe the behavior of popl %esp
B.  subl $4, %esp
    movl 4(%esp), REG

4.45
A.  void bubble_b(int *data, int count) {
    int i, last, *lower, *higher, t;
        for (last = count - 1; last > 0; last--) {
            lower = data;
            higher = lower + 1;
            for (i = 0; i < last; i++) {
                if (*higher < *lower) {
                    t = *higher;
                    *higher = *lower;
                    *lower = t;
                    higher++;
                    lower++;
                }
            }
        }
    }
B.      pushl %ebp
        rrmovl %esp, %ebp
        mrmovl 12(%ebp), %edx       retrieve count
        irmovl $1, %eax             
        subl %eax, %edx             initialize last for outer loop
        jle End                     skip outer loop if last <= 0
    Outer:
        mrmovl 8(%ebp), %esi        retrieve data, compute lower
        rrmovl %esi, %edi           
        irmovl $4, %eax 
        addl %eax, %edi             compute higher
        irmovl $0, %ecx             initialize i for inner loop
    Inner:
        mrmovl (%esi), %eax         *lower
        mrmovl (%edi), %ebx         *higher
        subl %eax, %ebx             *higher - *lower, no cmpl instruction, have to perform subl and overwrite %ebx
        jge NOSWAP 
        mrmovl (%edi), %ebx         reset %ebx to *higher
        rmmovl %ebx, (%esi)         
        rmmovl %eax, (%edi)         swap *higher and *lower
    NOSWAP:
        irmovl $4, %eax
        addl %eax, %esi             lower++
        addl %eax, %edi             higher++
        irmovl $1, %eax
        addl %eax, %ecx             i++
        rrmovl %ecx, %ebx 
        subl %ecx, %ebx             i - count
        jl Inner
    InnerEnd:
        irmovl $1, %eax
        subl %eax, %edx             last--
        jg Outer
    End:
        pushl %ebp
        ret
        
4.46
    pushl %ebp
    rrmovl %esp, %ebp
    mrmovl 12(%ebp), %edx       retrieve count
    irmovl $1, %eax             
    subl %eax, %edx             initialize last for outer loop
    jle End                     skip outer loop if last <= 0
Outer:
    mrmovl 8(%ebp), %esi        retrieve data, compute lower
    rrmovl %esi, %edi           
    irmovl $4, %eax 
    addl %eax, %edi             compute higher
    irmovl $0, %ecx             initialize i for inner loop
Inner:
    mrmovl (%esi), %eax         *lower
    mrmovl (%edi), %ebx         *higher
    subl %eax, %ebx             *higher - *lower, no cmpl instruction, have to perform subl and overwrite %ebx
    pushl %edx                  not enough registers, reusing %edx
    mrmovl (%edi), %ebx         reset %ebx to *higher
    mrmovl (%esi), %edx         set %edx to *lower
    cmovl %ebx, %eax
    cmovl %edx, %ebx            swap the value of %eax and %ebx if *higher < *lower
    popl %edx                   reset %edx to last
    rmmovl %eax, (%esi)         
    rmmovl %ebx, (%edi)         swap *higher and *lower
    irmovl $4, %eax
    addl %eax, %esi             lower++
    addl %eax, %edi             higher++
    irmovl $1, %eax
    addl %eax, %ecx             i++
    rrmovl %ecx, %ebx 
    subl %ecx, %ebx             i - count
    jl Inner
InnerEnd:
    irmovl $1, %eax
    subl %eax, %edx             last--
    jg Outer
End:
    pushl %ebp
    ret
    
4.47
Fetch:      icode:ifun <- M1[PC]
            rA:rB <- M1[PC + 1]
            valC <- M4[PC + 2]
            valP <- PC + 6
Decode:     valB <- R[rB]
Execute:    valE <- valC + valB
            Set CC
Memory:
Write back: R[rB] <- valE
PC update:  PC <- valP

4.48
Fetch:      icode:ifun <- M1[PC]
            valP <- PC + 1
Decode:     valA <- r[%ebp]
            valB <- r[%ebp]
Execute:    valE <- 4 + valB
Memory:     valM <- M4[valA]
Write back: r[%esp] <- valE
            r[%ebp] <- valM
PC update:  PC <- valP

4.49 - 4.50
./CSAPP/hcl/seq-full.hcl

4.51
the file actually is named pipe-nobypass.hcl
without forwarding, all write to registers should stall following reading from the same register until write back stage
write instructions: OPL, RRMOVL, IRMOVL, MRMOVL, POPL, PUSHL, CALL, RET
read instructions: OPL, RRMOVL, MRMOVL, RMMOVL, POPL, PUSHL, CALL, RET
this "read/write hazard" happens where normally forwarding happens, thereby the forwarding logic can be reused here:
    // wrong version
    // bool rw_hazard =
    //     d_srcA in { e_dstE, M_dstM, M_dstE, W_dstM, W_dstE } ||
    //     d_srcB in { e_dstE, M_dstM, M_dstE, W_dstM, W_dstE };
    bool rw_hazard =
        (d_srcA != RNONE && d_srcA in { e_dstE, M_dstM, M_dstE, W_dstM, W_dstE }) ||
        (d_srcB != RNONE && d_srcB in { e_dstE, M_dstM, M_dstE, W_dstM, W_dstE });
the read instruction is stalled at decode stage
the write instruction moves normally from execute stage to write back stage
therefore pipeline register D and before (F) should be stalled, also bubbles should be inserted in E
F       D       E       M       W
stall   stall   bubble  normal  normal
like processing ret, rw_hazard can happen in different stages (execute, memory and write back)
while bubbles will be inserted at execute stage
    case1   case2   case3
W                   write 
M           write   bubble
E   write   bubble  bubble
D   read    read    read
Combination 1:
    when a pair of write/read instructions is also a pair of load/use instructions (e.g. MRMOVL -> RRMOVL)
    case1 and load/use hazard can happen in the same time
    however they force the same set of stall/bubble conditions onto registers, so this combination causes no trouble
    actually the conditions that triggers load/use hazard is a subset of conditions that triggers write/read hazard
    hence load/use hazards can be ignored
Combination 2, 3, 4:
    RET is a read instruction (reads %esp)
    so all three cases of read/write hazard and case1 of ret may happen at the same time
    this combination will put pipeline register D in both stalled and bubble condition
    to solve this confliction, the write instruction preceding RET should be fully executed first
    W   bubble
    M   bubble
    E   bubble
    D   ret
    then the RET instruction can be processed normally
    therefore the condition set of write/read hazard should have higher priority than ret processing
for the resulting pipe-stall.hcl
please refer https://github.com/DreamAndDead/CSAPP-3e-Solutions/blob/master/chapter4/code/sim/pipe/pipe-stall.hcl
also thanks https://github.com/DreamAndDead/CSAPP-3e-Solutions/blob/master/chapter4/4.53.md
excluded the situation where d_srcA == RNONE or d_srcB == RNONE
where forwarding didn't actually happen but the forwarding logic still computes the correct srcA and srcB
however according to analysis here, jxx misprediction and write/read hazard cannot happen at the same time
(jxx is neither a read nor write instruction, d_srcA == d_srcB == RNONE)
hence rw_hazard implies !jxx_misprediction and the above implementation includes a few redundency
after deleting misprediction conditions from like (rw_hazard && !jxx_misprediction)
the compiled simulator still passes all 600 hazard tests defined by htest.pl
./CSAPP/hcl/pipe-stall.hcl

4.52
the condition code should be updated
./CSAPP/hcl/pipe-full.hcl

4.53
LEAVE reads memory into registers, thereby is vulnerable to load/use hazard
bool load_hazard = E_icode in { IPOPL, IMRMOVL, ILEAVE } && E_dstM in {d_srcA, d_srcB };
./CSAPP/hcl/pipe-full.hcl

4.54
J_YES is actually defined as UNCOND in the file
the meaning of misprediction reversed
    bool mispred = M_icode == IJXX && M_ifun != UNCOND && Cnd;
all pipeline register control and fetching code should be adjusted accordingly
for instruction JXX, E_valA and M_valA are not used, it's safe to store E_valC in M_valA through e_valA:
    int e_valA = [
        E_icode in { IJXX } : E_valC;
        1 : E_valA;
    ];
./CSAPP/hcl/pipe-nt.hcl

4.55
thanks https://github.com/DreamAndDead/CSAPP-3e-Solutions/blob/master/chapter4/code/sim/pipe/pipe-btfnt.hcl
had never known one can compare integers in hcl (what's the purpose of CC then?)
JXX instruction do not use ALU as well: both M_valE and M_valA can be safely reused
M_valA will be set to D_valP by default
by setting aluA to valC, aluB to 0 when E_icode == IJXX, M_valE will be D_valC
again the meaning of misprediction changed:
    bool mispred = 
        M_icode == JXX && M_ifun != UNCOND && 
        (M_Cnd && M_valE >= M_valA || !M_Cnd && M_valE < M_valA);
PC should be M_valE (== valC) when M_Cnd and M_valA (== valP) when !M_Cnd
(for some reason e_valA is not available in the pipeline register control logic, using E_valA there)
./CSAPP/hcl/pipe-btfnt.hcl

4.56
A.  among all instructions, only RMMOVL, PUSHL writes register values to memory
    for RMMOVL, only the value of rA can be forwarded from memory stage to execute stage, not rB
    for PUSHL, only the operand rA can be forwarded from memory stage to execute stage, not %esp
    both these two operands is passed as d_srcA
        bool e_forwarding = E_icode in { IMRMOVL, IPOPL } && D_icode in { IRMMOVL, IPUSHL } && E_dstM == d_srcA;
        bool load_hazard = E_icode in { IMRMOVL, IPOPL } && E_dstM in { d_srcA, d_srcB } && !e_forwarding
B.  forwarding logic:
    int e_valA = [
        E_icode in { IRMMOVL, IPUSHL } && E_srcA == M_dstM : m_valM;
        1 : E_valA;  
    ];
    ./CSAPP/hcl/pipe-lf.hcl

4.57
ipopl => iaddl $4, %esp 
ipop2 rA => mrmovl -4(%esp), rA
IPOPL
Fetch:      icode:ifun <- M1[PC]
            rA:rB <- M1[PC + 1]
            valP <- PC
            (next icode set to IPOP2)
Decode:     valB <- R[%esp]
Execute:    valE <- 4 + valB
Memory:
Write back: R[%esp] <- valE
PC update:  PC <- valP
IPOP2 rA
Fetch:      icode:ifun <- M1[PC]
            rA:rB <- M1[PC+1]
            valP <- PC + 2
Decode      valB <- R[%esp]
Execute:    valE <- -4 + valB
Memory:     valM <- M4[valE]
Write back: R[rA] <- valM
PC update:  PC <- valP
./CSAPP/hcl/pipe-1w.hcl

4.58
-

Chapter 5
5.1
it will set *xp (== *yp) to 0

5.2
n <= 2:         Version 1
3 <= n <= 7:    Version 2
n >= 7:         Version 3

5.3
A.  1   91  90  90
B.  91  1   90  90
C.  1   1   90  90

5.4
A.  in -O1, %xmm0 is used as a temporary register for storing and computing the next value for *dest
    in -O2, %xmm0 has the same role as acc in combine4, accumulating the product
B.  -
C.  as -O2 writes the value of %xmm0 to memory every iteration
    at the starting of each iteration, %xmm0 == (%r12), where %r12 holds dest
    -O1 and -O2 will be equivalent even if dest is aliased

5.5
A.  2n additions (result += .. and i++), 2n multiplications (a[i] * xpwr and x * xpwr)
B.  the latency bound of double multiplication is 5 cycles
    the value of xpwr in the next iteration depends on a multiple of xpwr in the currecnt iteration
    which forms a critical path, so 5 is the lower bound of the CPE of this function

5.6
A.  2n additions (a[i] + .. and i--) and n multiplications (x * result)
B.  now result is stored in a loop register
    its value in the next iteration depends on the return of an addition and a multiplication involving itself
    the critical path now contains a double multiplication and a double addition
    assuming result -> %xmm0, x -> %rax, i -> %rdx, the data-flow may looks like:
    %xmm0   %rax    %rdx
    |       |       |
    mul <---|       |
    |       |       |
    add <-----load--|
    |       |       add
    |       |       |
    %xmmo   %rax    %rdx
    the lower bound of CPE is the combined latency of double addition and double multiplication, which is 3+5 = 8
C.  the critical path is now longer, so is the CPE
    asymptotically, the function with lower CPE always win out 
5.7
./CSAPP/opt

5.8
r = ((r * x) * y) * z:
    three multiplications on the critical path
    CPE = 15
r = (r * (x * y)) * z:
    two multiplications on the critical path
    CPE = 10
r = r * ((x * y) * z) and r = r * (x * (y * z)):
    one multiplications on the critical path
    CPE = 5
r = (r * x) * (y * z):
    two multiplications on the critical path
    CPE = 10

5.9
./CSAPP/opt

5.10
A.  a[i] == i+1 for 0 <= i <= 998
    a[999] == 999
B.  a[i] == 0 for all i
C.  in part A, every memory position appears twice 
    first time as src, second time as dest in the next iteration
    thereby the function never reads from a memory position it previously stores to
    load and store operations in this case do not form critial paths
    in part B, again every memory position appears twice
    first time as dest, then immediately as src in the next iteration
    load operations in every iteration depends on store operation in the previous iteration
    the critical path in this case includes load and store operations, hence higher CPE
D.  as the function does not read from any memory address after write to it
    the performance should be close to that in part A

5.11
%rsi, %rax -> load_a
%rsi, %rax -> s_addr
%rdi, %rax -> load_b
load_a, load_b -> add
add -> s_data
s_data -> load_a, in next iteration, if addresses match
critical path:  (s_data in previous iteration)
                ! 
                load_a
                |
                addss
                |
                s_data
every iteration reads from memory address that is written to by the previous iteration
the critical path thus includes load and store operations

5.12
./CSAPP/opt

5.13
A.  a = 1500/2500 = 0.6
    k = 1.5
    S = 1/(0.4 + 0.6/1.5) = 1/0.8 = 1.25
B.  S = 1/((1 - a) + a/k) = 1/(0.4 + 0.4/k) = 5/3
    5 * (0.4 + 0.4/k) = 3
    2 + 2/k = 3
    2/k = 1, k = 2

5.14
S = 1/((1 - 0.8) + 0.8/k) = 2
0.4 + 1.6/k = 1
1.6/k = 0.6
k = 8/3

5.15
A.  %rbx, %rdx -> load_a
    %rax, %rdx -> load_b
    load_a, load_b -> mulss
    mulss, %xmm1 -> addss -> %xmm1
    %rdx -> add -> %rdx
    critical path:  %xmm1
                    |
                    addss
                    |
                    %xmm1
B.  the latency of single precision floating point addition
    CPE >= 3
C.  the latency of 32-bit integer addition
    CPE >= 1
D.  the multiplication operations have long latency (4-5 cycles) but is fully pipelined
    since all multiplications are local, they can be issued every cycle
    the floating point multiplication is located on another critical path, where %rdx is incremented
    as integer addition has very short latency (1 cycle), also the procedure does not alter values in memory
    data loading can be performed and cached every cycle, hence multiplication can be issued every next cycle
    the latency of floating point addition is longer than the throughput of floating point multiplication
    therefore the addition becomes the bottleneck

5.16
./CSAPP/opt
A.  every multiplication requires two data loads, every one takes one cycle at least
    so the multiplication can only be performed every next cycle
B.  the floating point addition is still on the critical path
    its 3-cycle latency is the bottleneck of this loop procedure

5.17
./CSAPP/opt
A.  data loading
B.  there are only 6 general-purpose registers in IA32
    there are at least 8 local variables in this procedure
    (which is length, udata, vdata, sum1 - sum4, i)
    some local variables have to be stored on the stack, thereby limits the performance

5.18
already done reassociation in problem 5.16
try implement the function with simds instead

5.19
./CSAPP/opt

5.20
./CSAPP/opt

5.21
./CSAPP/opt

5.22
S1 = 1/((1 - 30%) + 30%/3) = 1/(0.7 + 0.1) = 5/4
S2 = 1/((1 - 50%) + 50%/1.5) = 1/(1/2 + 2/3) = 6/5
should speed up part B

Chapter 6
6.1
4   4   2   2   2
4   4   2   2   2
16  8   4   3   4
32  16  5   4   5
32  32  5   5   5

6.2
2 * 2 * 10000 * 400 * 512 = 8.192 GB

6.3
Tseek = 8ms
Trotation = 1/2 * 60/15000 * 1000 = 2ms
Ttransfer = 1/15000 * 1/500 * 60 * 1000 = 0.008ms
Taccess = Tseek + Trotation + Transfer = 10.008ms

6.4
Tseek = 5ms
Trotation = 1/2 * 60/10000 * 1000 = 3ms
Ttransfer = 1/10000 * 1/1000 * 60 * 1000 = 0.006ms
if sequential: T = Tseek + Trotation + Ttransfer * 10^6/512 = 19.72ms
if random: T = 10^6/512 * (Tseek + Trotation + Ttransfer) = 15636.71ms

6.5
A.  cylinders in use: 22076928 / 8 / 864 = 3194
    spare cylinders: 3201 - 3194 = 7
B.  cylinders in use: 20804608 / 8 / 704 = 3694
    spare cylinders: 3700 - 3694 = 6

6.6
A.  10^15 / (170 * 10^6) / 3600 / 24 / 365 = 0.187 years
B.  10^15 / (14 * 10^6) / 3600 / 24 / 365 = 2.265 years
C.  10^15 / (20 * 10^9) / 365 = 137.00 years
    
6.7
log(3e-4 / (500 / (1e15 / 1e6))) / log(1600000 ** (1/30)) = 13.434
around year 2023

6.8
change line 8 to
    sum += a[i][j][k];

6.9
clear1:
    stride-1 reference pattern
clear2:
    the 6 4-byte memory positions in a struct is referred in order:
    0   3   1   4   2   5
    similar to a stride-3 reference pattern
clear3:
    stride-6 reference pattern

6.10
-

6.11
3 out of 4 floats in a block will be cache hits

6.12
A.  in this scenario, an address is parsed as:
        s||t||b
    where s is set index, t is tag, b is block offset
    assuming direct-mapping caches, there is only one line in every set
    addresses with same s and t but different b are in the same block
    addresses with same s but different t and b are mapped to the same cache set
    therefore 2^t contiguous blocks are mapped to the same set
B.  s = 9
    b = 5
    t = m - (b + s) = 32 - 14 = 18
    int is 4-byte long, every 2^18 / 4 = 65536 contiguous bits will be mapped to the same block
    thus all array[4096] will be mapped to the same block, at most one block will be stored in the cache

6.13
s = 3
b = 2
t = m - (b + s) = 8
from highest bit to lowest
12-5: tag
4-2: set index
1-0: block offset

6.14
A.  0x0E34 = 0b01110001-101-00
B.  CO: 0x0
    CI: 0x5
    CT: 0x71
    cache hit: Y
    byte returned: 0x0B

6.15
A.  0x0DD5 = 0b01100110-001-01
B.  CO: 0x1
    CI: 0x1
    CT: 0x66
    cache hit: N
    byte returned: -

6.16
A.  0x1FE4 = 0x11111111-001-00
    CO: 0x0
    CI: 0x1
    CT: 0xFF
    cache hit: N 
    byte returned: -

6.17
0x064C
0x064D
0x064E

6.18
read/write positions in every iteration:
    iter    i   j   read    write
    1       0   0   0       16
    2       0   1   4       24
    3       1   0   8       20
    4       1   1   12      28
A.  t = log2(32/16) = 1
    read/write set in every iteration:
        iter    r_addr  r_set   w_addr  w_set   r_hit   w_hit
        1       0       0       16      0       N       N
        2       4       0       24      1       N       N
        3       8       1       20      0       N       N
        4       12      1       28      1       Y       N
B.  t = log(32/32) = 1, the entirety of both arrays can be loaded into the cache
        iter    r_addr  r_set   w_addr  w_set   r_hit   w_hit
        1       0       0       16      2       N       N
        2       4       0       24      3       Y       N
        3       8       1       20      2       N       Y
        4       12      1       28      3       Y       Y

6.19
t = log2(16*16*4*2/1024) = 1
A.  16 * 16 * 2 = 512 reads
B.  a block contains 16/sizeof(algae-position) = 2 structs
    every next read in both iteration will be a cache miss
    512/2 = 256 reads miss
C.  256/512 = 50%

6.20
A.  still 512 reads, since structs with multiple fields usually cannot be stored in registers
    .x and .y have to be two seperate memory reads
B.  a stride-64 reference pattern
    every 8 loads from the lower level in an iteration will be overwritten by the next 8 loads
    let struct B be the struct next to struct A in the array, then B will only be read after 16 iteration
    thus every structs have to be read from the lower level, but both fields x and y are read in a single iteration
    every next read will be a cache miss
    512/2 = 256 reads miss 
C.  256/512 = 50%
D.  when the cache is large enough to load the entirety of the array
    one read from the lower level can load two structs into the cache
    every one out of four read will miss, miss rate 25%

6.21
A.  still 512 reads
B.  again a block contains 2 structs
    but this time both fields x and y are read in a single iteration
    every one out of four reads will be a cache miss
    512/4 = 128 reads miss
C.  128/512 = 25%
D.  will not change as long as the block size is still 16 bytes

6.22
nowhere in the text ever mentioned the clock cycle per second of this particular i7 CPU

6.23
let B denotes the total number of bits can be stored on the disk
B = Θ(xr * (1-x)r) = Θ(x - x^2)
the maximum of (x - x^2) is at x = 1/2

6.24
Tseek = 4ms
Trotation = 1/2 * 1/15000 * 60 * 1000 = 2ms
Ttransfer = 1/15000 * 1/800 * 60 * 1000 = 0.005ms
T = 4 + 2 + 0.005 = 6.005ms

6.25
Tseek = 4ms
Trotation = 1/15000 * 60 * 1000 = 2ms
Ttransfer = 1/15000 * 1/1000 * 60 * 1000 = 0.004ms
A.  T = Tseek + Trotation + (2e6 / 512) * Ttransfer = 21.625ms
B.  T = (2e6 / 512) * (Tseek + Trotation + Ttransfer) = 23453.125ms

6.26
fn calc(m: u32, c: u32, b: u32, e: u32) {
  let s = (c / b) / e;
  let lb = 32 - (b-1).leading_zeros();
  let ls = 32 - (s-1).leading_zeros();
  let lt = m - lb - ls;
  println!("{}\t{}\t{}\t{}", s, lt, ls, lb);
}
64	24	6	2
1	30	0	2
128	22	7	3
1	29	0	3
32	22	5	5
8	24	3	5

6.27
1.  S = 2^s = 256
    C = S * E * B = 1024
2.  B = 2^b = 4
    E = (C / B) / S = 4
3.  s = log2(S) = 6
    t = m - b - s = 25
4.  B = (C / E) / S = 32
    b = log2(B) = 5

6.28
fn valid_address(ci: u32, cts: &[u32]) {
  for ct in cts {
    for co in 0..4 {
      println!("0x{:04X}", (*ct << 5) + (ci << 2) + co);
    }
  }
}
A.  0x08A4
    0x08A5
    0x08A6
    0x08A7
    0x0704
    0x0705
    0x0706
    0x0707
B.  0x1238
    0x1239
    0x123A
    0x123B

6.29
A.  no hit, both lines invalid
B.  0x18F0
    0x18F1
    0x18F2
    0x18F3
    0x00B0
    0x00B1
    0x00B2
    0x00B3
C.  0x0E34
    0x0E35
    0x0E36
    0x0E37
D.  0x1BDC
    0x1BDD
    0x1BDE
    0x1BDF

6.30
b = log2(B) = 2
s = log2(S) = 2
t = m - b - s = 8
A.  11-4: CT
    3-2: CI
    1-0: CO
B.  0x834 = 0b10000011-01-00
        CT = 0x83
        CI = 0x1 
        CO = 0x0
        miss, value unknown
    0x836 = 0b10000011-01-10
        CT = 0x83
        CI = 0x1 
        CO = 0x2
        hit
    0xFFD = 0b11111111-11-01
        CT = 0xFF
        CI = 0x3
        CO = 0x1
        hit, read value = 0xC0

6.31
A.  C = B * E * S = 128
B.  s = 3, b = 2, t = 13 - 3 - 2 = 8
    12-5: CT
    4-2: CI
    1-0: CO

6.32
fn decode(addr: u32) {
  let ct_mask = 0xff << 5;
  let ct = (addr & ct_mask) >> 5;
  let ci_mask = 0b111 << 2;
  let ci= (addr & ci_mask) >> 2;
  let co_mask = 0b11;
  let co = addr & co_mask;
  println!("0x{:0X} = 0b{:08b}-{:03b}-{:02b}", addr, ct, ci, co);
  println!("CT: 0x{:02X}", ct);
  println!("CI: 0x{:X}", ci);
  println!("CO: 0x{:X}", co);
}
A.  0x071A = 0b00111000-110-10
B.  CT = 0x38
    CI = 0x6
    CO = 0x2
    hit: Y 
    return: 0xEB

6.33
A.  0x16E8 = 0b10110111-010-00
B.  CT: 0xB7
    CI: 0x2
    CO: 0x0
    hit: N
    return: -

6.34
0x1788
0x1789
0x178A
0x178B
0x16C8
0x16C9
0x16CA
0x16CB

6.35
(i, j): s_hit   d_hit
(0, 0): false   false
(0, 1): false   false
(0, 2): true    false
(0, 3): false   false
(1, 0): false   false
(1, 1): true    false
(1, 2): false   false
(1, 3): true    false
(2, 0): false   false
(2, 1): false   false
(2, 2): true    false
(2, 3): false   false
(3, 0): false   false
(3, 1): true    false
(3, 2): false   false
(3, 3): true    false

6.36
(i, j): s_hit   d_hit
(0, 0): false   false
(0, 1): true    false
(0, 2): true    false
(0, 3): true    false
(1, 0): false   true
(1, 1): true    true
(1, 2): true    true
(1, 3): true    true
(2, 0): false   true
(2, 1): true    true
(2, 2): true    true
(2, 3): true    true
(3, 0): false   true
(3, 1): true    true
(3, 2): true    true
(3, 3): true    true

6.37
A.  in every iteration, &x[0][i] + 512 == &x[1][i] 
    every second read in an iteration will overwrite the data loaded by the first one
    every read will be a cache miss, results in a 100% miss rate
B.  the entirety of the array can be loaded into the cache
    every cache miss will load 1 block (== 4 ints) into the cache, results in a 25% miss rate
C.  again &x[0][i] + 512 = &x[1][i], the two reads will be loaded to the same cache set
    but now the cache set has two lines, the second read will not overwrite the first one
    after 4 * 512 / 16 / 2 = 64 iterations, the same cache set will be used again
    as the update policy is LRU, the data 64 iteration ago will soon be discarded
    the cache after 64 iteration hehaves just like an empty cache
    every cache miss will load 4 ints into the cache, results in 25% miss rate
D.  25% is already the optimal miss rate with a block size of 16 bytes
    increasing the cache size will not reduce the miss rate
E.  assume the a block contains B bytes of data
    every cache miss will load B/4 ints into the cache
    the miss rate will be 1/(B/4)

6.38
S = 2^12 / 16 = 256
s = 8, b = 4
sumA:
    stride-1 reference pattern
    miss rate will be approximately 1/(16/4) = 25% in both cases
sumB:
    when N = 64, 
        the inner loop is a stride-256 reference pattern
        if the ith read is mapped to jth cache set, (i+1)th read is mapped to (j+(256/16) mod S)th cache set
        256 / 16 = 16, the subgroup of Z256 generated by 16 has only 16 elements
        thereby every 16 loads will be overwritten by the following 16 loads
        while a memory address is read, the address next to it will only be read in the next inner loop
        an inner loop has 64 iterations, the block is already overwritten then
        approximately all read will be a cache miss, results in 100% miss rate
    when N = 60, 
        the inner loop is a stride-240 reference pattern
        240 / 16 = 15, 15 and 256 are coprime, 15 is a generator of Z256
        the 60 reads in the first inner loop will all miss
        but every cache miss will load a block into the cache, none will be overwritten
        then reads in the next three inner loops will not miss
        approximate miss rate is 25%
sumC:
    when N = 64,
        &a[i][j] + 256 = &a[i+1][j]
        &a[i][j+1] + 256 = &a[i+1][j+1]
        in a single iteration, a[i][j] and a[i+1][j] will be mapped to different cache sets
        thereby a[i][j+1] and a[i+1][j+1] will not be cache miss
        i is incremented by 2 every iteration
        in the inner loop all four reads in a iteration is a stride-512 reference pattern
        subgroup of Z256 generated by 512/16 = 32 has only 8 elements
        thereby loads in every 8 iteration will be overwritten by the following 8 iterations
        when a block is loaded, two ints are read, the other two will only be read in the next inner loop
        an inner loop has 32 iterations, the block is already overwritten then
        thereby approximately the miss rate is 50%
    when N = 60, 
        in the inner loop all four reads in a iteration is a stride-480 reference pattern
        subgroup of Z256 generated by 480/16 = 30 has 128 elements
        the inner loop has 32 iterations, the blocks loaded in a iteration survives to the next
        all four ints loaded by a cache miss will be read before the block is overwritten
        miss rate will be approximately 25%
simulation results:
sumA, N = 64, miss rate: 1024/4096
sumA, N = 60, miss rate: 900/3600
sumB, N = 64, miss rate: 4096/4096
sumB, N = 60, miss rate: 900/3600
sumC, N = 64, miss rate: 2048/4096
sumC, N = 60, miss rate: 900/3600

6.39
S = 2048 / 32 = 64
A.  assume the cache is write-through, there are 4 * 16 * 16 = 1024 writes in total
B.  as the writes follow stride-1 reference pattern, there will be a cache miss every B/4 writes
    B = 32 and 1 out of 8 writes will miss
    1024 / 8 = 128 misses in total
C.  1/(B/4) = 4/32 = 12.5%

6.40
A.  again 1024
B.  the writes to structures in the array follows a stride-256 reference pattern (16 * sizeof(point_color))
    256 / 32 = 8, 64 / gcd(64, 8) = 8, a block will be overwritten 8 iterations later
    the other structure in the same block will only be read in the next inner loop, which is 16 iterations later
    therefore every struct causes a cache miss, but the 4 fields of the struct still can be read at once
    1024 / 4 = 256 misses in total
C.  miss rate approximately 25%

6.41
A.  again 1024, 256 in the first loop, 768 in the second
B.  the first loop is a stride-16 reference pattern
    B / 16 = 2, half the reads in this loop will miss
    the second loop loads 2 structures into the cache for each miss, 6 fields are read then
    256 / 2 + 768 / 6 = 256 misses in total 
C.  miss rate approximately 256 / 1024 = 25%

6.42
buffer is aligned and the block has the same size as the structure
no matter referenced in which order, a cache miss loads a single structure into the cache, 4 fields of it are read then
miss rate 25%

6.43
stride-1 reference pattern, similar to the previous one, 25% miss rate

6.44
this time a single write will write 4 bytes of data, which is a whole block
miss rate 100%

6.45
Clock frequency is approx. 1000.0 MHz
Memory mountain (MB/sec)
	s1	s2	s3	s4	s5	s6	s7	s8	s9	s10	s11	s12	s13	s14	s15	
128m	6124	3437	2269	1675	1236	1005	836	718	668	632	596	563	544	522	512	
64m	6184	3436	2290	1674	1244	1005	839	730	676	630	590	562	545	528	517	
32m	6110	3439	2287	1682	1244	1009	837	730	676	624	590	556	540	522	510	
16m	6112	3422	2347	1689	1273	1009	845	732	677	644	609	565	545	551	545	
8m	6378	3764	2473	1800	1380	1013	937	814	763	726	694	671	668	669	695	
4m	6731	3971	2779	2026	1421	1197	1257	1169	1073	1090	1034	1061	1022	1067	1236	
2m	7425	5341	4107	3042	2477	2200	1951	1864	1805	1749	1724	1692	1581	1538	1555	
1024k	8196	5746	4533	3436	2903	2546	2244	1988	1939	1891	1794	1762	1749	1733	1724	
512k	8657	6039	4639	3439	2906	2542	2237	1988	1940	1904	1879	1851	1854	1879	1909	
256k	9985	7384	6323	5072	4111	3544	3120	2765	2714	2695	2719	2703	2851	2981	3209	
128k	11182	8973	8794	7528	6178	5217	4574	4057	3994	4021	4029	4026	3996	4003	3995	
64k	11178	9002	8833	7710	6394	5453	4709	4121	4104	4137	4166	4057	4139	4985	8212	
32k	13347	13003	12941	12412	12388	12327	11417	11770	11447	12089	12057	11471	11150	11090	10812	
16k	13342	12526	12583	12190	12224	11767	11250	10449	10520	10993	10199	9750	9844	9141	9176	
L1: ~32k
L2: ~128k
L3: ~2m

6.46
./CSAPP/cache
$ cargo test --benches --release
running 3 tests
test transpose_bench_blocking ... bench:      79,836 ns/iter (+/- 31,510)
test transpose_bench_ordinary ... bench:      74,891 ns/iter (+/- 24,914)
test transpose_bench_rawptr   ... bench:     111,000 ns/iter (+/- 28,793)
the version using raw pointers to access arrays get automatically unrolled 8-way
    movl (%rbx), %ecx
    movl %ecx, (%rax)
    movl 4(%rbx), %ecx
    movl %ecx, (%rax,%r12)
    addq %r12, %rax
    ...
    movl 28(%rbx), %ecx
    movl %ecx, (%r12,%rax)
    addq %r12, %rax
    addq $32, %rbx
    addq %r12, %rax
unrolling in this case will not improve the performance (no arithmetic, only independent loads and stores)
while the ordinary verison, surprisingly, is compiled to a procedure logically similar to the raw pointer version
    movl (%rdx,%rax,4), %ebx
    movl %ebx, (%rdi,%rsi,4)
    incq %rax
    addq %r8, %rsi
    cmpq %r8, %r14
    jb .LBB0_4
the relation between source and assembly in Rust is not as clear as in C

6.47
the slightly more general form of transposing can be defined as
    void g_transpose(int *dst, int *src, int dim, int (*op)(int, int)) {
        int i, j, s, d;
        for (i = 0; i < dim; i++) {
            for (j = 0; j < dim; j++) {
                s = &src[i * dim + j];
                d = &dst[j * dim + i];
                *d = (*op)(*s, *d);
            }
        }
    }
and the normal transpose is derived by
    int fst(int s, int d) {
        return s;
    }
    void transpose(int *dst, int *src, int dim) {
        g_transpose(dst, src, dim, fst);
    }
col_convert is derived by
    int or(int s, int d) {
        return s || d;
    }
    void col_convert(int *G, int dim) {
        g_transpose(G, G, dim, or);
    }
the optimization of transpose can be applied directly to g_transpose, hence col_convert

Chapter 7
7.1
buf     Y   extern  main.o  .data
bufp0   Y   global  swap.o  .data
bufp1   Y   global  swap.o  .bss 
swap    Y   global  swap.o  .text
temp    N   -       -       -

7.2
A.  REF(main.1) --> DEF(main.1)
    REF(main.2) --> DEF(main.1)
B.  ERROR, two strong symbols
C.  REF(x.1) --> DEF(x.2)
    REF(x.2) --> DEF(x.2)

7.3
A.  ld p.o libx.a
B.  ld p.o libx.a liby.a
C.  ld p.o libx.a liby.a libx.a p.o

7.4
A.  0x80483bb
B.  0x0000009
C.  won't change, it's PC relative

7.5
A.  otherwise the load won't know where to start execution
B.  call to _exit is already in crt1.o, which is linked to every C program

7.6
buf     Y   extern  main.o  .data
bufp0   Y   global  swap.o  .data
bufp1   Y   local   swap.o  .bss
swap    Y   global  swap.o  .text
temp    N   -       -       -
incr    Y   local   swap.o  .text
count   Y   local   swap.o  .data

7.7
double x;
void f() {
    x = x;
}

7.8
A.  main.2 is not global
    REF(main.1) --> DEF(main.1)
    REF(main.2) --> DEF(main.2)
B.  unknown, two weak symbols
C.  ERROR, two strong symbols

7.9
as main.bar6 is a weak symbol, REF(main.bar6) --> DEF(main.foo6)
an implicit type casting (void (*)(void)) -> char is performed, and the last two hex digits of pointer main is printed

7.10
A.  ld p.o libx.a p.o
B.  ld p.o libx.a liby.a libx.a
C.  ld p.o libx.a liby.a libz.a libx.a

7.11
thanks https://github.com/DreamAndDead/CSAPP-3e-Solutions/blob/master/chapter7/7.11.md
0xe8 is the size of the .data section
0x104 is the size of .data and .bss section

7.12
bufp0   line3   0x3     0x0
buf[1]  line5   0x8     0x4
bufp1   line8   0x10    0x0
bufp1   line15  0x1f    0x0

7.13
A.  0x12: R_386_PC32 p3
    0x19: R_386_32 xp
    0x21: R_386_PC32 p2
B.  0x4: R_386_32 x

7.14
A.  0x11: R_386_32 .rodata
B.  0x0: R_386_32 relo3+0x28
    0x4: R_386_32 relo3+0x15
    0x8: R_386_32 relo3+0x25
    0xc: R_386_32 relo3+0x18
    0x10: R_386_32 relo3+0x18
    0x14: R_386_32 relo3+0x20

7.15
there's no libc.a in modern osx
from the result of
    cat /usr/include/libc.h | grep "#include" | wc -l
there may be 27 object files in what's equivalent to a libc.a

Chapter 8
8.1
AB  y
AC  n 
BC  y

8.2
A.  printf1: x=2
    printf2: x=1
B.  printf2: x=0

8.3
abcc
bacc

8.4
A.  6
B.  Hello
    0
    1
    Bye
    2
    Bye

8.5
./CSAPP/ecf

8.6
./CSAPP/ecf

8.7
thanks CSAPP2e
./CSAPP/ecf

8.8
213

8.9
AB  n
AC  y 
AD  y
BC  y 
BD  y 
CD  y

8.10 
A.  fork
B.  execve, longjmp
C.  setjmp

8.11
4

8.12
8

8.13
x=2 // from child, line 10
x=4 // from parent, line 8
x=3 // from parent, line 10

8.14
3

8.15
5

8.16
counter = 2
a child process will get its own copy of virtual memory, including global variables in .data section

8.17
(parent)
Hello
(child) (parent) // two processes running concurrently, outputs may interleave in arbitrary way
1       0
Bye
(parent)
2

8.18
parent -> child1, child2
child2 -> child3
(parent)    (child1)    (child2)    (child3)
                        0           0       // printf("0"); at line 13
1           1                               // printf("1"); at line 15
            2                       2       // printf("2"); in end  
A.  1(p)-12(c1)-0(c2)-02(c3)
B.  impossible, 2 must follow 1 or 0
C.  1(p)-02(c3)-12(c1)-0(c2)
D.  impossible, the second 2 must be the fourth or later output
E.  1(p)-0(c2)-02(c3)-12(c1)

8.19
2^n

8.20
thanks https://docs.rs/nix/0.10.0/nix/unistd/fn.execve.html
./CSAPP/ecf

8.21
abc; bac

8.22
./CSAPP/ecf

8.23
signals are not queued

8.24
// nowhere implemented strerror or strsignal, neither repl.it or other online compiling services
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>
#include <errno.h>
#include <signal.h>
#define N 2
int main(void) {
  int status, i;
  pid_t pid;
  for (i = 0; i < N; i++) {
    if ((pid = fork()) == 0) {
      char *text = (char *) main;
      *text = '1';
      exit(100+i);
    }
  }
  while (waitpid(-1, &status, 0) > 0) {
    if (WIFEXITED(status))
      printf("child %d terminated normally with exit status=%d\n", pid, WEXITSTATUS(status));
    if (WIFSIGNALED(status)) {
      int sig = WTERMSIG(status);
      char desc[128];
      sprintf(desc, "child %d terminated by signal %d", pid, sig);
      psignal(sig, desc);
    }
  }
  if (errno != ECHILD) {
    fprintf(stderr, "waitpid error: %d", errno);
  }
  exit(0);
}

8.25
#include <stdio.h>
#include <signal.h>
#include <unistd.h>
#include <setjmp.h>
static sigjmp_buf env;
void handler(int sig) {
  longjmp(env, 1);
}
char *tfgets(char *s, int n, FILE *stream) {
  signal(SIGALRM, handler);
  alarm(5);
  if (setjmp(env) == 0) {
    char *s_indicator = fgets(s, n, stream);
    alarm(0);
    return s_indicator;
  } else {
    return NULL;
  }
}

8.26
-

Chapter 9
9.1
8   256B    255
16  64K     65535
32  4G      4294967295
48  256T    2^48 - 1
64  16E     2^64 - 1

9.2
16  4K  2^4 = 16
16  8K  2^3 = 8
32  4K  2^20 = 1M
32  8K  2^19 = 512K

9.3
1K  22  10  14  10
2K  21  11  13  11
4K  20  12  12  12
8K  19  13  11  13 

9.4
A.  0x03d7 = 0b0011-11-010111
B.  VPN:        0x0f
    TLBI:       0x3
    TLBT:       0x3
    TLB hit:    y
    page fault: n
    PPN:        0x0d
C.  0b001101-0101-11
D.  CO:         0x3
    CI:         0x5
    CT:         0xd
    Cache hit:  y
    Return:     0x1d

9.5
./CSAPP/vm

9.6
malloc(1)   8   0x9
malloc(5)   16  0x11
malloc(12)  16  0x11
malloc(13)  24  0x19

9.7
12B, 4B header || 4B payload || 4B footer
8B, 4B header || 4B payload
16B, 4B header || 8B payload || 4B footer
8B, 4B header || 4B payload

9.8 - 9.9
./CSAPP/vm/src/mm.rs

9.10
since with simple segregated free lists blocks are never coalesced
if an application 
    1.  allocates and frees a lot of small objects
    2.  allocates and frees only much bigger objects then
then all the small blocks allocated in step 1 will never be reused

9.11
A.  0b000010-01-111100
B.  VPN:            0x9
    TLBI:           0x1
    TLBT:           0x2
    TLB hit:        n
    page fault:     n
    PPN:            0x17
C.  0b010111-1111-00
D.  CO:             0x0
    CI:             0xf
    CT:             0x17
    Cache hit:      n
    return byte:    -

9.12
A.  0b000011-10-101001
B.  VPN:            0xe
    TLBI:           0x2
    TLBT:           0x3
    TLB hit:        n
    page fault:     n
    PPN:            0x11
C.  0b010001-1010-01
D.  CO:             0x1
    CI:             0xa
    CT:             0x11
    Cache hit:      n
    return byte:    -

9.13
A.  0b000000-01-000000
B.  VPN:            0x1
    TLBI:           0x1
    TLBT:           0x0
    TLB hit:        n
    page fault:     y

9.14
./CSAPP/vm

9.15
8       0x00000009
16      0x00000011
24      0x00000019
32      0x00000021

9.16
16
16
16
16

9.17 - 9.18
./CSAPP/vm/src/mm.rs

9.19
1.  a:  true, if all allocations are malloc(2^n + 1), a buddy system have to allocate blocks of size 2^(n+1) bytes each
    b:  false, best-fit have to analyse the size of all the free blocks for each allocation
        while first-fit stops when a fit is find, twice as fast as best-fit on average
    c:  false, with boundary tags deallocation is constant time
    d:  false, external fragmentation in C is is unavoidable
2.  a:  false, it will have high performance and severe external fragmentation
        performance will be good (constant time), if the first free block doesn't fit then more memory is needed
        for repeating small mallocs, big free blocks will be wasted on small data, or splited into small free blocks
    b:  false, the order doesn't matter that much with best-fit
    c:  false, smallest
    d:  true
3.  a:  false, coalescing is not performed by GC
    b:  true
    c:  false, most modern GC scans memory periodically, conservative or not
    d:  false, they do if no root node points to the cyclic list of memories

9.20
-

Chapter 10
10.1
the smallest file descriptor available to this program
after FILENO_STDIN, FILENO_STDOUT and FILENO_STDERR, fd2 == 3

10.2
c = f
the file is opened twice, two file descriptors with independent file offsets starting from 0
both read will read the first character in the file

10.3
c = o 
parent and child processes share the same file table
the first Read(fd, &c, 1) increments file offset by 1, the second read then reads the second character in foobar.txt

10.4
dup2(5, FILENO_STDIN)

10.5
c = o
Read(fd2, &c, 1) increments file offset of fd2 by 1
Dup2(fd2, fd1) overwrites fd1 with entries of fd2, including file offset
Read(fd1, &c, 1) then reads the second character in foobar.txt into c

10.6
fd2 = 4
stdin, stdout, stderr, foo.txt and baz.txt are opened at line 11
fd2 points to baz.txt, which is the fifth file

10.7
./CSAPP/rio

10.8
./CSAPP/rio

10.9
int fd = open("foo.txt", O_RDONLY);
dup2(fd, STDIN_FILENO);

10.10
./CSAPP/rio

Chapter 11
11.1
0.0.0.0
255.255.255.255
127.0.0.1
0xcdbca015
0x400c950d
0xcdbc9217

11.2 - 11.3
./CSAPP/network

11.4
offical hostname: google.com.
address: 172.217.24.14
address: 2404:6800:4012::200e
A.  ipv4 first, ipv6 second
B.  ?

// web server in C
// chapter skipped

Chapter 12
12.1
when Fork() is called, the child process get its own copy of file descriptor table
all file entries in open file table have their ref count incremented by 1
after parent process called Close(connfd), the ref count of connfd is still positive

12.2
when a process is terminated, the ref counts of files in its file descriptor table is automatically decremented
so calling exit(0) is equivalent to calling Close(fd) with all file descriptors currently opened in the child process

12.3
when stdin is at eof, it will never be possible to read more bytes from it (eof is not a character)
all read requests to stdin will immediately return 0, indicating no byte is read
thus a request to read 1 byte from stdin will never block
select will always return immediately with STDIN_FILENO set in fdset

12.4
select will modifiy this argument

12.5
peer threads, unlike child processes, will not receive a whole copy of stack, heap and file descriptor table
they share the same memory space with the main thread
which means the reference counts will not be incremented when a peer thread is spawned
therefore a file descriptor only has to be closed once, and only peer threads know when it's no longer needed

12.6
A.  ptr     y   y   y
    cnt     n   y   y
    i.m     y   n   n   // call by value, copied not not shared
    msgs.m  y   y   y
    myid.p0 n   y   n
    myid.p1 n   n   y
B.  ptr, cnt, msgs.m

12.7
1 1 H1  —   —   0   
2 1 L1  0   -   0
3 2 H2  0   -   0
4 2 L2  0   0   0
5 2 U2  0   1   0
6 2 S2  0   1   1
7 1 U1  1   1   1
8 1 S1  1   1   1
9 1 T1  1   1   1
10 2 T2 1   1   1
incorrect

12.8
A.  safe 
B.  unsafe
C.  safe

12.9
A.  necessary, a produceer must block if
    1.  the buffer is full, protected by sp.slots
    2.  the consumer is accessing the buffer, protected sp.mutex
    same as the consumer
B.  invariant: sp->slots + sp->items == 0
    not necessary, a producer must block if
    1.  the buffer is full, protected by sp.slots
    2.  the consumer is accessing the buffer
        the consumer may only access the buffer if: sp->items == 1, which means sp->slots == 0
        at the end of sbuf_remove, the consumer will increment sp->slots to 1
        when sp->slots == 1, sp->items == 0 and the consumer will block, cannot access the buffer
        therefore P(&sp->slots) has the same effect as P(&sp->mutex)
    symmetrically the consumer
C.  necessary
    more than one producers/consumers may try to access the buffer at the same time
    the mutex makes sure that only one producer/consumer has access, thereby prevents inconsistent states

12.10
a writer arrives first, then a stream of readers, writer accquires semaphore w
then a stream of writers arrives, and the kernel always chooses another writer to run next

12.11
1.  Sp = 1
2.  Ep = 75%
3.  Sp = 3

12.12
privatep can be a shared variable
if privatep == shardp, then this function is equivalent to thread-unsafe ctime

12.13
when peer thread reaches line 24, ptr may already be freed in the main thread

12.14
A.  pass by value instead of by reference
B.  infeasible when the argument is a big structure
    or for arguments of dynamically sized types like strings

12.15
A.  (1,0)   (0,0)   (1,0)   (1,-1)  (1,0)
    (1,-1)  (0,-1)  (1,-1)  (1,-2)  (1,-1)
    (1,0)   (0,0)   (1,0)   (1,-1)  (1,0)
    (0,0)   (-1,0)  (0,0)   (0,-1)  (0,0)
    (1,0)   (0,0)   (1,0)   (1,-1)  (1,0)
B.  initially t = 0, so both threads will block at P(t)
C.  t = 1
D.  (1,1)   (0,1)   (1,1)   (1,0)   (1,1)
    (1,0)   (0,0)   (1,0)   (1,-1)   (1,0)
    (1,1)   (0,1)   (1,1)   (1,0)   (1,1)
    (0,1)   (-1,1)  (0,1)   (0,0)   (0,1)
    (1,1)   (0,1)   (1,1)   (1,0)   (1,1)

12.16
./CSAPP/conc

12.17
A.  when the main process exits, all peer threads are immediately terminated
B.  Pthead_join(tid, NULL);

12.18
A.  unsafe 
B.  safe
C.  unsafe 

12.19
check if readcnt == 0 at the beginning of writer, skip the current iteration if not
this may raise cpu intensity as the condition is constantly been checked
may be improved with condvar, which blocks the thread on certain conditions

12.20
sem_t mutex;    // initially 1
sem_t slot;     // initially N
void reader(void) {
    while (1) {
        P(&slot);
        P(&mutex);
        // critical
        V(&mutex);
        V(&slot);
    }
}
void writer(void) {
    while (1) {
        P(&mutex);
        // critical
        V(&mutex);
    }
}

12.21
basically 12.19 but switching the role of reader and writer
read_cnt -> write_cnt
writer increments write_cnt on acquiring mutex, decrements on release
first writer in the queue locks a mutex r
last writer in the queue unlocks r
reader checks write_cnt == 0 at the beginning of the loop, skip current iteration if not

12.22
change two ifs to a if .. else if .. clause

12.23
handle echo in a peer thread

12.24
no, these functions accepts pointers to rio_t and buffers, which may points to shared memory

12.25
it's thread-safe, accesses to the global variable byte_cnt is protected by a mutex
it's not reentrant as byte_cnt is shared

12.26
./CSAPP/conc/gethostbyname_ts.c

12.27
thanks https://github.com/DreamAndDead/CSAPP-3e-Solutions/blob/master/chapter12/12.27.md
fdopen(fd, mod) opens a stream associated to a file descriptor fd
calling fclose on any stream associated to a file descriptor will close the file descriptor as well (why?)
after fclose(fpin), fpout still associates to the already closed descriptor sockfd
calling fclose(fpout) will fail and usually cause no harm
but when a thread started after another called fclose(fpin), the underlying descriptor sockfd will be reused
and while the first thread is still running, the second thread then calls fclose(fpout)
sockfd is closed again and cause hazards in the first thread

12.28
it will not deadlock according to mutex lock ordering rule

12.29
it cannot deadlock, thread 1 does not hold b and c simultanously
a is not present in thread 2 and can be ignored
by mutex lock ordering rule it's deadlock-free

12.30
A.  1:  (a, b), (a, c)
    2:  (c, b) 
    3:  (b, a)
B.  thread 2 and 3
C.  unclear how to adjust the lock ordering while maintaining the semantics (if any)
    assuming variable rewrite
    thread 2:
        P(b)
        P(c)
        V(c)
        V(b)
        P(a)
        V(a)
    thread 3:
        P(c)
        V(c)
        P(a)
        P(b)
        V(b)
        V(a)


12.31 - 12.33
raw process and select function not present in safe Rust
implemented with thread and channel instead
./CSAPP/conc/src/tfgets.rs

12.34
./CSAPP/conc

12.35 - 12.37
// skipped

12.38
./CSAPP/conc/src/tiny.rs