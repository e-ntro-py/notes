// Whenever possible, programming homeworks will be done in Rust instead of C.

4. The Abstraction: The Process
section 4.5, starting from Oct 2008, struct context in xv6 is:
    struct context {
        uint edi;
        uint esi;
        uint ebx;
        uint ebp;
        uint eip;
    };
ecx and edx are caller saved, esp the stack pointer is encoded in the address of the context, none
of them has to be saved explicitly

Questions
4.1
100%, no process issues IO, unless the kernel intentionally blocks execution for no reason the cpu
will always be assigned to a ready process 

4.2
// length of the IO operation determined by -L includes the tick in which the IO operation is
// issued, an IO operation of length 5 issued at tick 1 is finished at the start of tick 6, the
// entirety of tick 6 may be scheduled to some other process, but the IO operation is still only
// considered as complete at tick 6, not tick 5
10 cycles: 
    PID 0 is run to completion (4 cycles), context switch to PID 1
    PID 1 issues IO (1 cycle) 
    PID 1 blocks on IO (4 + 1 cycles, + 1 since the process is considered complete at tick 10)

4.3
6 cycles:
    PID 0 issues IO (1 cycle), blocks on IO, context switch
    PID 1 is run to complete (4 cycles)
    PID 0 blocks on IO (1 + 1 cycle)
The scheduler is not preemptive, a process will not be de-scheduled unless it invoked a syscall 

4.4
9 cycles:
    PID 0 issues IO (1 cycles)
    PID 0 blocks on IO (4 cycles), context switch at start of tick 5
    PID 1 runs to completion (4 cycles)

4.5
same to 4.3

4.6
27 cycles:
    PID 0 issues IO (1 cycle), context switch to PID 1
    PID 1 runs to completion (5 cycles), context switch to PID 2
    PID 2 runs to completion (5 cycles), context switch to PID 3
    PID 3 runs to completion (5 cycles), context switch to PID 0
    PID 0 issues IO (1 cycle)
    PID 0 blocks on IO (4 cycles)
    PID 0 issues IO (1 cycle)
    PID 0 blocks on IO (4 + 1 cycles)

4.7
18 cycles:
    PID 0 issues IO (1 cycle), context switch to PID 1
    PID 1 runs to completion (5 cycles), context switch to PID 0
    PID 0 issues IO (1 cycle), context switch to PID 2
    PID 2 runs to completion (5 cycles), context switch to PID 0
    PID 0 issues IO (1 cycle), context switch to PID 3
    PID 3 runs to completion (5 cycles)
A process issued an IO operation is likely to issue more in near future (e.g. keyboard press in a
document processing software, mouse click in a GUI), immediately switch back to the process after IO
completion increases utilization of the IO device and CPU as well as responsiveness to user input.
In modern preemptive OS an IO heavy process may be assigned higher priority, compared to computation
bounded processes it will be scheduled more frequently but with smaller time quantum each time. 

4.8
in general, -I IO_RUN_IMMEDIATE should be roughly more efficient than -I IO_RUN_LATER, -S
SWITCH_ON_IO should be strictly more efficient than -S SWITCH_ON_END

Remaining questions: 
- after control being yielded to user process, how could a process be preempted without invoking
  syscalls by itself? (A: with interruption tied to a physical timer)

5.Interlude: Process API
wait() will return prematurely when:
    - the argument (*stat_loc) is not a proper pointer or NULL
    - the child process is stopped (not terminated) by a signal, in which case it can be restarted
      later

meaning of suffixes of exec:
    - l: variadic functions accepting arbitrary number of arguments as arguments to the program
    - p: search program in PATH environment variable
    - v: arguments
    - e: environment variables
    
Questions 
5.1
./ostep/chapter_5/q1.c
Fork() copies the entire state of the parent process to the child process, x as an auto variable on
the stack or in register is copied to the child process with the initial value 100. After that x in
child and parent processes are two different entities hence modification to them does not interfere
with each other.

5.2
./ostep/chapter_5/q2.c
the file descriptor is available to both parent and child processes, write from the parent process
always seems to happen before write from the child process, maybe fork() returns earlier to the
parent process compared to the child?

5.3
./ostep/chapter_5/q3.c
the parent process can sleep for a long enough duration, the two processes may communicate with some
form of shared memory, pipe, lock or signal, above all wait() still is the most natural way to
express this pattern.

5.4
./ostep/chapter_5/q4.c
All variants of exec are built upon a single syscall `execve`. At the beginning the C programming
language was an implementation detail of UNIX system, in the 80s C gained popularity among various
vendors despite having no standard and kept evolving that way even after ANSI C. UNIX before Linux
is a blanket term for a dozen competing incompatible operating systems. The current state of exec
variants may be an effort to maintain backward compatibility with all of them.

5.5
./ostep/chapter_5/q5.c
On success wait() returns process id of the terminated child. When the process calling wait() has no
child process ECHILD is assigned to the global variable errno.

5.6
./ostep/chapter_5/q6.c
Parent process block on the termination of a selected child process instead of any one of them.
Behavior of the function may be modified by the additional options argument, e.g. return immediately
when there's no terminated child process. 

5.7
./ostep/chapter_5/q7.c
printf() silently succeeds without actually printing anything to stdout.

5.8
./ostep/chapter_5/q8.c

6. Mechanism: Limited Direct Execution
Measurement (in WSL)
syscall:
    ./ostep/chapter_6/measure_syscall.c
    getpid(), 48 nanoseconds
context switch:
    ./ostep_chapter_6/measure_switch.c
    20 microseconds (without sched_setaffinity)
    1 microsecond (with sched_setaffinity)

7. Scheduling: Introduction
Proofs of the optimality of SJF and STCF can be found in problem 16-2 of introduction to algorithms

Questions
7.1
SJF:
    avg. turnaround: (200 + 400 + 600)/3 = 400
    avg. response: (0 + 200 + 400)/3 = 200
FIFO:
    same to SJF

7.2
SJF:
    avg. turnaround: (100 + 300 + 600)/3 = 333.33
    avg. response: (0 + 100 + 300)/3 = 133.33
FIFO:
    same to SJF

7.3
RR, same length:
    avg. turnaround: (598 + 599 + 600)/3 = 599
    avg. response: (0 + 1 + 2)/3 = 1
RR, different lengths:
    avg. turnaround: (298 + 499 + 600)/3 = 465.67
    avg. response: (0 + 1 + 2)/3 = 1

7.4
jobs ordered by ascending length, in other cases FIFO is not optimal

7.5
all except the longest job must be shorter than the quantum length:
    if there's two jobs with lengths longer than quantum length, no matter what is scheduled first
    the other will has a longer response time than in RR

7.6
response time in SJF is linear in job lengths
p./scheduler.py -p SJF -j 3 -l 3,2,1 -c
    Average -- Response: 1.33  Turnaround 3.33  Wait 1.33
p./scheduler.py -p SJF -j 3 -l 30,20,10 -c
    Average -- Response: 13.33  Turnaround 33.33  Wait 13.33
p./scheduler.py -p SJF -j 3 -l 300,200,100 -c
    Average -- Response: 133.33  Turnaround 333.33  Wait 133.33

7.7
response time with RR is linear in quantum length
let quantum length be T_q, worst response time is:
    (N - 1)T_q
    
8. Scheduling: The Multi-Level Feedback Queue
Questions
8.1
./mlfq.py -j 2 -n 2 -c -m 50 -M 0

8.2
Example 1: A Single Long-Running Job
    ./mlfq.py -n 3 -q 10 -l 0,200,0 -c
Example 2: Along Came A Short Job
    ./mlfq.py -n 3 -q 10 -l 0,200,0:100,20,0 -c
// io frequency is defined as "number of CPU ticks between two IO requests" in the simulator 
Example 3: What About I/O?
    ./mlfq.py -S -n 3 -q 10 -l 0,200,0:100,20,1.1 -c
Attempt #2: The Priority Boost
    without boost:
    ./mlfq.py -n 3 -q 10 -S -I -i 1 -l 0,200,0:100,50,1:100,50,1 -c
    with boost:
    ./mlfq.py -n 3 -q 10 -S -B 100 -I -i 1 -l 0,200,0:100,50,1:100,50,1 -c
Attempt #3: Better Accounting
    without allotment accounting:
    ./mlfq.py -q 10 -S -i 1 -l 0,200,0:100,100,9 -c
    with allotment accounting:
    ./mlfq.py -q 10 -i 1 -l 0,200,0:100,100,9 -c
Tuning MLFQ And Other Issues
    ./mlfq.py -Q 10,20,40 -l 0,140,0:0,140,0 -c

8.3
one queue, no allotment accounting, no IO reset
./mlfq.py -n 1 -j 10 -c -m 20

8.4
./mlfq.py -q 100 -S -i 1 -l 0,10000,99:0,10000,0 -c

8.5
200ms, assume after each boost the job will be run at least once (i.e. the system is not crowded
with high priority jobs)

8.6
lower response time in sacrifice of IO throughput. In CFQ (the default Linux IO scheduler between
2.6 - 5.0) the scheduler will introduce an artificial delay after an IO request in hope to catch more
IO requests from the same process to be performed in batch. Such a mechanism is majorly meaningless
with an SSD. CFQ was then removed from Linux in 5.0.

[B+18] “The Battle of the Schedulers: FreeBSD ULE vs. Linux CFS”
additional details of CFS: 
    - fairness is ensured among applications instead of threads
    - a new thread is created with maximum vruntime in the queue
    - a thread waking up doesn't preempt the current thread if the vruntime is close enough
    - threads are distributed to CPUs by their utilizations 
    - load balancing happens every 4ms, cores steal threads from each other

9. Scheduling: Proportional Share
Weighting (Niceness), logarithm of prio_to_weight is roughly linear, i.e.
    log(Wi) - Log(Wj) ~ i - j
    e^(log(Wi) - log(Wj)) ~ e^(i - j)
    Wi / Wj ~ e^(i - j)
    
Remaining questions:
    - how are these dynamic data structures, especially the priority queue in stride scheduling
      implemented in the kernel where dynamic allocation is not taken as given? (A: kernel has its
      own heap and heap allocator)

Questions
9.1
// too long, omitted 

9.2
Job 0 has 1% chance to be run before completion of job 1. With such imbalance in ticket distribution
the scheduler is no longer fair or even preemptive.

9.3
Finish time T of the first job is governed by the negative binomial distribution with a constraint
    X ~ NB(100, 0.5), X <= 200 
    E[X] = Σ_{k = 0}^100 C(k + 100, k) * 0.5^100 * 0.5^k * (100 + k)
By WolframAlpha the expectation is around 189.67, expected fairness is 189.67/200 = 0.95

9.4
fairness decreases as quantum increases, when -q 2 the distribution is equivalent to
    X ~ NB(50, 0.5), X <= 100
    E[X] = 92.96, fairness = 0.93
when -q 5,
    X ~ NB(20, 0.5), X <= 40
    E[X] = 35.86, fairness = 0.90
when -q 10,
    X ~ NB(10, 0.5), X <= 20
    E[X] = 17.30, fairness = 0.87
when -q 100, the first job runs to completion before the start of the other, fairness = 0.5

9.5
The unfairness by low resolution impacts stride scheduler as well but the difference between finish
time will be limited to one quantum. Another interesting topic would be the balance between
resolution and scheduling efficiency, which is beyond the capacity of this simulator.

10. Multiprocessor Scheduling
Questions
10.1
30 ticks, no other threads competing for CPUs, the cache is too small for the job to run efficiently

10.2
20 ticks, 10 cold tick and 10 warm ticks

10.3
the job runs twice as fast in warm mode, as the default value of -r.

10.4
by the trace
    9   a [ 20] cache[w]
the cache was warmed at the end of 10th tick, as the default value of -w.

10.5
150 ticks, the jobs are scheduled as
    CPU 0   ACBA...
    CPU 1   BACB...
as A has a working set as big as the cache, it invalidates all previous content in the cache, hence
no jobs are running in warm mode ever.

10.6
(10 + 90/2) * 2 = 110 ticks, this time a, b and c run in warm mode after the first 10 ticks, where b
and c shares the same CPU, the current affinity is the only one where
    1.  all CPUs are working
    2.  all working sets fit in the cache
therefore there's no other affinity setting that runs faster than the current one.

10.7
-M 50
    -n 1: 300 ticks
    -n 2: 150 ticks
    -n 3: 100 ticks
-M 100
    -n 1: 300 ticks
    -n 2: 150 ticks
    -n 3: 55 ticks
only with -M 100 -n 3 every job will run in warm mode, 10 + (90 / 2) = 55 ticks

10.8
100 ticks instead of 110, CPU utilization is slightly better
with no job stealing (-P 0) the running time is 200 ticks, with more job stealing (-P 1) the running
time improves slightly to 95 ticks as the simulator doesn't account for context switch and lock
costs. Per CPU scheduler scales worse than the single queue round-robin scheduler as the simulator
suggests, yet again because the simulator is over-simplified.

10.9
// omitted

13. The Abstraction: Address Spaces
Questions
13.1
free has an option to print memory in power of 1000 instead of 1024. Unlike HDDs Memory nowadays is
never marketed or discussed in power of 1000, maybe that's not yet an universal agreement back when
free is created.

13.2
WSL doesn't have full access to physical memory, out of 16GB installed 4GB is invisible inside WSL.
100MB used memory among which 2.4MB is reported by top, leaves 97.6MB occupied by the kernel.

13.3
how to use:
    install the x86_64-unknown-linux-musl build target by:
        rustup target add x86_64-unknown-linux-musl
    build with musl target and rust-lld:
        rustc --target x86_64-unknown-linux-musl -C linker=rust-lld memory-user.rs
    run the memory user in background:
        ./memory-user 100 &

13.4
A certain amount of memory is occupied immediately at the beginning of execution, for large
allocations the used amount of memory gradually increases over time. Both case the used memory is
freed the instance the program is killed. A page is only written out after the first write, in this
case by compiler magic the zero-initialization is not treated as a write.

13.5
The behavior of pmap is controlled by a config file (~/.pmaprc by default) instead of command line
arguments. As the format of its output varies more frequent than other UNIX tools it seems to be a
reasonable design.

13.6
// not a question

13.7
result of zsh:
    hundreds of segments, mostly shared libraries and memory mapped files 
    2964K r---- locale-archive  // memory-mapped localized strings used by the system
    2816K rw---   [ anon ]  // heap?
    2364K r--s- Unix.zwc    // auto-completion utilities of unix tools
    316K rw---   [ stack ]  // stack

13.8
result of memory-user:
    10+ segments, no shared libraries, libc and std statically linked 
    00007fde2f299000 16384004K rw---   [ anon ]
    00007fe2172b4000    292K r-x-- memory-user
    00007ffc31960000    136K rw---   [ stack ]

14. Interlude: Memory API
Questions
14.1
segmentation fault

14.2
Program received signal SIGSEGV, Segmentation fault.
0x0000555555555150 in main (argc=1, argv=0x7fffffffd6f8) at null.c:7
7           printf("%u", *ptr);

14.3
==1379== Invalid read of size 4
==1379==    at 0x109150: main (null.c:7)
==1379==  Address 0x0 is not stack'd, malloc'd or (recently) free'd

14.4
gdb didn't find any problem. Report from valgrind:
==1507== 40 bytes in 1 blocks are definitely lost in loss record 1 of 1
==1507==    at 0x483577F: malloc (vg_replace_malloc.c:299)
==1507==    by 0x10914D: main (leak.c:5)

14.5
GDB didn't find any problem. Report from valgrind:
==1727== Invalid write of size 4
==1727==    at 0x10916C: main (q5.c:6)
==1727==  Address 0x4a0e1d0 is 0 bytes after a block of size 400 alloc'd
==1727==    at 0x483577F: malloc (vg_replace_malloc.c:299)
==1727==    by 0x10915D: main (q5.c:5)
This is rather concerning. The allocator must have allocated a memory block larger than requested,
probably the next power of 2 (128 bytes), and GDB as the language agnostic debugger it is didn't
notice the original allocation size in C code.

14.6
GDB didn't find any problem. Report from valgrind:
==1898== Invalid read of size 4
==1898==    at 0x109182: main (q6.c:9)
==1898==  Address 0x4a0e040 is 0 bytes inside a block of size 400 free'd
==1898==    at 0x48369AB: free (vg_replace_malloc.c:530)
==1898==    by 0x10917D: main (q6.c:7)
==1898==  Block was alloc'd at
==1898==    at 0x483577F: malloc (vg_replace_malloc.c:299)
==1898==    by 0x10916D: main (q6.c:6)
Even more concerning. The allocator must didn't immediately return the allocated memory to the
system with brk, rather it reserves the memory for further allocation. GDB again was totally fine
with this illegal access to freed memory. Valgrind, however, hijacks calls to malloc and free to run
on its own allocator, thus had a chance to do more precise memory analysis.

14.7
GDB:
    Starting program: /mnt/d/Software/Textbook/playground/notes/ostep/chapter_14/main
    free(): invalid pointer
Valgrind:
    ==2063== Invalid free() / delete / delete[] / realloc()
    ==2063==    at 0x48369AB: free (vg_replace_malloc.c:530)
    ==2063==    by 0x109171: main (q7.c:6)
    ==2063==  Address 0x4a0e068 is 40 bytes inside a block of size 400 alloc'd
    ==2063==    at 0x483577F: malloc (vg_replace_malloc.c:299)
    ==2063==    by 0x10915D: main (q7.c:5)

14.8
./ostep/chapter_14/q8.c

14.9
... or create a saner interface to heap allocated structures, one that automatically frees the
memory when it's no longer needed, does bound check on each access, tracks the lifetime of the
references so the freed memory cannot be accessed again. Or even better, create a new language in
which these rules are enforced at compilation.

15. Mechanism: Address Translation
Questions 
15.1
-s 0
    0x000001ae --> 0x00003230
    0x00000109 --> 0x0000318b
    0x0000020b --> SIGSIGV
    0x0000019e --> 0x00003220
    0x00000322 --> SIGSIGV
-s 1
    0x0000030e --> SIGSIGV
    0x00000105 --> 0x00003741
    0x000001fb --> SIGSIGV
    0x000001cc --> SIGSIGV
    0x0000029b --> SIGSIGV
-s 2
    0x00000039 --> 0x00003ce2
    0x00000056 --> 0x00003cee
    0x00000357 --> SIGSIGV
    0x000002f1 --> SIGSIGV
    0x000002ad --> SIGSIGV

15.2
max(VA) + 1 = 930, +1 since limit is the length of the segment, limit must be one bigger than the
biggest offset to accommodate all the virtual addresses.

15.3
16 * 1024 - (100 - 1) = 0x00003f9d
irrelevant to virtual addresses, the size of data stored on these addresses are not specified

15.4
// skipped

15.5
fix base register and physical memory size, the expectation of fraction of randomly generated
addresses is exactly
    value of limit register / size of address space 

16. Segmentation
Questions
16.1
for a positively growing segment,
    PA = offset(VA) + base if offset(VA) < limit
for a negatively growing segment,
    PA = base - ((1 << OFFSET_BITS) - offset(VA)) if (1 << OFFSET_BITS) - offset(VA) <= limit
(0 ..= 63) --> Segment 0
(64 ..= 127) --> Segment 1
./segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 0
    VA  0: 0x0000006c (decimal:  108) --> seg 1, 0x000001ec
    VA  1: 0x00000061 (decimal:   97) --> seg 1, SIGSIGV
    VA  2: 0x00000035 (decimal:   53) --> seg 0, SIGSIGV
    VA  3: 0x00000021 (decimal:   33) --> seg 0, SIGSIGV
    VA  4: 0x00000041 (decimal:   65) --> seg 1, SIGSIGV
./segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 1
    VA  0: 0x00000011 (decimal:   17) --> seg 1, 0x00000011
    VA  1: 0x0000006c (decimal:  108) --> seg 0, 0x000001ec
    VA  2: 0x00000061 (decimal:   97) --> seg 1, SIGSIGV
    VA  3: 0x00000020 (decimal:   32) --> seg 0, SIGSIGV
    VA  4: 0x0000003f (decimal:   63) --> seg 0, SIGSIGV
./segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 2
Virtual Address Trace
    VA  0: 0x0000007a (decimal:  122) --> seg 1, 0x000001fa
    VA  1: 0x00000079 (decimal:  121) --> seg 1, 0x000001f9
    VA  2: 0x00000007 (decimal:    7) --> seg 0, 0x00000007
    VA  3: 0x0000000a (decimal:   10) --> seg 0, 0x0000000a
    VA  4: 0x0000006a (decimal:  106) --> seg 1, SIGSIGV

16.2
highest legal virtual address in segment 0
    0x0000013
lowest legal virtual address in segment 1
    0x00001ec
lowest illegal address
    0x000006c
highest illegal address
    0x000006b
// Modified the script to recognize hexadecimal addresses. The script is typical dynamic typed
// madness, the variable called `vStr` may actually be an integer, when instanceof(vStr, int) is
// false the string can be parsed with int(vStr, 0) which infers the base from the prefix.
./segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -A 0x13,0x14,0x6b,0x6c -c

16.3
--b0 0 --l0 2 --b1 (anything >= 4) --l1 2

16.4
SIZE=128;LIMIT=$(($SIZE / 2 * 9 / 10));./segmentation.py -a $SIZE -p 512 -b 0 -l $LIMIT -B 512 -L

16.5
./segmentation.py -a 128 -p 512 -b 0 -l 0 -B 512 -L 0 -c

17. Free-space Management
"The solution is simple: go through the list and merge neighboring chunks; when finished, the heap
will be whole again."
This coalesce algorithm is O(n). A common O(1) solution to the coalesce problem is to write not only
a header, but also a footer to the allocated chunk, hence on freeing a chunk the allocator may
access both the chunks before and after the chunk and perform the necessary coalesce.

[S15] "Understanding glibc malloc" by Sploitfun
---NOTE START---
ptmalloc2, the allocator in glibc since 2006, maintains multiple arenas for different threads, up to
a limit which is 8 * NUMBER_OF_CPU on 64-bit platforms, after that threads have to share arenas as
in the older dlmalloc.

The arena in the main thread is created with sbrk, all other thread arenas are created by mmap. Both
requires more than necessary space from the operating system, also do not return space immediately
to the operating system when it's free'd. Arenas grow whenever a malloc request cannot be fulfilled.

The allocator maintains three kinds of data structures:
    - heap_info: the heap header. There may be multiple heaps (contiguous chunk of memory in virtual
      memory space) in a single arena, as the arena grows overtime as a result of malloc requests,
      the memory under a single arena may not be contiguous. Main thread doesn't have multiple heaps
      (it's memory can always be moved to a larger contiguous chunk with sbrk)
    - malloc_state: the arena header. contains information about bins, top chunk, last remainder
      chunk, etc. For thread arenas malloc_state is part of the heap, while malloc_state of the main
      thread is a global variable of glibc.
    - malloc_chunk: the chunk header. Different type of chunks has different headers.

Small enough chunks (16 - 64 bytes) are kept in their own free lists, or "fast bins" in glibc term.
They are not coalesced nor sorted on free, just goes back the bin they came from. Each bin holds
free chunks of the same size, 8 bytes apart in size from one bin to another.

Chunks of other sizes when free'd are first added to an "unsorted bin", allowing them to be reused
quickly. Small Bins (< 512 bytes) are 8 bytes apart. Large Bins (>= 512 bytes) have exponentially
increasing sizes and chunks in each bin do not have the same size. Both of them are coalesced when
two free chunks are next to each other. 

Chunk at the top border (the last in virtual address, the initial free chunk) is called top chunk,
top chunk is not in any bins, large and top chunks are the only chunks that will be split on user
request. Top chunk is split when there's no other free blocks in any of the bins.

Last Remainder Chunk points to the last free chunk as the result of a split. Last Remainder Chunk is
prioritized in the unsorted bin to serve consecutive small allocations. These requests are more
likely to be allocated next to each other and coalesced back to a single chunk on free if Last
Reminder Chunk is split on consecutive calls to malloc. 
---NOTE END---

Questions
17.1
./malloc.py -n 10 -H 0 -p BEST -s 0
10 operations, no headers, best fit, no coalesce
ptr[0] = Alloc(3)
    return 1000
    List [(1003, 97)]
Free(ptr[0])
    return 0
    List [(1000, 3), (1003, 97)]
ptr[1] = Alloc(5)
    return 1003
    List [(1000, 3), (1008, 92)]
Free(ptr[1])
    return 0
    List [(1000, 3), (1003, 5), (1008, 92)]
ptr[2] = Alloc(8)
    return 1008
    List [(1000, 3), (1003, 5), (1016, 84)]
Free(ptr[2])
    return 0
    List [(1000, 3), (1003, 5), (1008, 8), (1016, 84)]
ptr[3] = Alloc(8)
    return 1008
    List [(1000, 3), (1003, 5), (1016, 84)]
free(ptr[3])
    return 0
    List [(1000, 3), (1003, 5), (1008, 8), (1016, 84)]
ptr[4] = Alloc(2)
    return 1000
    List [(1002, 1), (1003, 5), (1008, 8), (1016, 84)]
ptr[5] = Alloc(7)
    return 1008
    List [(1002, 1), (1003, 5), (1015, 1), (1016, 84)]
the free space is fragmented badly, neighboring free chunks are not coalesced 

17.2
Free list at the end
    [ addr:1000 sz:3 ] [ addr:1003 sz:5 ] [ addr:1008 sz:8 ] [ addr:1016 sz:8 ] [ addr:1033 sz:67 ]
Free space are even more fragmented, the biggest chunk is now 76 bytes instead of 84, other small
fragments increased in size.

17.3
Free space is fragmented much as the BEST strategy but not as bad as WORST. Allocation is still O(n)
but should be much faster than BEST and WORST, allocator no longer has to inspect the entire free
list.

17.4
allocation time comparison
-l ADDRSORT
    FIRST < BEST = WORST
-l SIZESORT+
    FIRST = BEST < WORST
-l SIZESORT-
    FIRST = WORST < BEST

17.5
With no coalesce most allocation in the long run fails, the free space is fragmented to the extreme
that it contains 100 chunks of length 1. With coalesce most allocation still succeeds in long run,
the free list never grows beyond 10 nodes. 

17.6
In theory FIRST fit with SIZESORT+ is equivalent to BEST fit, FIRST fit with SIZESORT- is equivalent
to BEST fit, while ordering should not affect the performance of BEST and WORST by too much (maybe
some minor effect when the order is used to break ties), but the simulator is written in a poor way
that the free space will not be correctly coalesced unless the free list is ordered by ADDRSORT,
both SIZESORT- and SIZESORT+ will cause more fragmentation.

17.7
For any fit strategy and free list order, 
    1.  allocate a series of chunks of size (n + 1) until the free space is totally exhausted
        (assuming the size of free space is a multiple of (n + 1))
    2.  for each chunk allocated at step 1
        - free a chunk of size (n + 1)
        - allocate a chunk of size n 
        - allocate a chunk of size 1
    3.  free all chunks of size n
at the end, only 1/(n + 1) of the free space is used, nevertheless there's no free node with length
longer than n.

18. Paging: Introduction
Questions
18.1
-a ASIZE
    address space size
-P PAGESIZE
    page size
page table size = ASIZE / PAGESIZE
larger pages incur more internal fragmentation

18.2
1k page size, lowest 10 bits are page offset
16k / 1k = 16 = 2^4, highest 4 bits are virtual page number
-u 50
    VA 0x00003385 (decimal:    13189) --> (VPN 12)  0x00003f85
    VA 0x0000231d (decimal:     8989) --> (VPN 8)   INVALID
    VA 0x000000e6 (decimal:      230) --> (VPN 0)   0x000060e6
    VA 0x00002e0f (decimal:    11791) --> (VPN 11)  INVALID
    VA 0x00001986 (decimal:     6534) --> (VPN 6)   0x00007586
more virtual addresses are valid as -u increases

18.3
-P 8 -a 32 -p 1024 -v -s 1
    page size too small, virtual address space too small compared to physical address space, most of
    physical address space is not addressable from a single process
-P 8k -a 32k -p 1m -v -s 2
    nothing different, only the page size is more reasonable
-P 1m -a 256m -p 512m -v -s 3
    overall reasonable, page size too large for light threads

18.4
-a 32k -p 16k
    Error: physical memory size must be GREATER than address space size (for this simulation)
-p 2g
    Error: must use smaller sizes (less than 1 GB) for this simulation.
-a 5k
    Error in argument: address space must be a power of 2
-P 5k
    Error in argument: page size must be a power of 2
-a 2k -P 4k
    // page size should not be greater than virtual address space size, didn't catch the error 

19. Paging: Faster Translations (TLBs)
Questions
19.1 
Instant::now() timer in Rust std, backed by clock_gettime(CLOCK_MONOTONIC) on Linux. The resolution
reported by clock_getres() is 1ns, but after that much patches to Spectre and other vulnerabilities
there's no way any system timer can still have sub-microsecond precision. Without any knowledge of
the deviation of the timer nor the memory operation I'd say at least a few thousand iterations would
be necessary.

19.2
how to use:
    install the x86_64-unknown-linux-musl build target by:
        rustup target add x86_64-unknown-linux-musl
    build with musl target and rust-lld:
        rustc --target x86_64-unknown-linux-musl -C linker=rust-lld -O -o tlb-musl tlb.rs
    run in linux:
        ./tlb-musl NUM_OF_PAGES PEPEAT
    build on windows:
        rustc --target x86_64-pc-windows-msvc -O -o tlb-msvc tlb.rs
    run in windows:
        ./tlb-msvc NUM_OF_PAGES PEPEAT

19.3
how to use:
    // depends on /bin/bash
    ./run.sh PATH_TO_EXEC
5000 trials seems to be enough

19.4
text is clear enough in this case, there's no much data and the trend is simple.

19.5
instead of plain array access the array is modified with volatile_write:
    let ptr = &mut vec[i] as *mut u32;
    unsafe { write_volatile(ptr, 1); }
volatile writes are never elided nor reordered by the Rust compiler.

19.6
not significant so far in measurements 

19.7
whatever overhead the first access incurs will be averaged to almost nothing after 5000 trials,
adding manual volatile initialization before measuring didn't change time per access.

20. Paging: Smaller Tables
Questions
20.1
Still one: the PDBR. Locations of lower levels are stored in memory not a register.

20.2
// would do 1 instead of 30 translations in a table of 4096 raw bytes
// -s 0, the first virtual address
PDBR = 108
VA = 0x611c = 0b11000_01000_11100
PDIndex = 0b11000 = 24
PDE = 0xa1 = 0b1_0100001, VDE.Valid = True
PDE.PFN = 0b0100001 = 33
PTIndex = 0b01000 = 8
PTE = 0xb5 = 0b1_0110101, PTE.Valid = True
PTE.PFN = 0b0110101 = 53
Offset = 0b11100 = 28
Value = 0x08
each lookup follows 3 memory references in total
    one to the PDE
    one to the PTE
    one to the physical address in PTE

20.3
Modern CPU brings a whole page or something close to the cache on memory access, after the first
access to a memory location the highest level PDT and the page tables down from there for the VA
would have been bought into cache, following accesses up to a common low level VPN would have cache
hits. If the Page table hierarchy is deep to the point that not all page directory tables used to
translate a single VA could be fit into the cache there would be significantly more cache misses.

21. Beyond Physical Memory: Mechanisms
Questions
21.1
./mem 1024
    free, The amount of free memory decreased by 1_000_000. the unit seems to be KB.
    in, The number of interrupts per second increased by 3x. Mostly page memory accesses.
    r, The number of runnable processes increased by 1
    us, user time is 8%, a process constantly fault on memory access is impossible to saturate a
        modern CPU
All of the stats above are linear in the number of mem running

21.2
swpd remains 0, free increased then decreased by 1GB.

21.3
./mem $((13 * 1024))
1.  Before the main loop, an array bigger than available memory is allocated, pages that doesn't fit
    in the main memory is swapped out to the disk, for a brief second so skyrocketed to 1.5GB/s. This
    number is significantly over the capacity of the disk, which indicates the swap files are merely
    created by the file system and contains uninitialized data at this point. 
2.  At the beginning of loop 0 most VAs accessed by the main loop is in physical memory, after a
    while the program reaches the swapped out region of the array, generated a constant stream of
    page faults. si remained constant at ~100MB/s. For some reason the OS swapped out more than
    necessary pages out to the disk on initialization, as swpd decreased from 1.5GB to 1GB with no
    pages swapped out in this period.
3.  Starting from loop 1, each page access is now a page fault (maybe due to the page evict policy),
    the same amount of pages are swapped, in and out every second, si == so == bandwidth, no change
    in swpd anymore.

21.4
bi == si, bo == so as expected, no other process utilizing the disk
cs == 2 * in, each interrupt is handled by a context switch from the process to kernel and a context
switch from kernel to the process
the CPU is entirely idle, the user process is blocking on IO, the kernel has no ready process to
schedule, only the disk is busily swapping pages in and out.

21.5
./mem $((4 * 1024))
    The first loop is slower than subsequent loops as the memory is initialized on the fly. After
    that the bandwidth is 9000MB/s constant.
./mem $((13 * 1024))
    The first loop is faster than subsequent loops as a major part of the memory it accesses is not
    in swap space yet. After that the bandwidth is 100MB/s constant.
The graph should be like a step function: any x <= 12 maps to 9000, any x > 12 maps to 100.

21.6
the entire system freezes after a certain size
the allocation fails once array size > memory available to user process + swap file size

21.7
// is it even possible to configure swap space from WSL?

22. Beyond Physical Memory: Policies
"However, in many cases the importance of said algorithms has decreased, as the discrepancy between
memory-access and disk-access times has increased."
A reasonably available NVMe storage now is only 1 magnitude slower than DDR4 in terms of both speed
and IOPS.

Questions
22.1
-p FIFO -s 0 -n 10
    10% hit rate 
-p LRU -s 0 -n 10
    20% hit rate
-p RAND -s 0 -n 10
    0% hit rate
-p OPT -s 0 -n 10
    40% hit rate
-p CLOCK -s 0 -n 10
    10% hit rate
the seemingly random sequence (8 7 4 2 5 4 7 3 4 5) and the small default cache size (3 pages)
nullified the potential benefit of LRU and CLOCK.

22.2
FIFO
    a repeated sequential access to a pattern of length > 5, 0% hit rate. Would be dramatically
    improved to 100% once the cache size is equal or greater to the length of the pattern
LRU
    the same to FIFO
MRU
    (1 2 3 4 5 6 5 6 5 6 ...), the last two pages 5 and 6 will be evicted each time on the access of
    the other, 0% hit rate, would be dramatically improved to 100% once cache size is increased by 1

22.3
same to Figure 22.6 , given the trace is long enough

22.4
hot / cold pages, same to Figure 22.7, given the trace is long enough

22.5
The processed list of page numbers exceeds the length limit of argument list (getconf ARG_MAX, in
this case 2097152 bytes). The output is limited to the first 10_000 accesses. The program ls has a
working set so tiny that even a single cached page will cover more than 60% memory accesses,
regardless of policy in use. The first 10_000 memory access of a Linux core utility must be a bad
sample as the trace of vmstat gives the exact same results.

23. complete virtual memory systems
[ll82] “virtual memory management in the vax/vms operating system”
---NOTE START---
A common low-end processor in 1970s had <1 mhz clock speed, as a result, vax/vms is optimized
towards reduced usage of processor on cost of memory requirements.

Two system parameters, a low limit and a high limit, are associated with the global modified list of
pages. Once the list size reaches the high limit, the OS writes out pages until the size of the
modified list is now the lower limit, during which process contiguous pages in virtual memory is
written to contiguous regions of the disk, next time the process faults on one of the pages (and by
spatial locality, would fault on consecutive pages) the OS may cluster the read to a sequential
access to the disk. 

Whenever a process is removed from the memory (e.g. on context switch), its resident set is swapped
out to the disk. A process is never swapped in unless there's enough memory for its entire resident
set at the point it's swapped out. A process could lock itself and its pages in memory so it's never
swapped out, a privileged syscall in modern Linux, which should also be the case of VAX/VMS (not
mentioned in the paper).
---NOTE END---

26. Concurrency: An Introduction
Questions
26.1
All general registers, if not specified otherwise, has initial value 0. The program will halt after
the first iteration of the loop, on exit %dx = -1.

26.2
The state of registers are not shared between threads, no matter what is the interrupt frequency the
two threads will be decremented by 1 each iteration, after 3 iterations both threads will halt.
Since interrupt frequency is set to a value much larger than the cycles required to run a thread to
completion, the second thread will start only after when the first thread halted.

26.3
As stated above in 26.2, the program is deterministic and the interrupt frequency will not change
the result of execution.

26.4
In C terms,
    int *ptr = 2000;
    do {
        *ptr += 1;
    } while (b > 0);
b = 0, *ptr = 0 at the beginning of the program, value = *ptr is incremented once from 0 to 1 by
instruction 1004 then the program halts.

26.5
The default interrupt frequency is once between 50 instructions, both threads are not interrupted
while in the critical section, the number of iterations is controlled by the initial value of the
loop counter %bx which is set to 3, the final value of memory position 2000 is 6.

26.6
-s 0
    final value is 2, both threads are not interrupted in critical section
-s 1
    Thread 0 is interrupted right after instruction 1000, the same value 1 is written twice by
    thread 0 and 1 to the memory position 2000, final value is 1
-s 2
    final value is 2, both threads are not interrupted in critical section
critical section is instruction 1000 to 1002 inclusive, if a thread is interrupted after instruction
1000 and before instruction 1003 the execution order is unsafe.

26.7
-i 1
    final value is 1, both thread loads the initial value of (2000) to %ax
-i 2 
    final value is 1, both thread loads the initial value of (2000) to %ax
-i 3
    final value is 2, the store operation (instruction 1002) of thread 0 happens before the context
    switch, threads 1 read value 1 from the memory location
for i >= 3, the answer is correct for a single iteration

26.8
There's 6 instructions in the loop, if a = b mod 6, using a or b as the interrupt frequency should
yield the same correctness.
-i 1, -i 2 is incorrect as stated above in 26.7
-i 3 is correct
    length of the critical section is 3, the execution order is:
        critical section of thread 0
        critical section of thread 1
        jump test of thread 0
        jump test of thread 1
        (repeat)
    both threads are never interrupted in critical section
-i 4 is incorrect
    thread 0 is interrupted in the critical section of the 2nd iteration
-i 5 is incorrect
    thread 0 is interrupted in the critical section of the 4th iteration
-i 6 is correct
    each thread runs for a whole iteration of the loop before being interrupted

26.9
The memory location 2000 is used as a spin lock, thread 1 initialized with ax = 1 releases the lock
by storing 1 to the memory location, thread 0 initialized with ax = 0 busily waits for the store in
the other thread. the final value of (2000) is always 1 on exit.

26.10
As long as there's only one signaller, the behavior of the program is deterministic, both threads
doesn't have a critical section assume the instructions are atomic and the threads are scheduled on
a single CPU. On multiple CPUs the behavior of the program is less consistent, the modification done
by one CPU may not be immediately visible to another CPU. 
The memory location is used as a spin lock, the waiter loop at full speed until the lock is released
by the signaller, that's definitely not an efficient use of the CPU.

27. Interlude: Thread API
Cast between long long int and void * is not always safe, void * could be 32-bit

A possible deadlock scenario of 2 threads if mutex was released before sending signal, thanks
https://stackoverflow.com/questions/21439359/
    1.  thread 1 (signaller) releases mutex
    2.  thread 0 (waiter) awoken spuriously
    3.  thread 0 checks condition, the condition is not met
    4.  signal from thread 1 arrives, ignored because thread 0 is not waiting on condvar
    5.  thread 0 waits on condvar and deadlock 

Questions
27.1
Redirect the output of valgrind to less:
    valgrind --tool=helgrind 2>&1 ./main | less
If the program is compiled with debug symbols (-g flag to gcc), helgrind will report the file name
and line number where the data race occurred.
Two data races are reported: one between read in main thread and write in spawned thread, another
between write in main thread and read in spawned thread.
==221== ----------------------------------------------------------------
==221==
==221== Possible data race during read of size 4 at 0x10C07C by thread #1
==221== Locks held: none
==221==    at 0x1094D0: main (main-race.c:15)
==221==
==221== This conflicts with a previous write of size 4 by thread #2
==221== Locks held: none
==221==    at 0x109497: worker (main-race.c:8)
==221==    by 0x483C8B6: mythread_wrapper (hg_intercepts.c:389)
==221==    by 0x4856FA2: start_thread (pthread_create.c:486)
==221==    by 0x49694CE: clone (clone.S:95)
==221==  Address 0x10c07c is 0 bytes inside data symbol "balance"
==221==
==221== ----------------------------------------------------------------
...
==221== ----------------------------------------------------------------
==221==
==221== Possible data race during write of size 4 at 0x10C07C by thread #1
==221== Locks held: none
==221==    at 0x1094D0: main (main-race.c:15)
...
Along with where the race occurred, helgrind reports the size of the conflicting read, the thread
performing the conflicting read and write, any lock held by the threads at the point of data race,
the memory address of the data race and the variable name under unprotected access.

27.2
remove one of the offending lines of code
    empty report from helgrind 
lock only the access to balance in main thread with a mutex
    helgrind reports the appearance of the lock
    ==599==  Lock at 0x10C0A0 was first observed
    ==599==    at 0x483DB1D: pthread_mutex_init (hg_intercepts.c:787)
    ==599==    by 0x10924C: Pthread_mutex_init (mythreads.h:18)
    ==599==    by 0x1094C3: main (main-race.c:16)
    ==599==  Address 0x10c0a0 is 0 bytes inside data symbol "mutex"
    the same lock is reported at the data race since the data race is not eliminated by the lock
    ==599== Possible data race during write of size 4 at 0x10C084 by thread #1
    ==599== Locks held: 1, at address 0x10C0A0
    ==599==    at 0x1094F6: main (main-race.c:20)
lock both access with the same mutex
    again empty report from helgrind 

27.3
The two workers lock the two mutexes in reverse order, a possible execution order is
    1.  worker 1 locks mutex m1
    2.  worker 2 locks mutex m2
    3.  worker 1 try locking mutex m2 and block
    4.  worker 2 try locking mutex m1 and block
no thread can make progress any more, hence a deadlock

27.4
helgrind reported "lock order violated", followed by where and to which locks the lock order is
reversed in one thread from another

27.5
main-deadlock-global.c doesn't have the deadlock problem that's present in main-deadlock.c, the two
locks m1 and m2 are still acquired in reverse order in different threads but the acquisition are
themselves protected by a global mutex g, nonetheless helgrind still reported the same lock order
violation as a bug of the program.
As deadlock-detection is probably NP-hard[1], it's a reasonable decision for a tool like helgrind to
utilize heuristics that may have false-positives and false-negatives instead of basing itself on an
algorithm that's 100% correct.
[1] https://madoc.bib.uni-mannheim.de/1309/1/Deadlock_Detection_in_Component_Based_Systems_is_NP_hard.pdf

27.6
The OS cannot reliably distinguish between a thread doing useful work and a thread spinning on a
condition check, if the child thread takes a long time to complete the main thread will saturate the
CPU resource available to it doing meaninglessly frequent check.

27.7
helgrind reports the data race on `done`. Data race in C is undefined behavior, compilers are
allowed to do whatever they want if there's unprotected mutual access to a variable, the binary may
appear to be correct only because the current compile target performs all read / write atomically
and the compiler is not yet exploiting the assumption hard enough.
Also helgrind doesn't understand atomic operations, even if `done` is defined as an atomic int and
modified with proper atomic builtins the same "errors" are still reported.

27.8
The main improvement of main-signal-cv.c from main-signal.c is:
    1.  there's no data race anymore, the program is now correct and cross-platform
    2.  the program no longer spin on a condition check

27.9
No error reported by helgrinGd

28. Locks
Figure 28.9: Lock With Queues, Test-and-set, Yield, And Wakeup
In reality park() may return spuriously without another thread calling unpack

What would happen if the release of the guard lock came after the park(), and not before?
Deadlock: the current thread is parked while holding the guard to the lock structure, the rest of
threads take turns to spin until a timer interrupt.

Figure 28.10: Linux-based Futex Locks
---NOTE START---
All modifications to `mutex` is atomic, but reads are not necessarily so. In particular
    v = *mutex;
is not atomic, but the code snippet is simplified a lot from the source of glibc/nptl, the original
function is a few hundred lines long littered with macros and compiler flags.

The lower 31 bits of `mutex` are only modified when a thread enters or leaves lock state. futex_wait
solves the problem with park(): if the thread is interrupted after v = *mutex and before futex_wait,
during which the lock is released, either the caller acquires the lock
    if (v >= 0)
        continue;
    // another iteration of the loop
    if (atomic_bit_test_set (mutex, 31) == 0)
        return;
or another thread had acquired the lock, mutex is decremented by 1, difference between `mutex` and `v`
causes futex_wait to return immediately.
---NOTE END---

Questions 
28.1
In C terms,
    for (; b > 0; b--) {
        while (flag != 0)
            ;
        flag = 1;
        count += 1;
        flag = 0;
    }
Spin lock on non-atomic flag variable, wrong in every possible way.

28.2
The default interrupt frequency is once per 50 instructions, both threads will not be interrupted in
critical section, the program will correctly put 2 in `count` no matter how broken the lock is.
`flag` will be 0 after the second thread released the lock.

28.3 - 28.4
Once the number of iteration (%bx) is large enough, threads start to be interrupted in critical
sections, the end value of `count` would no longer equal to twice the number of iterations, but as
the lock is always released at the end of an iteration, `flag` would still contain 0 at the end of
execution.

28.5
In C terms, 
    _Atomic int mutex = 0;
    // acquire
    while (atomic_exchange(&mutex, 1) != 0)
        ;
    // release
    atomic_store(&mutex, 0);
Assuming a strict memory order (modification from one thread is immediately visible to all others),
both the lock acquire and release are correct.

28.6
A possible measurement of efficiency is total executed instructions / %bx.
    BX=50;INS=$(./x86.py -p test-and-set.s -M mutex,count -a bx=$BX,bx=$BX -i 10 -s 10 -c | wc -l);echo $((INS / BX))
The average result is 32 instructions per iteration in both threads, the wasting of CPU cycles is
not that much outrageous as there's 10 instructions per iteration in the shortest path, 20 for both
threads, roughly 33% CPU time is spent in the spin lock.

28.7
-P 00111
    1000 mov  $1, %ax
    1001 xchg %ax, mutex
    ------ Interrupt ------  ------ Interrupt ------
                            1000 mov  $1, %ax
                            1001 xchg %ax, mutex
                            1002 test $0, %ax
    ------ Interrupt ------  ------ Interrupt ------
    1002 test $0, %ax
    1003 jne  .acquire
    ------ Interrupt ------  ------ Interrupt ------
                            1003 jne  .acquire
                            1000 mov  $1, %ax
                            1001 xchg %ax, mutex
    ------ Interrupt ------  ------ Interrupt ------
    1004 mov  count, %ax
    1005 add  $1, %ax
xchg ensures that only one thread would have %ax = 1 at any point into the execution, without %ax =
0 a thread cannot enter its critical section. Another thing worth testing is whether one thread will
starve under any possible scheduling. 

28.8
The program has 3 1-bit flags:
    flag[0], flag[1], turn
in addition to two 1-bit states semantically important to the correctness of the program:
    thread_1_in_critical_section, thread_2_in_critical_section
There's 32 states in total, a rigorous proof would have to show the program never enters a state (_,
_, _, 1, 1). The initial state is (0, 0, 0, 0, 0) or (0, 0, 1, 0, 0).
The first thread may only enter the critical section when the state is (1, _, 0, 0, 0), the second
thread may only enter the critical section when the state is (_, 1, 1, 0, 0), the two sets of states
are mutually exclusive.
A thread never modifies `turn` in its own favor, that vaguely means when a thread is granted access
to the critical section (at the start of .spin1 or at the start of .spin2), execution of the other
thread will not invalidate its access or allow the other thread to enter the critical section
concurrently. Formally that means there's no path from (1, _, 0, _, 0) to (_, 1, 1, _, 0) executing
only thread 2.
The program is deadlock free: if there's no contention, a thread trying to acquire the lock
immediately jumps to .fini then the start of the critical section; if there's contention exactly one
of them pointed by the value of `turn` will be granted access to the critical section.

28.9
starting from -i 7, the execution is much shorter as the first thread acquired the lock with no
contention, interrupt frequencies shorter than that cause the value of `turn` to bounce between 0
and 1 a few times.

28.10
see 28.8

28.11
A faithful translation of Figure 28.7: Ticket Locks. The shortest path of one iteration contains 13
instructions, the execution in total is 99481 instructions, or 50 instructions per iteration, only
26% percent of the time the CPU is doing meaningful works.

28.12
Without randomized interrupts the performance is stable at ~50 instruction / iteration
    -t 2: 99481
    -t 3: 149443
    -t 4: 199306
    -t 5: 249169
    -t 6: 299032
    -t 7: 348946
With randomized interrupts the performance is much worse for more threads
    -t 2: 62608
    -t 3: 130654
    -t 4: 209992
    -t 5: 337954
    -t 6: 490873
    -t 7: 656734

28.13
ostep $ ./x86.py -p test-and-set.s -M mutex,count -t 10 -a bx=100 -c | wc -l
71311
ostep $ ./x86.py -p yield.s -M mutex,count -t 10 -a bx=100 -c | wc -l
18190
By definition only one thread may progress in the critical section, all other threads would have to
waste their entire time slice spinning in test-and-set.s, in yield.s however the contending threads
immediately de-schedule themselves. More threads spawned by the process, more significant the saving
is.

28.14
There's a saving only when xchg is much more expensive than mov and time slices are accounted by
number of instructions instead of real time, both are not true in a realistic system. 

29. Lock-based Concurrent Data Structures
Questions 
29.1
see 19.1

29.2
./ostep/chapter_29/concurrent_structures
The number of virtual CPUs should have a negative impact on performance, given the number of threads
a context switch is more likely to be between CPUs when there are more virtual CPUs in the system.


29.3
./ostep/chapter_29/concurrent_structures
The code in the text has a bug: accumulated local negative updates are never flushed to the global
count.

29.4
./ostep/chapter_29/concurrent_structures
[MS04] “Concurrent Data Structures” by Mark Moir and Nir Shavit, the cited paper didn't show an
implementation of hand-over-hand linked list, instead it redirected reader to two paywalled sources
for the details. The code here is based on lecture slide from Washington University in St. Louis:
    https://www.cse.wustl.edu/~angelee/archive/cse539/spr15/lectures/lists.pdf
The only possible situation I can think of where hand-over-hand list performs better than a globally
locked linked list is when sequentially ordered items are removed from the list. Even that heavily
depends on the performance of mutex provided by the system.


29.5 - 29.6
https://github.com/ivfranco/talent-plan/tree/main/kvs, a concurrent log-structured key-value store

30. Condition Variables
Questions
30.1
---NOTE START---
#include <mythreads.h>
Abort-on-failure wrappers of standard library functions except work().
    void work(int seconds)
    keeps the CPU busy in an empty while loop for `seconds` second. This functions is never used in
    any actual consumer / producer program.

#include <pc-header.h>
Global variables used through variations of the producer / consumer program.
    fill_ptr 

#include <main-header.h>
#include <main-common.h>
Common structures among variations of the producer / consumer program, parses the command line
arguments then run the program accordingly. Sets up the p0 - p6, c0 - c6 macros that pause the
threads wrt. the sleep string argument following -P and -C.

Negative values in a buffer slot indicates the slot is empty (EMPTY) or the producer is terminated
(END_OF_STREAM). The program emits the same number of END_OF_STREAM as the number of consumers into
the buffer, each consumer terminates after consuming a different END_OF_STREAM value.

The program is essentially the same to Figure 30.14: The Correct Producer/Consumer Synchronization.
Producers and consumers are blocked on their own conditional variables and the same mutex.
---NOTE END---

30.2
When there's no sleep, apparently what happened is the producer never uses more than one buffer slot
at a time, after producing a single value into the buffer the producer releases the mutex which will
immediately be taken over by the consumer, therefore the sole producer and the sole consumer take
turns to do their work one item at a time till the end of stream, regardless of the buffer size or
the total number of items produced. In theory the outcome of the program could be far more
non-deterministic.
When the sleep time after c6 is set to a non-zero value, the producer after releasing the mutex is
allowed to re-acquire it instantly hence enter another iteration as there's no contention, until the
buffer is completely filled (since the work takes negligible time compared to a whole second which
is the minimum sleeping time) then wait on its conditional variable. `num_full` will bounce between
`max` and `max` - 1 till end of stream.

30.3
// skipped

30.4
At least 0 seconds
    the producer and one consumer take turns to run, neither the producer or the consumers ever
    enter the while loop or wait
At most 13 seconds 
    1.  all 3 consumers acquire the mutex before the producer, proceeds to wait on the conditional
        variable
    2.  producer fills the empty buffer, signals a single consumer 
    3.  one consumer is woken, after the one-second sleep it consumes the value, signals the
        producer, re-acquire the lock to begin another iteration then proceeds to wait on the same
        conditional variables again
    repeat steps 2 and 3 until all values (10 stream values + 3 END_OF_STREAM tokens) are consumed.

30.5
Still 0 - 13 seconds, the buffer size is irrelevant to the argument above in 30.4.

30.6
By moving the sleep to a point after c6, the consumers no longer sleep while holding the mutex.
At least 0 seconds
    same to above
At most 5 seconds
    1.  all 3 consumers acquire the mutex before the producer, proceeds to wait on the conditional
        variable
    2.  producer fills the empty buffer, signals a single consumer 
    3.  one consumer is woken, it consumes the value, signals the producer, releases the lock then
        goes to sleep for 1 second
    every second steps 2 to 3 is repeated 3 times, once for each consumer thread. 13 values in total
    is consumed in 5 seconds

30.7
still 0 - 5 seconds, the bottleneck of this system is not the buffer size but the mandatory sleep
time of the consumers.

30.8
The program is deadlock free when there's only one consumer. the producer could only block on the
conditional variable when the buffer is full, then the consumer, the sole other thread will take
over the lock, consume the values in the buffer and signal the producer from waiting; similarly the
consumer could only block on the conditional variable when the buffer is empty. The conditional
variable is never shared by both the consumer and the producer, and when a thread is woken from
waiting the buffer state is always valid to it. 

30.9
As stated in the text, it should be possible to cause deadlock even without any particular sleep
string, but I couldn't reproduce the deadlock in a debian WSL for some reason, no matter what the
sleep string is set to. 
Some settings, for example -P 0,0,0,0,0,0,1 may cause deadlock on EOS tokens, but these tokens are
inserted directly by the main thread ignorant of producers / consumers as well as the conditional
variables and mutex they rely on. 

30.10
-c 1
    assuming there's no spurious wake up, each time the producer or the consumer is woken, state of
    the buffer cannot possibly be invalidated as there's no contending producers / consumers, the
    program is correct with a single producer and a single consumer
-c 2
    the program error exits on almost every run even without a sleep string crafted for the purpose,
    as stated in the text a consumer may be exposed to an empty buffer on wake up

30.11
-p 1 -c 1 -m 2
    1.  the consumer sees an empty buffer, proceeds to block on `fill`
    2.  the producer produces two values in quick succession, signals the consumer then proceeds to
        block on `empty`
    3.  the consumer consumes one value, signals the producer, re-acquire the lock upon entering a
        new iteration
    4.  now the next time the consumer releases the lock at the end of c3, it may be interrupted in
        critical section by the ready to run producer, which would have access to the critical
        section as well
Didn't find a reliable sleep string exposing the race conditions, it would be much more easier if
the program could set set sleep string for each iteration of the program.

31. Semaphores
Questions
31.1
./ostep/chapter_31/semaphore/src/bin/fork_join.rs

31.2
./ostep/chapter_31/semaphore/src/bin/rendezvous.rs

31.3
./ostep/chapter_31/semaphore/src/bin/barrier.rs

31.4 - 31.5
./ostep/chapter_31/semaphore/src/bin/reader_writer.rs
Before sleep() is added to the code, writers almost never had a chance to increment the value as
long as there's more than one concurrent readers.
In addition to the code in Figure 31.13: A Simple Reader-Writer Lock, now a waiting writer also
blocks all pending readers until the writer unlocks. The program now suffers from some degree of
reader starvation instead.
An actually fair read-write lock in Rust could be found in parking_lot crate:
    https://docs.rs/parking_lot/0.11.1/parking_lot/type.RwLock.html
which bases its scheduling on running times of lock holders.

31.6
./ostep/chapter_31/semaphore/src/bin/mutex_nostarve.rs
Thanks The Little Book of Semaphores, Allen B. Downey, available at 
    https://greenteapress.com/semaphores/LittleBookOfSemaphores.pdf
The Rust code is a word to word translation of the C implementation in the book.

31.7
No, I do not enjoy it unconditionally.

32. Common Concurrency Problems
TIP: ENFORCE LOCK ORDERING BY LOCK ADDRESS
Doesn't work if the lock is not process-local, e.g. system-wide named semaphore in Linux.

TIP: DON’T ALWAYS DO IT PERFECTLY (TOM WEST’S LAW)
The reason behind spurious wake ups and EINTER.

Questions
32.1
---NOTE START---
void vector_add(vector_t *v_dst, vector_t *v_src), in vector-deadlock.c
    Acquires first the lock of v_dst, then the lock of v_src. The content of v_src is added inplace
    to the content of v_dst.

void *worker(void *arg), in main-common.c
    For times supplied by argument -l, call vector_add(&v0, &v1). If -p is _NOT_ set, all threads
    share the same pair of vectors. If -d is set, half of the threads call vector_add with roles of
    v0 and v1 reversed.

void print_info(int call_return, int thread_id, int v0, int v1), in main-common.c
    The output is indented so that reports from different threads are in different column.
    ->add(v0, v1)
        A thread called vector_add(v0, v1)
    <-add(v0, v1)
        A thread returned from vector_add(v0, v1)
    
./vector-deadlock -n 2 -l 1 -v 
    Except ->add always happens before ->add for the same thread, there's no consistent order
    between events.
---NOTE END---

32.2
The program deadlocks once in a few hundred trials on average. Deadlock manifests only when 
    ->add(1, 0)
    ->add(0, 1)
occur at the same time in different threads. 

32.3
Increasing the number of threads significantly worsens the situation, on 10 threads the program is
almost guaranteed to deadlock before the 100th trial, ~20 trials on average. Since circular wait may
occur between any two threads with reversed lock order, more threads exponentially increases the
chance of deadlock.
This program running on any number of threads more than 1 is vulnerable to circular wait, the only
safe option is -n 1.

32.4
Locks are acquired in order of their memory address, this program is deadlock-free as there's no
circular wait. 
Without the special case where the supplied v_dst and v_src is the same vector, a thread would
deadlock itself by locking the same lock twice.

32.5
Running time is roughly linear in number of threads.
    for n in {1..6}; do
        THREADS=$((2 ** n));
        echo "$THREADS threads";
        ./vector-global-order -t -n $THREADS -l 100000 -d;
    done
    2 threads
    Time: 0.02 seconds
    4 threads
    Time: 0.11 seconds
    8 threads
    Time: 0.36 seconds
    16 threads
    Time: 0.76 seconds
    32 threads
    Time: 1.48 seconds
    64 threads
    Time: 2.99 seconds
Running time is roughly linear in number of loops.
    for l in {1..10}; do 
        LOOP=$((l * 100000)); 
        echo "$LOOP loops"; 
        ./vector-global-order -t -n 4 -l $LOOP -d; 
    done 
    100000 loops
    Time: 0.14 seconds
    200000 loops
    Time: 0.27 seconds
    300000 loops
    Time: 0.37 seconds
    400000 loops
    Time: 0.50 seconds
    500000 loops
    Time: 0.65 seconds
    600000 loops
    Time: 0.78 seconds
    700000 loops
    Time: 0.85 seconds
    800000 loops
    Time: 1.11 seconds
    900000 loops
    Time: 1.27 seconds
    1000000 loops
    Time: 1.27 seconds

32.6
Up to the physical number of CPUs in the system (6 in my case) the performance should be close to -n
1 without -p flag. Performance gain beyond that certain number of threads, if any, must be from
now eliminated overhead of mutex scheduling.
    for n in {1..6}; do 
        THREADS=$((2 ** n)); 
        echo "$THREADS threads"; 
        ./vector-global-order -t -n $THREADS -l 100000 -d -p; 
    done
    2 threads
    Time: 0.01 seconds
    4 threads
    Time: 0.01 seconds
    8 threads
    Time: 0.01 seconds
    16 threads
    Time: 0.03 seconds
    32 threads
    Time: 0.04 seconds
    64 threads
    Time: 0.08 seconds

32.7
The first pthread_mutex_trylock() is unnecessary per deadlock avoidance, the first lock is unlocked
anyway if the thread failed to acquire the second lock, there's never circular wait in the system no
matter the first lock is acquired non-blocking or not.
The performance is much worse than vector-global-order, both the running time and number of retries
are super linear in number of threads once the number of threads goes beyond the number of physical
CPUs. 
    for n in {1..6}; do
        THREADS=$((2 ** n));
        echo "$THREADS threads";
        ./vector-try-wait -t -n $THREADS -l 100000 -d;
    done
    2 threads
    Retries: 12478
    Time: 0.02 seconds
    4 threads
    Retries: 23301
    Time: 0.07 seconds
    8 threads
    Retries: 4442106
    Time: 0.32 seconds
    16 threads
    Retries: 23177620
    Time: 1.74 seconds
    32 threads
    Retries: 71349251
    Time: 8.53 seconds
    64 threads
    Retries: 185078973
    Time: 16.27 seconds

32.8
This approach prohibits any form of parallelism even if the threads are working on different
vectors. The performance with -p flag is significantly worse than vector-global-order.
    for n in {1..6}; do
        THREADS=$((2 ** n));
        echo "$THREADS threads";
        ./vector-avoid-hold-and-wait -t -n $THREADS -l 100000 -d -p;
    done
    2 threads
    Time: 0.01 seconds
    4 threads
    Time: 0.04 seconds
    8 threads
    Time: 0.12 seconds
    16 threads
    Time: 0.32 seconds
    32 threads
    Time: 0.53 seconds
    64 threads
    Time: 1.02 seconds
    ostep $

32.9
The semantics of vector-nolock and previous versions of the program are not exactly the same. In
previous versions the entire vector_add function is atomic, in contrary vector-nolock guarantees
only atomicity of operations on a single vector element. For example, let 
    v0 = [1, 1]
    v1 = [1, 1]
    v2 = [1, 1]
when there are two concurrent calls to vector_add
    ->add(v1, v0)
    ->add(v2, v1)
the result of all previous versions of the program would have
    v2 = [2, 2] or [3, 3]
but the result of vector-nolock could be
    v2 = [2, 3]

32.10
On separate vectors the performance of vector-nolock is on par with vector-global-order
    for n in {1..6}; do
        THREADS=$((2 ** n));
        echo "$THREADS threads";
        ./vector-nolock -t -n $THREADS -l 100000 -d -p;
    done
    2 threads
    Time: 0.04 seconds
    4 threads
    Time: 0.04 seconds
    8 threads
    Time: 0.05 seconds
    16 threads
    Time: 0.06 seconds
    32 threads
    Time: 0.12 seconds
    64 threads
    Time: 0.22 seconds
Quite surprisingly when working on the same vectors the no-lock version is worse in performance
compared to a global lock
    for n in {1..6}; do
        THREADS=$((2 ** n));
        echo "$THREADS threads";
        ./vector-nolock -t -n $THREADS -l 100000 -d;
    done
    2 threads
    Time: 0.34 seconds
    4 threads
    Time: 0.96 seconds
    8 threads
    Time: 1.73 seconds
    16 threads
    Time: 2.91 seconds
    32 threads
    Time: 5.52 seconds
    64 threads
    Time: 12.48 seconds

33. Event-based Concurrency (Advanced)
Questions
// skipped, had done this several times as exercise of books of various topics

37. Hard Disk Drives
Questions
python-tk, backend of the GUI doesn't work on WSL
by default, 
    1.  each track has 12 sectors, 30 unit distance between each other, sectors are numbered
        counterclockwise 
    2.  the outmost track is the first one
    3.  tracks are 40 distance units apart
    4.  the seek head starts at the midpoint of sector 6
The rotate time displayed by -c is the time waiting on rotate _after_ the seek. The rotate times
in calculations below are rotating time _including_ seek and wait.

37.1    
-a 0
    seek        = 0
    rotate      = (0 - 6.5) mod 12 * 30 = 165
    transfer    = 30
    total       = 195
-a 6
    seek        = 0
    rotate      = (6 - 6.5) mod 12 * 30 = 345
    transfer    = 30
    total       = 375
-a 30
    seek        = ceil(30 / 12) * 40 = 80
    rotate      = (30 - 6.5) mod 12 * 30 = 345
    transfer    = 30
    total       = 375 (seek and rotate are concurrent)
-a 7,30,8
    section 7
        seek        = 0
        rotate      = (7 - 6.5) mod 12 * 30 = 15
        transfer    = 30
        total       = 45
    section 30, start at the start of section 8
        seek        = |ceil(30 / 12) * 40 - 0| * 40 = 80
        rotate      = (30 - 8) mod 12 * 30 = 300
        transfer    = 30
        total       = 330
    section 8, start at the start of section 31
        seek        = 80
        rotate      = (8 - 31) mod 12 * 30 = 60, +360 must wait for another full rotation 
        transfer    = 30
        total       = 420
    795 in total
-a 10,11,12,13
    section 10, 11
        seek        = 0
        rotate      = (10 - 6.5) mod 12 * 30 = 105
        transfer    = 60
        total       = 165
    section 12, 13, start at the start of section 0
        seek        = 40
        rotate      = 360
        transfer    = 60
        total       = 420
    585 in total 

37.2 - 37.3
// skipped, mostly the same calculation

37.4
-a 7,30,8 -p SSTF, one best schedule
    section 7,8
        seek        = 0
        rotate      = 15
        transfer    = 60
        total       = 75
    section 30, start at beginning of section 9
        seek        = 80
        rotate      = (30 - 9) mod 12 * 30 = 270
        transfer    = 30
        total       = 300
    375 in total  
section 8 may be served before section 7 in SSTF

37.5
SATF guarantees that section 7 is always served before section 8, any time a series of requests of
the same seek time appears SATF would potentially outperform SSTF.

37.6
track skew: tracks doesn't numerically start at the same angular position, e.g. for a skew of 2, the
outmost track start at angular position 0, the track immediately inside to it starts at angular
position π/3 and so on.
-a 10,11,12,13 is slow because after access to section 10 and 11, without a skew the seek head must
wait for a full rotation on the inner track. A skew of 2 will maximize the performance as it
minimizes the waiting time on the inner track.
-a 10,11,12,13 -o 2
    section 10, 11
        seek        = 0
        rotate      = (10 - 6.5) mod 12 * 30 = 105
        transfer    = 60
        total       = 165
    section 12, 13, start at the start of section 0
        seek        = 40
        rotate      = (2 - 0) mod 12 * 30 = 60
        transfer    = 60
        total       = 120
    285 in total 

37.7
// it's really hard to tell what the geometry is without graphic output, with -z 10,20,30 the
// tracks are not perfectly aligned, there's a small 5 degree skew between the first and second
// tracks as far as I can tell, calculation skipped 
bandwidth of 
    outer track: 1/10 section per unit time
    middle track: 1/20 section per unit time 
    inner track: 1/30 section per unit time 

37.8
The limit is different depending on the seed, but at a window size of 200 most seeds reports the
same result to best performance.
for s in {1..100}; do 
    ./disk.py -A 1000,-1,0 -p SATF -w 200 -s $s -c; 
    ./disk.py -A 1000,-1,0 -p SATF -w -1 -s $s -c; 
done | grep TOTALS
In theory the window size must be equal or greater to the total number of requests to maximize
performance, consider a track with 10000 sectors, a series of requests 
    1,2,3,..,999,0
will only be optimally scheduled with window size >= 1000
When the window size is 1, every scheduling policy degrades into FIFO

37.9
"Create a series of requests to starve a particular request"
    32,(0,1,2,3,4,5,6,7,8,9,10,11)*
BSATF solves starvation: upon arrival, every request will be served in a finite time linear to the
window size. A finite window size always hurts the performance in long term.
In practice where performance on magnetic disk matters, a file on magnetic disk is virtually never
modified at any position except the end, policies introduced so far may not incur so much starvation
it did back in the days magnetic disks are still the only budget choice.

35.10
-a 17,20,4,23,4
    FIFO total: 1035
    SATF total: 1065

38. Redundant Arrays of Inexpensive Disks (RAIDs)
Questions 
38.1
RAID 5 left symmetric layout, each stripe numerically starts at the parity block
    0   1   2   3   P0
    5   6   7   P1  4
    10  11  P2  8   9
    15  P3  12  13  14
    P4  16  17  18  19
RAID 5 left asymmetric layout, each stripe numerically starts at the first disk
    0   1   2   3   P0
    4   5   6   P1  7 
    8   9   P2  10  11
    12  P3  13  14  15
    P4  16  17  18  19
chunk size defaults to a single block (4KB), Logical block is then mapped to physical block
according to the RAID level. Let N denotes the number of disks in the RAID system,
-L 0 
    Disk = LogicalBlock % N
    Offset = ceil(LogicalBlock / N)
-L 1 
    Disk = LogicalBlock % (N / 2)
    CopyDisk = Disk + 1
    Offset = ceil(LogicalBlock / (N / 2))
-L 4
    Disk = LogicalBlock % (N - 1)
    Offset = ceil(LogicalBlock / (N - 1))
-L 5 -5 LS
    Offset = ceil(LogicalBlock / (N - 1))
    StripPos = LogicalBlock % (N - 1)
    ParityPos = N - 1 - (Offset % N)
    Disk = (ParityPos + 1 + StripPos) % N
-L 5 -5 LA
    Offset = ceil(LogicalBlock / (N - 1))
    StripPos = LogicalBlock % (N - 1)
    ParityPos = N - 1 - (Offset % N)
    Disk = if (PartiyPos == StripPos)
        StripPos + 1
    else 
        StripPos

38.2
let C denote the number of blocks in a chunk, the blocks are placed as if the block size is C times
as much in RAID 0,
-L 0
    Chunk = ceil(LogicalBlock / C)
    ChunkOffset = LogicalBlock % C
    Disk = Chunk % N
    Offset = ceil(Chunk / N) + ChunkOffset
The same adjustment can be applied to other RAID levels in a similar fashion.

38.3
-L 0
    LogicalBlock = Offset * N + Disk 
-L 1
    LogicalBlock = Offset * (N / 2) + ceil(Disk / 2)
-L 4
    LogicalBlock = Offset * (N - 1) + Disk
-L 5 -5 LS
    StripPos = Disk - ParityPos - 1
    LogicalDisk = Offset * (N - 1) + StripPos
-L 5 -5 LA
    // skipped

38.4
Each request of K * BlockSize is mapped to K physical read operation. Sequential read on a RAID 4 or
5 system is not so different to a RAID 0 system, the parity blocks are ignored in case of read
operations. 

38.5
-L 0
    disk:0  busy: 100.00  I/Os:    28 (sequential:0 nearly:1 random:27)
    disk:1  busy:  93.91  I/Os:    29 (sequential:0 nearly:6 random:23)
    disk:2  busy:  87.92  I/Os:    24 (sequential:0 nearly:0 random:24)
    disk:3  busy:  65.94  I/Os:    19 (sequential:0 nearly:1 random:18)
    STAT totalTime 275.7
-L 1 
    disk:0  busy: 100.00  I/Os:    28 (sequential:0 nearly:1 random:27)
    disk:1  busy:  86.98  I/Os:    24 (sequential:0 nearly:0 random:24)
    disk:2  busy:  97.52  I/Os:    29 (sequential:0 nearly:3 random:26)
    disk:3  busy:  65.23  I/Os:    19 (sequential:0 nearly:1 random:18)
    STAT totalTime 278.7
-L 4
    disk:0  busy:  78.48  I/Os:    30 (sequential:0 nearly:0 random:30)
    disk:1  busy: 100.00  I/Os:    40 (sequential:0 nearly:3 random:37)
    disk:2  busy:  76.46  I/Os:    30 (sequential:0 nearly:2 random:28)
    disk:3  busy:   0.00  I/Os:     0 (sequential:0 nearly:0 random:0)
    STAT totalTime 386.1
-L 5
    disk:0  busy: 100.00  I/Os:    28 (sequential:0 nearly:1 random:27)
    disk:1  busy:  95.84  I/Os:    29 (sequential:0 nearly:5 random:24)
    disk:2  busy:  87.60  I/Os:    24 (sequential:0 nearly:0 random:24)
    disk:3  busy:  65.70  I/Os:    19 (sequential:0 nearly:1 random:18)
    STAT totalTime 276.7
RAID level 4 is significantly slower than others, an entire disk is allocated for parity blocks
only, the maximum possible bandwidth of RAID 4 is 3/4 of other RAID levels.

38.6 - 38.7
// skipped, see Figure 38.8: RAID Capacity, Reliability, and Performance

38.8
When the request size is a multiple of the strip size ((N - 1) * BlockSize), all the disks can be
utilized at the same time, also the parity block is updated per (N - 1) block write which is the
logical minimum.

39. Interlude: Files and Directories
Questions
39.1 - 39.4
./ostep/chapter_39/file_utils

40. File System Implementation
Questions
40.1 
-s 17
    mkdir(/u)
    creat(/a)
    unlink(/a)
    mkdir(/z)
    mkdir(/s)
    creat(/z/x)
    link(/z/x, /u/b)
    unlink(/u/b)
    open(/z/x), write(), close()
    creat(/u/b)

40.2
-s 21
    mkdir("/o")
        [d a:0 r:2] [d a:1 r:2]
        [(.,0) (..,0) (o,1)] [(.,1) (..,0)]
    creat("/b")
        [d a:0 r:2] [d a:1 r:2] [f a:-1 r:1]
        [(.,0) (..,0) (o,1) (b,2)] [(.,1) (..,0)]
    creat("/o/q")
        [d a:0 r:2] [d a:1 r:2] [f a:-1 r:1] [f a:-1 r:1]
        [(.,0) (..,0) (o,1) (b,2)] [(.,1) (..,0) (q,3)]
    fd=open("/b", O_WRONLY|O_APPEND); write(fd, buf, BLOCKSIZE); close(fd);   
        [d a:0 r:2] [d a:1 r:2] [f a:2 r:1] [f a:-1 r:1]
        [(.,0) (..,0) (o,1) (b,2)] [(.,1) (..,0) (q,3)] [u]
    fd=open("/o/q", O_WRONLY|O_APPEND); write(fd, buf, BLOCKSIZE); close(fd);
        [d a:0 r:2] [d a:1 r:2] [f a:2 r:1] [f a:3 r:1]
        [(.,0) (..,0) (o,1) (b,2)] [(.,1) (..,0) (q,3)] [u] [u]
    creat("/o/j")
        [d a:0 r:2] [d a:1 r:2] [f a:2 r:1] [f a:3 r:1] [f a:-1 r:1]
        [(.,0) (..,0) (o,1) (b,2)] [(.,1) (..,0) (q,3) (j,4)] [u] [u]
    unlink("/b")
        [d a:0 r:2] [d a:1 r:2] [] [f a:3 r:1] [f a:-1 r:1]
        [(.,0) (..,0) (o,1)] [(.,1) (..,0) (q,3) (j,4)] [] [u]
    fd=open("/o/j", O_WRONLY|O_APPEND); write(fd, buf, BLOCKSIZE); close(fd);
        [d a:0 r:2] [d a:1 r:2] [] [f a:3 r:1] [f a:2 r:1]
        [(.,0) (..,0) (o,1)] [(.,1) (..,0) (q,3) (j,4)] [u] [u]
    creat("/o/x")
        [d a:0 r:2] [d a:1 r:2] [f a:-1 r:1] [f a:3 r:1] [f a:2 r:1]
        [(.,0) (..,0) (o,1)] [(.,1) (..,0) (q,3) (j,4) (x,2)] [u] [u]
    mkdir("/o/t")
        [d a:0 r:2] [d a:1 r:2] [f a:-1 r:1] [f a:3 r:1] [f a:2 r:1] [d a:4 r:2]
        [(.,0) (..,0) (o,1)] [(.,1) (..,0) (q,3) (j,4) (x,2)] [u] [u] [(.,5) (..,1)]

40.3
Mostly only empty files under the root directory. Operations that allocate more data blocks would
fail, namely write() and mkdir().

40.4
Operations that allocate more inodes would fail, namely mkdir(), creat() and link(). Nothing beside
the empty root directory exists right before the out-of-space error, neither a new directory or a
new file can be created without enough inode slots.

41. Locality and The Fast File System
Questions
41.1
4 blocks of the file is distributed to every cylinder group.

41.2
29 blocks of the file in cylinder group 0 (the first data block is allocated to the root directory),
11 blocks in cylinder group 1.

41.3
-L 4
    First block of a: second inode of cylinder group 0
    Last block of a: 4th data block of cylinder group 9 
    span    = (40 * 9 + 10 + 4) - 2
            = 372
-L 100
    First block of a: second inode of cylinder group 0
    Last block of a: 11th data block of cylinder group 1
    span    = (40 + 10 + 11) - 2
            = 59
Larger large-file exception parameter causes the file to be less spread among different cylinders,
the file span however depends on how the distance between blocks is defined.

41.4
Both inode and data blocks of files under the same directory would be placed at the same cylinder
group, 3 out of 10 cylinder groups will be allocated to contents and inodes of directory /, /j and
/t.

41.5
dir span of /
    29 - 1 = 28
dir span of /j
    21 - 1 = 20
dir span of /t
    35 - 1 = 34
FFS places files under the same directory close to each other, dir span is minimized unless
large-file exception is turned on.

41.6
// inode per group is controlled by option -i, not -I
All the files under the directory /, /j and /t can no longer be allocated into a single cylinder
group, instead each directory must be spread between two cylinder groups, dir span increases
accordingly.

41.7
Directory /j and /t is created back to back, With -A 1 /j and /t are placed at cylinder group 2 and
3, with -A 2 /j and /t are placed at cylinder group 2 and 4, if later a lot of small files are
created under the two directories, -A 2 reduces dir span by placing directories more sparsely so
more file inodes under the same directory can be placed next to each other.

41.8
0 /ib-d-f-h- ibidifihii ii
Data blocks of /i is not contiguous on disk, any program reading the content of /i cannot utilize
the disk throughput more than 66% if the drive is backed by an HDD.

41.9
This time the content of /i is placed contiguously on the disk. For this specific workload the
layout won't change anymore for -C greater than 2 as the hole created by deletion are of size 1.
Greater -C argument should cause the file and dir span to increase as otherwise available data
blocks are skipped.

42. Crash Consistency: FSCK and Journaling
Questions 
42.1
-s 1 
    directories
        /, /m, /a
    files
        /m/m, /m/e, /a/r, /s, /g
-s 2
    directories
        /, /c, /c/o, /c/o/u
    files
        /c/o/u/q, /c/o/u/e, /c/o/q
-s 3
    directories
        /, /r, /r/s
    files
        /f, /x

42.2
Inode bitmap or the inodes are corrupted, bit 13 of inode bitmap is not set but the inode 13 points
to a file block.
According to the original fsck tool, in such a case inode bitmap should be rewritten to reflex the
real state of inodes. 

42.3
-S 3
    The link count of inode 13 is 2 while there's only one file system entry /m pointing to the
    inode
-S 19
    Link count of a directory should be at least 2, one in the parent directory and one for the
    directory itself, but inode 8 has link count 2.
According to the original fsck tool, in such a case reference count in inodes should be rewritten to
reflex the state of the file system.

42.4
-S 5
    Entry `..` pointing to its parent directory in directory /g is corrupted, it points to the same
    inode but now has a name /g/y. 
    Name of the entry should be rewritten to `..`, in this case it's the obvious thing to do.
-S 38
    (Reported by -c) the name of file /w/p is altered to /w/b
    The corruption is impossible to detect, a directory is allowed to reference a file by any name,
    the file system is in a perfectly legal state.
-S 642
    (Reported by -c) the name of directory /g is altered to /w
    The corruption is detectable but impossible to fix, there's two entries in the root directory
    with the same name which is not allowed in VSFS, but the original name of the directory is
    permanently lost.

42.5
-S 6
    Inode 12 is not set in inode bitmap nor referenced anywhere in the file system but has obviously
    corrupted content (an empty directory).
    The inode should be reset to empty.
-S 13
    Inode 10 is not set in inode bitmap nor referenced anywhere in the file system but has valid
    content of an empty file.
    The inode should be reset to empty as the file inode doesn't point to any data blocks, otherwise
    it's content should be moved  to lost+found directory.

42.6
The type field of inode 13 is corrupted, it points to a data block but the its type is set to
directory.
Given the assumption that there's only one corrupted block, the reference count of the parent
directory `/` must be trusted, the type of the inode should be rewritten to a file. 

42.7
Inode 0, inode of the root directory has type file instead of directory.
The VSFS assumes that the inode 0 always points to the root directory, type field of inode 0 should
be rewritten to directory.

42.8
Entry `..` to parent directory in directory `/w` points to inode 3 instead of 0.
Inode number of the entry `/w/..` should be rewritten to 0, the information is available in the data
block of the root directory.

42.9
-S 16
    Inode 13, the inode referenced by file `/m`, points to an empty data block, also the data block 15 is
    dangling.
-S 20
    Inode 8, the inode referenced by directory `/g`, points to an empty data block 11, also the
    data block 6 is dangling.
The corrupted inode should be removed, the content of the dangling data block should be moved to
lost+found.

43. Log-structured File Systems
Questions
43.1
-n 3
    creat("/ku3");
    int fd = open("/ku3"); write(fd, /* z0 */); close(fd);
    creat("/qg9");
    live blocks at the end:
        0, 8, 9, 11, 12, 13, 14
-n 5
    // following operations of -n 3
    link("/qg9", "/is8");
    mkdir("/cl6");
    live blocks at the end:
        0, 8, 9, 17, 19, 20, 21, 22, 23
The task doesn't become any more harder as the number of operations increases, unlike a typical file
system the LFS never overwrites old contents and metadata, the operations can be easily figured out 
from what has been appended to the log.

43.2
-s 1
    creat("/tg4");
    // the file "/tg4" is resized without written to 
    creat("/lt0");
    live blocks at the end:
        0, 8, 10, 11, 12, 13

43.3
[   0 ] live checkpoint: 3 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   1 ]      [.,0] [..,0] -- -- -- -- -- --
[   2 ]      type:dir size:1 refs:2 ptrs: 1 -- -- -- -- -- -- --
[   3 ]      chunk(imap): 2 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
// creat file /us7
[   4 ] live [.,0] [..,0] [us7,1] -- -- -- -- --
[   5 ] live type:dir size:1 refs:2 ptrs: 4 -- -- -- -- -- -- --
[   6 ]      type:reg size:0 refs:1 ptrs: -- -- -- -- -- -- -- --
[   7 ]      chunk(imap): 5 6 -- -- -- -- -- -- -- -- -- -- -- -- -- --
// write file /us7 offset=4 size=0
[   8 ]      type:reg size:5 refs:1 ptrs: -- -- -- -- -- -- -- --
[   9 ]      chunk(imap): 5 8 -- -- -- -- -- -- -- -- -- -- -- -- -- --
// write file /us7 offset=7 size=7
[  10 ] live [file content of size 7]
[  11 ] live type:reg size:8 refs:1 ptrs: -- -- -- -- -- -- -- 10
[  12 ] live chunk(imap): 5 11 -- -- -- -- -- -- -- -- -- -- -- -- -- --

43.4
live blocks at the end:
    check point: 0, 
    imap: 99
    file /af4: 66, 60, 64, 65, 
    file /lt0: 80, 34, 68, 69, 70, 76, 77, 78, 79
    file /ln7/zp3: 91, 
    dir /ln7: 94, 93,
    file /ln7/zu5: 95, 
    dir /: 98, 97,

43.5
[   0 ] live checkpoint: 19 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   1 ]      [.,0] [..,0] -- -- -- -- -- --
[   2 ]      type:dir size:1 refs:2 ptrs: 1 -- -- -- -- -- -- --
[   3 ]      chunk(imap): 2 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   4 ] live [.,0] [..,0] [foo,1] -- -- -- -- --
[   5 ] live type:dir size:1 refs:2 ptrs: 4 -- -- -- -- -- -- --
[   6 ]      type:reg size:0 refs:1 ptrs: -- -- -- -- -- -- -- --
[   7 ]      chunk(imap): 5 6 -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   8 ] live v0v0v0v0v0v0v0v0v0v0v0v0v0v0v0v0
[   9 ]      type:reg size:1 refs:1 ptrs: 8 -- -- -- -- -- -- --
[  10 ]      chunk(imap): 5 9 -- -- -- -- -- -- -- -- -- -- -- -- -- --
[  11 ] live t0t0t0t0t0t0t0t0t0t0t0t0t0t0t0t0
[  12 ]      type:reg size:2 refs:1 ptrs: 8 11 -- -- -- -- -- --
[  13 ]      chunk(imap): 5 12 -- -- -- -- -- -- -- -- -- -- -- -- -- --
[  14 ] live k0k0k0k0k0k0k0k0k0k0k0k0k0k0k0k0
[  15 ]      type:reg size:3 refs:1 ptrs: 8 11 14 -- -- -- -- --
[  16 ]      chunk(imap): 5 15 -- -- -- -- -- -- -- -- -- -- -- -- -- --
[  17 ] live g0g0g0g0g0g0g0g0g0g0g0g0g0g0g0g0
[  18 ] live type:reg size:4 refs:1 ptrs: 8 11 14 17 -- -- -- --
[  19 ] live chunk(imap): 5 18 -- -- -- -- -- -- -- -- -- -- -- -- -- --

43.6
[   0 ] live checkpoint: 13 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   1 ]      [.,0] [..,0] -- -- -- -- -- --
[   2 ]      type:dir size:1 refs:2 ptrs: 1 -- -- -- -- -- -- --
[   3 ]      chunk(imap): 2 -- -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   4 ] live [.,0] [..,0] [foo,1] -- -- -- -- --
[   5 ] live type:dir size:1 refs:2 ptrs: 4 -- -- -- -- -- -- --
[   6 ]      type:reg size:0 refs:1 ptrs: -- -- -- -- -- -- -- --
[   7 ]      chunk(imap): 5 6 -- -- -- -- -- -- -- -- -- -- -- -- -- --
[   8 ] live v0v0v0v0v0v0v0v0v0v0v0v0v0v0v0v0
[   9 ] live t1t1t1t1t1t1t1t1t1t1t1t1t1t1t1t1
[  10 ] live k2k2k2k2k2k2k2k2k2k2k2k2k2k2k2k2
[  11 ] live g3g3g3g3g3g3g3g3g3g3g3g3g3g3g3g3
[  12 ] live type:reg size:4 refs:1 ptrs: 8 9 10 11 -- -- -- --
[  13 ] live chunk(imap): 5 12 -- -- -- -- -- -- -- -- -- -- -- -- -- --
The metadata of the file and the imap is updated (appended) once instead of 4 times if the 4 chunks
are written at once. Not only the write can be flushed to the disk in a sequential write, the the
resulting log also is much shorter if the writes are buffered.

43.7
-L c,/foo:w,/foo,0,1
    creat("/foo");
    write file /foo offset=0 size=1;
-L c,/foo:w,/foo,7,1
    creat("/foo");
    write file /foo offset=7 size=1;
A chunk of size 1 is written to different offset of the file, in the second case the file has size 8
and its content up to offset 7 is uninitialized, according to the man page of fseek it's content up
to offset 7 should be filled with 0 bytes (that is, if the writes are done through libc).

43.8
On file creation the content of the file is empty, only a single inode is allocated for the fresh
file. On directory creation the new directory must be initialized with the default entries to itself
and its parent directory, two blocks, one data block and one inode are created. On both cases the
inode of the parent directory, the imap and the check point must be updated to reflect the existence
of the new entry.

43.9
4 blocks are written out to the disk:
    the new directory entries containing the hard link
    the new inode of the directory
    the new inode of the linked file with incremented reference count
    the new imap pointing to the new inodes
It resembles the creation of a file except that, instead of a new file inode with reference count 1,
the same inode of the old file is appended with incremented reference count.

43.10
With -a s, the 10 files created by the operations fits in a single imap, this imap is updated
(appended) every single time a new file is created; with -a r, inodes of files are scattered over
the possible range of inode numbers, 8 instead of 1 imaps are live in the file system.
Random inode allocation hinders the performance during rebuilding of the imap cache in memory on
startup if the backing drive has poor random access throughput compared to sequential, the log could
also be slightly longer as possibly two imaps are updated on file creation if inodes of the
directory and the file are allocated to different imaps.

43.11
// The simulator contains a bug. When operations are generated randomly the simulator may attempt to
// create a hard link of a file while there's no file in the file system, resulting in index out of
// bound error. This bug is triggered by seed 1000, seed 1001 is used in the answer below as a
// replacement.
If the check point is never updated or only updated periodically, upon unexpected power loss or in
any other way the system crashes, the modification to the file system after the last update is lost.
Not sure how to roll forward and recover the lost modifications in this simple version of LFS as
there's no way to tell what exactly an imap points to without an up to date checkpoint, certain file
system structures e.g. the root directory is easy to figure out _assuming_ the content is not
corrupted and some of the inodes and imaps can be recovered by following the pointers in reverse,
but I don't think the entire file system can be recovered reliably in this way. 

44. Flash-based SSDs